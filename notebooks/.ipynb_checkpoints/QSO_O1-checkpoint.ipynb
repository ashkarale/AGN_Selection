{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7eb2c4",
   "metadata": {},
   "source": [
    "# Performing QSO Classification using Autoencoders¶\n",
    "\n",
    "This notebook performs Quasar Classification via a simple Autoencoder. The frameworks used for this deep learning model are TensorFlow and Pytorch.\n",
    "\n",
    "\n",
    "## Authors\n",
    "\n",
    "* Ash Karale\n",
    "    \n",
    "\n",
    "## Contents:\n",
    "\n",
    "* [Introduction](#one)\n",
    "* [Importing Modules](#two)\n",
    "* [Data Acquisition](#three)\n",
    "* [Data Processing](#four)\n",
    "* [TensorFlow](#five)\n",
    "* [PyTorch](#six)\n",
    "* [TensorFlow vs PyTorch](#seven)\n",
    "\n",
    "\n",
    "## Versions:\n",
    "\n",
    "Initial Version: November 2022 (Ash Karale)\n",
    "\n",
    "Updated Version: April 2023 (Ash Karale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6223a6a",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction <a class=\"anchor\" id=\"one\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206739fd",
   "metadata": {},
   "source": [
    "Plan is to explain the dataset first, and what we aim to do with it. Next, an introduction to autoencoders and why we chose it. Lastly, an introduction to TensorFlow and PyTorch- I am thinking just a brief paragraph or two as I will write more about them in their cell blocks below\n",
    "\n",
    "TensorFlow and PyTorch are two of the most popular deep learning frameworks. They allow developers to build and train machine learning models using a variety of techniques, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac234f8",
   "metadata": {},
   "source": [
    "## Importing Modules <a class=\"anchor\" id=\"two\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468c32b",
   "metadata": {},
   "source": [
    "It is widely recommended to include the import statements for all the necessary modules at the beginning of a Jupyter Notebook or any Python program. \n",
    "This practice ensures that the required dependencies are properly imported and accessible at the required points in the code, thus avoiding any potential issues or errors related to missing modules or dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648dcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n",
      "[Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# Importing all required modules\n",
    "\n",
    "# System modules allow Python programs to interact with the operating system and perform tasks \n",
    "# such as reading and writing files, managing processes, and accessing environment variables \n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Data manipulation modules allow users to perform various operations on data,\n",
    "# such as cleaning, transforming, aggregating, filtering, and visualizing data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization modules allow users to create visual representations of data\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import palettable\n",
    "import seaborn as sns\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# Scikit-learn provides a range of supervised and unsupervised learning algorithms,\n",
    "# as well as tools for model selection and data preprocessing\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "# Scipy is a Python library for scientific computing and technical computing\n",
    "from scipy import stats\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "# Astropy is a Python library for astronomy and astrophysics\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# TensorFlow is an open-source machine learning library that provides an extensive set of tools and libraries\n",
    "# for building,training, and deploying neural networks, as well as other machine learning algorithms\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# PyTorch is an open-source machine learning library for Python that provides a range of tools\n",
    "# and functions for building and training neural networks and other machine learning models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d6452",
   "metadata": {},
   "source": [
    "## Data Acquisition <a class=\"anchor\" id=\"three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfde60f",
   "metadata": {},
   "source": [
    "Data acquisition involves the collection and aggregation of data from diverse sources. This crucial initial stage in the data analysis pipeline entails recognizing data sources and acquiring the data in a format suitable for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192039dd",
   "metadata": {},
   "source": [
    "The provided statement establishes the data pathway. If an alternative data source is required, the line in the subsequent cell should be substituted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97acfd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ash/Research/Data/AGN_DataChallenge/ObjectTable.parquet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining a variable named 'data_dir' and assigning it the string value /Users/ash/Research/Data/AGN_DataChallenge/ \n",
    "# This is the path to the directory where the dataset is stored on the local machine\n",
    "data_dir = '/Users/ash/Research/Data/AGN_DataChallenge/ObjectTable.parquet'\n",
    "\n",
    "# Using the display() function to display the value of the 'data_dir' variable in the output of the Jupyter Notebook\n",
    "display(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aeef54",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "\n",
    "The measurements can be classified into several key categories:\n",
    "- __Astrometry__ includes measurements of celestial coordinates such as right ascension (RA), declination (Dec), proper motion, and parallax.\n",
    "- __Photometry__ encompasses both point and extended source photometry, providing measurements in terms of AB magnitudes and fluxes (expressed in nJy).\n",
    "- __Color__ is determined by computing the ratios of fluxes in different wavelength bands.\n",
    "- __Morphology__ is indicated by a binary value, with 1 representing extended sources and 0 representing point-like sources.\n",
    "- __Light Curve Features__ are extracted from the SDSS light curves when a match is found.\n",
    "- __Redshift__ is provided whenever available, including both spectroscopic and photometric measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be40be1",
   "metadata": {},
   "source": [
    "Inspecting the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8b051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>psPm_ra</th>\n",
       "      <th>psPm_dec</th>\n",
       "      <th>psParallax</th>\n",
       "      <th>psFlux_u</th>\n",
       "      <th>psFlux_g</th>\n",
       "      <th>psFlux_r</th>\n",
       "      <th>psFlux_i</th>\n",
       "      <th>psFlux_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lcNonPeriodic[27]_g</th>\n",
       "      <th>lcNonPeriodic[27]_r</th>\n",
       "      <th>lcNonPeriodic[27]_i</th>\n",
       "      <th>lcNonPeriodic[27]_z</th>\n",
       "      <th>lcNonPeriodic[28]_u</th>\n",
       "      <th>lcNonPeriodic[28]_g</th>\n",
       "      <th>lcNonPeriodic[28]_r</th>\n",
       "      <th>lcNonPeriodic[28]_i</th>\n",
       "      <th>lcNonPeriodic[28]_z</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>446487.000000</td>\n",
       "      <td>446487.000000</td>\n",
       "      <td>4.409540e+05</td>\n",
       "      <td>4.409540e+05</td>\n",
       "      <td>134086.000000</td>\n",
       "      <td>3.837000e+05</td>\n",
       "      <td>4.327770e+05</td>\n",
       "      <td>4.349760e+05</td>\n",
       "      <td>4.344730e+05</td>\n",
       "      <td>4.353380e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.086340e+05</td>\n",
       "      <td>2.086260e+05</td>\n",
       "      <td>2.086260e+05</td>\n",
       "      <td>2.086360e+05</td>\n",
       "      <td>208647.000000</td>\n",
       "      <td>208634.000000</td>\n",
       "      <td>208626.000000</td>\n",
       "      <td>208626.000000</td>\n",
       "      <td>208636.000000</td>\n",
       "      <td>446487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>113.444616</td>\n",
       "      <td>-0.366125</td>\n",
       "      <td>-1.573980e+02</td>\n",
       "      <td>3.466920e+02</td>\n",
       "      <td>0.632487</td>\n",
       "      <td>2.088371e+04</td>\n",
       "      <td>6.637403e+04</td>\n",
       "      <td>1.204108e+05</td>\n",
       "      <td>1.441588e+05</td>\n",
       "      <td>1.825155e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630352e-01</td>\n",
       "      <td>1.500006e-01</td>\n",
       "      <td>1.544376e-01</td>\n",
       "      <td>1.564321e-01</td>\n",
       "      <td>1074.567277</td>\n",
       "      <td>336.663047</td>\n",
       "      <td>252.196483</td>\n",
       "      <td>213.479630</td>\n",
       "      <td>673.852825</td>\n",
       "      <td>0.042991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>142.250504</td>\n",
       "      <td>2.913140</td>\n",
       "      <td>2.668886e+05</td>\n",
       "      <td>2.288902e+05</td>\n",
       "      <td>1.271928</td>\n",
       "      <td>8.627008e+04</td>\n",
       "      <td>2.603277e+05</td>\n",
       "      <td>5.643356e+06</td>\n",
       "      <td>4.128693e+05</td>\n",
       "      <td>5.371203e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.120180e-01</td>\n",
       "      <td>3.391911e-01</td>\n",
       "      <td>3.449507e-01</td>\n",
       "      <td>4.031540e-01</td>\n",
       "      <td>4250.521486</td>\n",
       "      <td>2162.567758</td>\n",
       "      <td>1587.289403</td>\n",
       "      <td>1351.681347</td>\n",
       "      <td>3356.310106</td>\n",
       "      <td>0.024886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>-63.348846</td>\n",
       "      <td>-1.549250e+08</td>\n",
       "      <td>-4.577680e+07</td>\n",
       "      <td>-17.428825</td>\n",
       "      <td>-3.010739e+05</td>\n",
       "      <td>-1.205824e+05</td>\n",
       "      <td>-3.882952e+04</td>\n",
       "      <td>-1.929064e+03</td>\n",
       "      <td>-8.334768e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.005440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.222099</td>\n",
       "      <td>-1.734935</td>\n",
       "      <td>-2.651840e+00</td>\n",
       "      <td>-4.435840e+00</td>\n",
       "      <td>0.042136</td>\n",
       "      <td>8.334138e+02</td>\n",
       "      <td>2.117627e+03</td>\n",
       "      <td>4.649031e+03</td>\n",
       "      <td>8.016084e+03</td>\n",
       "      <td>1.033239e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.404330e-02</td>\n",
       "      <td>1.267155e-02</td>\n",
       "      <td>1.132901e-02</td>\n",
       "      <td>1.049035e-02</td>\n",
       "      <td>1.550629</td>\n",
       "      <td>0.832346</td>\n",
       "      <td>0.515604</td>\n",
       "      <td>0.589236</td>\n",
       "      <td>1.262626</td>\n",
       "      <td>0.026742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.608160</td>\n",
       "      <td>-0.174219</td>\n",
       "      <td>1.751340e-01</td>\n",
       "      <td>-4.706605e-01</td>\n",
       "      <td>0.396610</td>\n",
       "      <td>2.269940e+03</td>\n",
       "      <td>4.816601e+03</td>\n",
       "      <td>1.285625e+04</td>\n",
       "      <td>2.199475e+04</td>\n",
       "      <td>2.979533e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.322668e-02</td>\n",
       "      <td>3.410033e-02</td>\n",
       "      <td>3.464072e-02</td>\n",
       "      <td>3.124982e-02</td>\n",
       "      <td>10.204748</td>\n",
       "      <td>5.822918</td>\n",
       "      <td>3.574042</td>\n",
       "      <td>3.669372</td>\n",
       "      <td>6.927093</td>\n",
       "      <td>0.034057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>320.663727</td>\n",
       "      <td>1.096750</td>\n",
       "      <td>4.129985e+00</td>\n",
       "      <td>2.756258e+00</td>\n",
       "      <td>0.960485</td>\n",
       "      <td>1.026092e+04</td>\n",
       "      <td>2.554773e+04</td>\n",
       "      <td>4.949970e+04</td>\n",
       "      <td>7.176169e+04</td>\n",
       "      <td>8.989345e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167255e-01</td>\n",
       "      <td>1.274892e-01</td>\n",
       "      <td>1.333405e-01</td>\n",
       "      <td>1.097157e-01</td>\n",
       "      <td>145.721905</td>\n",
       "      <td>78.707282</td>\n",
       "      <td>60.275080</td>\n",
       "      <td>41.841657</td>\n",
       "      <td>56.328877</td>\n",
       "      <td>0.050708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.999343</td>\n",
       "      <td>71.652336</td>\n",
       "      <td>7.469720e+07</td>\n",
       "      <td>8.200310e+07</td>\n",
       "      <td>30.256895</td>\n",
       "      <td>6.037682e+06</td>\n",
       "      <td>1.028422e+07</td>\n",
       "      <td>3.714715e+09</td>\n",
       "      <td>2.010603e+07</td>\n",
       "      <td>3.361230e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436499e+01</td>\n",
       "      <td>1.080583e+01</td>\n",
       "      <td>3.405070e+01</td>\n",
       "      <td>1.393099e+01</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>1.285118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ra            dec       psPm_ra      psPm_dec  \\\n",
       "count  446487.000000  446487.000000  4.409540e+05  4.409540e+05   \n",
       "mean      113.444616      -0.366125 -1.573980e+02  3.466920e+02   \n",
       "std       142.250504       2.913140  2.668886e+05  2.288902e+05   \n",
       "min         0.000281     -63.348846 -1.549250e+08 -4.577680e+07   \n",
       "25%        16.222099      -1.734935 -2.651840e+00 -4.435840e+00   \n",
       "50%        33.608160      -0.174219  1.751340e-01 -4.706605e-01   \n",
       "75%       320.663727       1.096750  4.129985e+00  2.756258e+00   \n",
       "max       359.999343      71.652336  7.469720e+07  8.200310e+07   \n",
       "\n",
       "          psParallax      psFlux_u      psFlux_g      psFlux_r      psFlux_i  \\\n",
       "count  134086.000000  3.837000e+05  4.327770e+05  4.349760e+05  4.344730e+05   \n",
       "mean        0.632487  2.088371e+04  6.637403e+04  1.204108e+05  1.441588e+05   \n",
       "std         1.271928  8.627008e+04  2.603277e+05  5.643356e+06  4.128693e+05   \n",
       "min       -17.428825 -3.010739e+05 -1.205824e+05 -3.882952e+04 -1.929064e+03   \n",
       "25%         0.042136  8.334138e+02  2.117627e+03  4.649031e+03  8.016084e+03   \n",
       "50%         0.396610  2.269940e+03  4.816601e+03  1.285625e+04  2.199475e+04   \n",
       "75%         0.960485  1.026092e+04  2.554773e+04  4.949970e+04  7.176169e+04   \n",
       "max        30.256895  6.037682e+06  1.028422e+07  3.714715e+09  2.010603e+07   \n",
       "\n",
       "           psFlux_z  ...  lcNonPeriodic[27]_g  lcNonPeriodic[27]_r  \\\n",
       "count  4.353380e+05  ...         2.086340e+05         2.086260e+05   \n",
       "mean   1.825155e+05  ...         1.630352e-01         1.500006e-01   \n",
       "std    5.371203e+05  ...         4.120180e-01         3.391911e-01   \n",
       "min   -8.334768e+03  ...         5.854756e-08         5.854756e-08   \n",
       "25%    1.033239e+04  ...         1.404330e-02         1.267155e-02   \n",
       "50%    2.979533e+04  ...         3.322668e-02         3.410033e-02   \n",
       "75%    8.989345e+04  ...         1.167255e-01         1.274892e-01   \n",
       "max    3.361230e+07  ...         1.436499e+01         1.080583e+01   \n",
       "\n",
       "       lcNonPeriodic[27]_i  lcNonPeriodic[27]_z  lcNonPeriodic[28]_u  \\\n",
       "count         2.086260e+05         2.086360e+05        208647.000000   \n",
       "mean          1.544376e-01         1.564321e-01          1074.567277   \n",
       "std           3.449507e-01         4.031540e-01          4250.521486   \n",
       "min           5.854756e-08         5.854756e-08             0.018316   \n",
       "25%           1.132901e-02         1.049035e-02             1.550629   \n",
       "50%           3.464072e-02         3.124982e-02            10.204748   \n",
       "75%           1.333405e-01         1.097157e-01           145.721905   \n",
       "max           3.405070e+01         1.393099e+01         22026.465795   \n",
       "\n",
       "       lcNonPeriodic[28]_g  lcNonPeriodic[28]_r  lcNonPeriodic[28]_i  \\\n",
       "count        208634.000000        208626.000000        208626.000000   \n",
       "mean            336.663047           252.196483           213.479630   \n",
       "std            2162.567758          1587.289403          1351.681347   \n",
       "min               0.018316             0.018316             0.018316   \n",
       "25%               0.832346             0.515604             0.589236   \n",
       "50%               5.822918             3.574042             3.669372   \n",
       "75%              78.707282            60.275080            41.841657   \n",
       "max           22026.465795         22026.465795         22026.465795   \n",
       "\n",
       "       lcNonPeriodic[28]_z            ebv  \n",
       "count        208636.000000  446487.000000  \n",
       "mean            673.852825       0.042991  \n",
       "std            3356.310106       0.024886  \n",
       "min               0.018316       0.005440  \n",
       "25%               1.262626       0.026742  \n",
       "50%               6.927093       0.034057  \n",
       "75%              56.328877       0.050708  \n",
       "max           22026.465795       1.285118  \n",
       "\n",
       "[8 rows x 383 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(446487, 384)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gal         246225\n",
       "Star         96715\n",
       "Qso          83130\n",
       "Agn           5608\n",
       "highZQso      1089\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of unlabeled objects: 13720'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object_df = pd.read_parquet(data_dir)\n",
    "display(object_df.describe())\n",
    "display(object_df.shape)\n",
    "\n",
    "# Number of objects in each class + unlabeled\n",
    "display(object_df['class'].value_counts())\n",
    "display(\"Number of unlabeled objects: {}\".format(object_df['class'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610606e5",
   "metadata": {},
   "source": [
    "Stripe 82 is a region of the sky that has been observed multiple times by the Sloan Digital Sky Survey (SDSS). It is located along the celestial equator and covers about 300 square degrees. Because Stripe 82 has been observed so many times, it has very deep imaging, which means it can detect fainter objects than a typical SDSS image.\n",
    "\n",
    "XMM-LSS stands for XMM-Large Scale Structure. It's an X-ray survey of the sky conducted by the XMM-Newton space telescope. It covers a region of about 11.1 square degrees and is designed to study large-scale cosmic structures like galaxy clusters and cosmic filaments.\n",
    "\n",
    "The merging of these datasets likely aims to provide a more comprehensive view of the studied celestial objects, combining data from both optical (Stripe 82) and X-ray (XMM-LSS) observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ba7c4",
   "metadata": {},
   "source": [
    "Data Munging\n",
    "\n",
    "Let's now do some data munging. Specifically\n",
    "\n",
    "    Merge the AGN, QSO, and High-z QSO classes\n",
    "    Remove features that we don't want to use and/or identify only the features that we want to keep\n",
    "    Remove objects that don't have one or more entries for the features (and/or impute those values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cafe091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446487,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0    246225\n",
       "0.0     96715\n",
       "2.0     89827\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of unlabeled objects: 13720'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the class value to numerical\n",
    "# Also move AGN and highZQso to Qso label\n",
    "object_df_new = object_df.replace({'class': {'Star': 0, 'Gal': 1, 'Qso': 2, 'Agn': 2, 'highZQso': 2}})\n",
    "display(object_df_new['class'].shape)\n",
    "display(object_df_new['class'].value_counts())\n",
    "display(\"Number of unlabeled objects: {}\".format(object_df_new['class'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de6c47",
   "metadata": {},
   "source": [
    "Where\n",
    "* 0 = Star\n",
    "* 1 = Galaxy\n",
    "* 2 = AGN/Quasar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414903f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ra', 'dec', 'psPm_ra', 'psPm_dec', 'psParallax', 'psFlux_u', 'psFlux_g', 'psFlux_r', 'psFlux_i', 'psFlux_z', 'psFlux_y', 'psFluxErr_u', 'psFluxErr_g', 'psFluxErr_r', 'psFluxErr_i', 'psFluxErr_z', 'psFluxErr_y', 'bdFlux_u', 'bdFlux_g', 'bdFlux_r', 'bdFlux_i', 'bdFlux_z', 'bdFlux_y', 'bdFluxErr_u', 'bdFluxErr_g', 'bdFluxErr_r', 'bdFluxErr_i', 'bdFluxErr_z', 'bdFluxErr_y', 'psMag_u', 'psMag_g', 'psMag_r', 'psMag_i', 'psMag_z', 'psMag_y', 'psMagErr_u', 'psMagErr_g', 'psMagErr_r', 'psMagErr_i', 'psMagErr_z', 'psMagErr_y', 'bdMag_u', 'bdMag_g', 'bdMag_r', 'bdMag_i', 'bdMag_z', 'bdMag_y', 'bdMagErr_u', 'bdMagErr_g', 'bdMagErr_r', 'bdMagErr_i', 'bdMagErr_z', 'bdMagErr_y', 'extendedness_u', 'extendedness_g', 'extendedness_r', 'extendedness_i', 'extendedness_z', 'extendedness_y', 'stdColor_0', 'stdColor_1', 'stdColor_2', 'stdColor_3', 'stdColor_4', 'stdColorErr_0', 'stdColorErr_1', 'stdColorErr_2', 'stdColorErr_3', 'stdColorErr_4', 'class', 'photoZ_pest', 'z', 'flags_u', 'flags_g', 'flags_r', 'flags_i', 'flags_z', 'flags_y', 'spec_fiberid', 'spec_plate', 'spec_mjd', 'lcPeriodic[0]_g', 'lcPeriodic[0]_r', 'lcPeriodic[0]_i', 'lcPeriodic[1]_g', 'lcPeriodic[1]_r', 'lcPeriodic[1]_i', 'lcPeriodic[2]_g', 'lcPeriodic[2]_r', 'lcPeriodic[2]_i', 'lcPeriodic[3]_g', 'lcPeriodic[3]_r', 'lcPeriodic[3]_i', 'lcPeriodic[4]_u', 'lcPeriodic[4]_g', 'lcPeriodic[4]_r', 'lcPeriodic[4]_i', 'lcPeriodic[4]_z', 'lcPeriodic[5]_u', 'lcPeriodic[5]_g', 'lcPeriodic[5]_r', 'lcPeriodic[5]_i', 'lcPeriodic[5]_z', 'lcPeriodic[6]_u', 'lcPeriodic[6]_g', 'lcPeriodic[6]_r', 'lcPeriodic[6]_i', 'lcPeriodic[6]_z', 'lcPeriodic[7]_u', 'lcPeriodic[7]_g', 'lcPeriodic[7]_r', 'lcPeriodic[7]_i', 'lcPeriodic[7]_z', 'lcPeriodic[8]_u', 'lcPeriodic[8]_g', 'lcPeriodic[8]_r', 'lcPeriodic[8]_i', 'lcPeriodic[8]_z', 'lcPeriodic[9]_u', 'lcPeriodic[9]_g', 'lcPeriodic[9]_r', 'lcPeriodic[9]_i', 'lcPeriodic[9]_z', 'lcPeriodic[10]_u', 'lcPeriodic[10]_g', 'lcPeriodic[10]_r', 'lcPeriodic[10]_i', 'lcPeriodic[10]_z', 'lcPeriodic[11]_u', 'lcPeriodic[11]_g', 'lcPeriodic[11]_r', 'lcPeriodic[11]_i', 'lcPeriodic[11]_z', 'lcPeriodic[12]_u', 'lcPeriodic[12]_g', 'lcPeriodic[12]_r', 'lcPeriodic[12]_i', 'lcPeriodic[12]_z', 'lcPeriodic[13]_u', 'lcPeriodic[13]_g', 'lcPeriodic[13]_r', 'lcPeriodic[13]_i', 'lcPeriodic[13]_z', 'lcPeriodic[14]_u', 'lcPeriodic[14]_g', 'lcPeriodic[14]_r', 'lcPeriodic[14]_i', 'lcPeriodic[14]_z', 'lcPeriodic[15]_u', 'lcPeriodic[15]_g', 'lcPeriodic[15]_r', 'lcPeriodic[15]_i', 'lcPeriodic[15]_z', 'lcPeriodic[16]_u', 'lcPeriodic[16]_g', 'lcPeriodic[16]_r', 'lcPeriodic[16]_i', 'lcPeriodic[16]_z', 'lcPeriodic[17]_u', 'lcPeriodic[17]_g', 'lcPeriodic[17]_r', 'lcPeriodic[17]_i', 'lcPeriodic[17]_z', 'lcPeriodic[18]_u', 'lcPeriodic[18]_g', 'lcPeriodic[18]_r', 'lcPeriodic[18]_i', 'lcPeriodic[18]_z', 'lcPeriodic[19]_u', 'lcPeriodic[19]_g', 'lcPeriodic[19]_r', 'lcPeriodic[19]_i', 'lcPeriodic[19]_z', 'lcPeriodic[20]_u', 'lcPeriodic[20]_g', 'lcPeriodic[20]_r', 'lcPeriodic[20]_i', 'lcPeriodic[20]_z', 'lcPeriodic[21]_u', 'lcPeriodic[21]_g', 'lcPeriodic[21]_r', 'lcPeriodic[21]_i', 'lcPeriodic[21]_z', 'lcPeriodic[22]_u', 'lcPeriodic[22]_g', 'lcPeriodic[22]_r', 'lcPeriodic[22]_i', 'lcPeriodic[22]_z', 'lcPeriodic[23]_u', 'lcPeriodic[23]_g', 'lcPeriodic[23]_r', 'lcPeriodic[23]_i', 'lcPeriodic[23]_z', 'lcPeriodic[24]_u', 'lcPeriodic[24]_g', 'lcPeriodic[24]_r', 'lcPeriodic[24]_i', 'lcPeriodic[24]_z', 'lcPeriodic[25]_u', 'lcPeriodic[25]_g', 'lcPeriodic[25]_r', 'lcPeriodic[25]_i', 'lcPeriodic[25]_z', 'lcPeriodic[26]_u', 'lcPeriodic[26]_g', 'lcPeriodic[26]_r', 'lcPeriodic[26]_i', 'lcPeriodic[26]_z', 'lcPeriodic[27]_u', 'lcPeriodic[27]_g', 'lcPeriodic[27]_r', 'lcPeriodic[27]_i', 'lcPeriodic[27]_z', 'lcPeriodic[28]_u', 'lcPeriodic[28]_g', 'lcPeriodic[28]_r', 'lcPeriodic[28]_i', 'lcPeriodic[28]_z', 'lcPeriodic[29]_u', 'lcPeriodic[29]_g', 'lcPeriodic[29]_r', 'lcPeriodic[29]_i', 'lcPeriodic[29]_z', 'lcPeriodic[30]_u', 'lcPeriodic[30]_g', 'lcPeriodic[30]_r', 'lcPeriodic[30]_i', 'lcPeriodic[30]_z', 'lcPeriodic[31]_u', 'lcPeriodic[31]_g', 'lcPeriodic[31]_r', 'lcPeriodic[31]_i', 'lcPeriodic[31]_z', 'lcPeriodic[32]_u', 'lcPeriodic[32]_g', 'lcPeriodic[32]_r', 'lcPeriodic[32]_i', 'lcPeriodic[32]_z', 'lcNonPeriodic[0]_u', 'lcNonPeriodic[0]_g', 'lcNonPeriodic[0]_r', 'lcNonPeriodic[0]_i', 'lcNonPeriodic[0]_z', 'lcNonPeriodic[1]_u', 'lcNonPeriodic[1]_g', 'lcNonPeriodic[1]_r', 'lcNonPeriodic[1]_i', 'lcNonPeriodic[1]_z', 'lcNonPeriodic[2]_u', 'lcNonPeriodic[2]_g', 'lcNonPeriodic[2]_r', 'lcNonPeriodic[2]_i', 'lcNonPeriodic[2]_z', 'lcNonPeriodic[3]_u', 'lcNonPeriodic[3]_g', 'lcNonPeriodic[3]_r', 'lcNonPeriodic[3]_i', 'lcNonPeriodic[3]_z', 'lcNonPeriodic[4]_u', 'lcNonPeriodic[4]_g', 'lcNonPeriodic[4]_r', 'lcNonPeriodic[4]_i', 'lcNonPeriodic[4]_z', 'lcNonPeriodic[5]_u', 'lcNonPeriodic[5]_g', 'lcNonPeriodic[5]_r', 'lcNonPeriodic[5]_i', 'lcNonPeriodic[5]_z', 'lcNonPeriodic[6]_u', 'lcNonPeriodic[6]_g', 'lcNonPeriodic[6]_r', 'lcNonPeriodic[6]_i', 'lcNonPeriodic[6]_z', 'lcNonPeriodic[7]_u', 'lcNonPeriodic[7]_g', 'lcNonPeriodic[7]_r', 'lcNonPeriodic[7]_i', 'lcNonPeriodic[7]_z', 'lcNonPeriodic[8]_u', 'lcNonPeriodic[8]_g', 'lcNonPeriodic[8]_r', 'lcNonPeriodic[8]_i', 'lcNonPeriodic[8]_z', 'lcNonPeriodic[9]_u', 'lcNonPeriodic[9]_g', 'lcNonPeriodic[9]_r', 'lcNonPeriodic[9]_i', 'lcNonPeriodic[9]_z', 'lcNonPeriodic[10]_u', 'lcNonPeriodic[10]_g', 'lcNonPeriodic[10]_r', 'lcNonPeriodic[10]_i', 'lcNonPeriodic[10]_z', 'lcNonPeriodic[11]_u', 'lcNonPeriodic[11]_g', 'lcNonPeriodic[11]_r', 'lcNonPeriodic[11]_i', 'lcNonPeriodic[11]_z', 'lcNonPeriodic[12]_u', 'lcNonPeriodic[12]_g', 'lcNonPeriodic[12]_r', 'lcNonPeriodic[12]_i', 'lcNonPeriodic[12]_z', 'lcNonPeriodic[13]_u', 'lcNonPeriodic[13]_g', 'lcNonPeriodic[13]_r', 'lcNonPeriodic[13]_i', 'lcNonPeriodic[13]_z', 'lcNonPeriodic[14]_u', 'lcNonPeriodic[14]_g', 'lcNonPeriodic[14]_r', 'lcNonPeriodic[14]_i', 'lcNonPeriodic[14]_z', 'lcNonPeriodic[15]_u', 'lcNonPeriodic[15]_g', 'lcNonPeriodic[15]_r', 'lcNonPeriodic[15]_i', 'lcNonPeriodic[15]_z', 'lcNonPeriodic[16]_u', 'lcNonPeriodic[16]_g', 'lcNonPeriodic[16]_r', 'lcNonPeriodic[16]_i', 'lcNonPeriodic[16]_z', 'lcNonPeriodic[17]_u', 'lcNonPeriodic[17]_g', 'lcNonPeriodic[17]_r', 'lcNonPeriodic[17]_i', 'lcNonPeriodic[17]_z', 'lcNonPeriodic[18]_u', 'lcNonPeriodic[18]_g', 'lcNonPeriodic[18]_r', 'lcNonPeriodic[18]_i', 'lcNonPeriodic[18]_z', 'lcNonPeriodic[19]_u', 'lcNonPeriodic[19]_g', 'lcNonPeriodic[19]_r', 'lcNonPeriodic[19]_i', 'lcNonPeriodic[19]_z', 'lcNonPeriodic[20]_u', 'lcNonPeriodic[20]_g', 'lcNonPeriodic[20]_r', 'lcNonPeriodic[20]_i', 'lcNonPeriodic[20]_z', 'lcNonPeriodic[21]_u', 'lcNonPeriodic[21]_g', 'lcNonPeriodic[21]_r', 'lcNonPeriodic[21]_i', 'lcNonPeriodic[21]_z', 'lcNonPeriodic[22]_u', 'lcNonPeriodic[22]_g', 'lcNonPeriodic[22]_r', 'lcNonPeriodic[22]_i', 'lcNonPeriodic[22]_z', 'lcNonPeriodic[23]_u', 'lcNonPeriodic[23]_g', 'lcNonPeriodic[23]_r', 'lcNonPeriodic[23]_i', 'lcNonPeriodic[23]_z', 'lcNonPeriodic[24]_u', 'lcNonPeriodic[24]_g', 'lcNonPeriodic[24]_r', 'lcNonPeriodic[24]_i', 'lcNonPeriodic[24]_z', 'lcNonPeriodic[25]_u', 'lcNonPeriodic[25]_g', 'lcNonPeriodic[25]_r', 'lcNonPeriodic[25]_i', 'lcNonPeriodic[25]_z', 'lcNonPeriodic[26]_u', 'lcNonPeriodic[26]_g', 'lcNonPeriodic[26]_r', 'lcNonPeriodic[26]_i', 'lcNonPeriodic[26]_z', 'lcNonPeriodic[27]_u', 'lcNonPeriodic[27]_g', 'lcNonPeriodic[27]_r', 'lcNonPeriodic[27]_i', 'lcNonPeriodic[27]_z', 'lcNonPeriodic[28]_u', 'lcNonPeriodic[28]_g', 'lcNonPeriodic[28]_r', 'lcNonPeriodic[28]_i', 'lcNonPeriodic[28]_z', 'ebv']\n"
     ]
    }
   ],
   "source": [
    "col_list = object_df_new.columns.values.tolist()\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47678d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ra                     446487\n",
       "dec                    446487\n",
       "psPm_ra                440954\n",
       "psPm_dec               440954\n",
       "psParallax             134086\n",
       "psFlux_u               383700\n",
       "psFlux_g               432777\n",
       "psFlux_r               434976\n",
       "psFlux_i               434473\n",
       "psFlux_z               435338\n",
       "psFlux_y               390710\n",
       "psFluxErr_u            383700\n",
       "psFluxErr_g            432777\n",
       "psFluxErr_r            434976\n",
       "psFluxErr_i            434473\n",
       "psFluxErr_z            435338\n",
       "psFluxErr_y            390710\n",
       "bdFlux_u               383720\n",
       "bdFlux_g               441230\n",
       "bdFlux_r               441340\n",
       "bdFlux_i               441189\n",
       "bdFlux_z               441372\n",
       "bdFlux_y               418980\n",
       "bdFluxErr_u            383720\n",
       "bdFluxErr_g            441230\n",
       "bdFluxErr_r            441340\n",
       "bdFluxErr_i            441189\n",
       "bdFluxErr_z            441372\n",
       "bdFluxErr_y            418980\n",
       "psMag_u                342472\n",
       "psMag_g                432568\n",
       "psMag_r                434958\n",
       "psMag_i                434463\n",
       "psMag_z                435270\n",
       "psMag_y                390710\n",
       "psMagErr_u             342472\n",
       "psMagErr_g             432602\n",
       "psMagErr_r             434979\n",
       "psMagErr_i             434469\n",
       "psMagErr_z             435291\n",
       "psMagErr_y             390766\n",
       "bdMag_u                345404\n",
       "bdMag_g                441011\n",
       "bdMag_r                441319\n",
       "bdMag_i                441178\n",
       "bdMag_z                441322\n",
       "bdMag_y                418980\n",
       "bdMagErr_u             345404\n",
       "bdMagErr_g             441011\n",
       "bdMagErr_r             441321\n",
       "bdMagErr_i             441179\n",
       "bdMagErr_z             441324\n",
       "bdMagErr_y             418981\n",
       "extendedness_u         383860\n",
       "extendedness_g         440431\n",
       "extendedness_r         440437\n",
       "extendedness_i         440415\n",
       "extendedness_z         440482\n",
       "extendedness_y         418259\n",
       "stdColor_0             337876\n",
       "stdColor_1             430081\n",
       "stdColor_2             432797\n",
       "stdColor_3             433420\n",
       "stdColor_4             387106\n",
       "stdColorErr_0          377671\n",
       "stdColorErr_1          430286\n",
       "stdColorErr_2          432811\n",
       "stdColorErr_3          433496\n",
       "stdColorErr_4          387106\n",
       "class                  432767\n",
       "photoZ_pest            231892\n",
       "z                      429804\n",
       "flags_u                383860\n",
       "flags_g                440812\n",
       "flags_r                440812\n",
       "flags_i                440812\n",
       "flags_z                440812\n",
       "flags_y                418731\n",
       "spec_fiberid           426493\n",
       "spec_plate             426990\n",
       "spec_mjd               426990\n",
       "lcPeriodic[0]_g        152062\n",
       "lcPeriodic[0]_r        153160\n",
       "lcPeriodic[0]_i        153490\n",
       "lcPeriodic[1]_g        152062\n",
       "lcPeriodic[1]_r        153160\n",
       "lcPeriodic[1]_i        153490\n",
       "lcPeriodic[2]_g        152062\n",
       "lcPeriodic[2]_r        153160\n",
       "lcPeriodic[2]_i        153490\n",
       "lcPeriodic[3]_g        152062\n",
       "lcPeriodic[3]_r        153160\n",
       "lcPeriodic[3]_i        153490\n",
       "lcPeriodic[4]_u        212419\n",
       "lcPeriodic[4]_g        212423\n",
       "lcPeriodic[4]_r        212423\n",
       "lcPeriodic[4]_i        212423\n",
       "lcPeriodic[4]_z        212423\n",
       "lcPeriodic[5]_u        212419\n",
       "lcPeriodic[5]_g        212423\n",
       "lcPeriodic[5]_r        212423\n",
       "lcPeriodic[5]_i        212423\n",
       "lcPeriodic[5]_z        212423\n",
       "lcPeriodic[6]_u        212419\n",
       "lcPeriodic[6]_g        212423\n",
       "lcPeriodic[6]_r        212423\n",
       "lcPeriodic[6]_i        212423\n",
       "lcPeriodic[6]_z        212423\n",
       "lcPeriodic[7]_u        212419\n",
       "lcPeriodic[7]_g        212423\n",
       "lcPeriodic[7]_r        212423\n",
       "lcPeriodic[7]_i        212423\n",
       "lcPeriodic[7]_z        212423\n",
       "lcPeriodic[8]_u        212425\n",
       "lcPeriodic[8]_g        212425\n",
       "lcPeriodic[8]_r        212425\n",
       "lcPeriodic[8]_i        212425\n",
       "lcPeriodic[8]_z        212425\n",
       "lcPeriodic[9]_u        212419\n",
       "lcPeriodic[9]_g        212423\n",
       "lcPeriodic[9]_r        212423\n",
       "lcPeriodic[9]_i        212423\n",
       "lcPeriodic[9]_z        212423\n",
       "lcPeriodic[10]_u       212419\n",
       "lcPeriodic[10]_g       212423\n",
       "lcPeriodic[10]_r       212423\n",
       "lcPeriodic[10]_i       212423\n",
       "lcPeriodic[10]_z       212423\n",
       "lcPeriodic[11]_u       212419\n",
       "lcPeriodic[11]_g       212423\n",
       "lcPeriodic[11]_r       212423\n",
       "lcPeriodic[11]_i       212423\n",
       "lcPeriodic[11]_z       212423\n",
       "lcPeriodic[12]_u       212419\n",
       "lcPeriodic[12]_g       212423\n",
       "lcPeriodic[12]_r       212423\n",
       "lcPeriodic[12]_i       212423\n",
       "lcPeriodic[12]_z       212423\n",
       "lcPeriodic[13]_u       212419\n",
       "lcPeriodic[13]_g       212423\n",
       "lcPeriodic[13]_r       212423\n",
       "lcPeriodic[13]_i       212423\n",
       "lcPeriodic[13]_z       212423\n",
       "lcPeriodic[14]_u       212419\n",
       "lcPeriodic[14]_g       212423\n",
       "lcPeriodic[14]_r       212423\n",
       "lcPeriodic[14]_i       212423\n",
       "lcPeriodic[14]_z       212423\n",
       "lcPeriodic[15]_u       212419\n",
       "lcPeriodic[15]_g       212423\n",
       "lcPeriodic[15]_r       212423\n",
       "lcPeriodic[15]_i       212423\n",
       "lcPeriodic[15]_z       212423\n",
       "lcPeriodic[16]_u       212425\n",
       "lcPeriodic[16]_g       212425\n",
       "lcPeriodic[16]_r       212425\n",
       "lcPeriodic[16]_i       212425\n",
       "lcPeriodic[16]_z       212425\n",
       "lcPeriodic[17]_u       212419\n",
       "lcPeriodic[17]_g       212423\n",
       "lcPeriodic[17]_r       212423\n",
       "lcPeriodic[17]_i       212423\n",
       "lcPeriodic[17]_z       212423\n",
       "lcPeriodic[18]_u       212419\n",
       "lcPeriodic[18]_g       212423\n",
       "lcPeriodic[18]_r       212423\n",
       "lcPeriodic[18]_i       212423\n",
       "lcPeriodic[18]_z       212423\n",
       "lcPeriodic[19]_u       212419\n",
       "lcPeriodic[19]_g       212423\n",
       "lcPeriodic[19]_r       212423\n",
       "lcPeriodic[19]_i       212423\n",
       "lcPeriodic[19]_z       212423\n",
       "lcPeriodic[20]_u       212419\n",
       "lcPeriodic[20]_g       212423\n",
       "lcPeriodic[20]_r       212423\n",
       "lcPeriodic[20]_i       212423\n",
       "lcPeriodic[20]_z       212423\n",
       "lcPeriodic[21]_u       212419\n",
       "lcPeriodic[21]_g       212423\n",
       "lcPeriodic[21]_r       212423\n",
       "lcPeriodic[21]_i       212423\n",
       "lcPeriodic[21]_z       212423\n",
       "lcPeriodic[22]_u       212419\n",
       "lcPeriodic[22]_g       212423\n",
       "lcPeriodic[22]_r       212423\n",
       "lcPeriodic[22]_i       212423\n",
       "lcPeriodic[22]_z       212423\n",
       "lcPeriodic[23]_u       212419\n",
       "lcPeriodic[23]_g       212423\n",
       "lcPeriodic[23]_r       212423\n",
       "lcPeriodic[23]_i       212423\n",
       "lcPeriodic[23]_z       212423\n",
       "lcPeriodic[24]_u       212425\n",
       "lcPeriodic[24]_g       212425\n",
       "lcPeriodic[24]_r       212425\n",
       "lcPeriodic[24]_i       212425\n",
       "lcPeriodic[24]_z       212425\n",
       "lcPeriodic[25]_u       212419\n",
       "lcPeriodic[25]_g       212423\n",
       "lcPeriodic[25]_r       212423\n",
       "lcPeriodic[25]_i       212423\n",
       "lcPeriodic[25]_z       212423\n",
       "lcPeriodic[26]_u       212419\n",
       "lcPeriodic[26]_g       212423\n",
       "lcPeriodic[26]_r       212423\n",
       "lcPeriodic[26]_i       212423\n",
       "lcPeriodic[26]_z       212423\n",
       "lcPeriodic[27]_u       212419\n",
       "lcPeriodic[27]_g       212423\n",
       "lcPeriodic[27]_r       212423\n",
       "lcPeriodic[27]_i       212423\n",
       "lcPeriodic[27]_z       212423\n",
       "lcPeriodic[28]_u       212425\n",
       "lcPeriodic[28]_g       212425\n",
       "lcPeriodic[28]_r       212425\n",
       "lcPeriodic[28]_i       212425\n",
       "lcPeriodic[28]_z       212425\n",
       "lcPeriodic[29]_u       212419\n",
       "lcPeriodic[29]_g       212423\n",
       "lcPeriodic[29]_r       212423\n",
       "lcPeriodic[29]_i       212423\n",
       "lcPeriodic[29]_z       212423\n",
       "lcPeriodic[30]_u       212419\n",
       "lcPeriodic[30]_g       212423\n",
       "lcPeriodic[30]_r       212423\n",
       "lcPeriodic[30]_i       212423\n",
       "lcPeriodic[30]_z       212423\n",
       "lcPeriodic[31]_u       212419\n",
       "lcPeriodic[31]_g       212423\n",
       "lcPeriodic[31]_r       212423\n",
       "lcPeriodic[31]_i       212423\n",
       "lcPeriodic[31]_z       212423\n",
       "lcPeriodic[32]_u       212419\n",
       "lcPeriodic[32]_g       212423\n",
       "lcPeriodic[32]_r       212423\n",
       "lcPeriodic[32]_i       212423\n",
       "lcPeriodic[32]_z       212423\n",
       "lcNonPeriodic[0]_u     212425\n",
       "lcNonPeriodic[0]_g     212425\n",
       "lcNonPeriodic[0]_r     212425\n",
       "lcNonPeriodic[0]_i     212425\n",
       "lcNonPeriodic[0]_z     212425\n",
       "lcNonPeriodic[1]_u     212425\n",
       "lcNonPeriodic[1]_g     212425\n",
       "lcNonPeriodic[1]_r     212425\n",
       "lcNonPeriodic[1]_i     212425\n",
       "lcNonPeriodic[1]_z     212425\n",
       "lcNonPeriodic[2]_u     212425\n",
       "lcNonPeriodic[2]_g     212425\n",
       "lcNonPeriodic[2]_r     212425\n",
       "lcNonPeriodic[2]_i     212425\n",
       "lcNonPeriodic[2]_z     212425\n",
       "lcNonPeriodic[3]_u     212425\n",
       "lcNonPeriodic[3]_g     212425\n",
       "lcNonPeriodic[3]_r     212425\n",
       "lcNonPeriodic[3]_i     212425\n",
       "lcNonPeriodic[3]_z     212425\n",
       "lcNonPeriodic[4]_u     212425\n",
       "lcNonPeriodic[4]_g     212425\n",
       "lcNonPeriodic[4]_r     212425\n",
       "lcNonPeriodic[4]_i     212425\n",
       "lcNonPeriodic[4]_z     212425\n",
       "lcNonPeriodic[5]_u     212425\n",
       "lcNonPeriodic[5]_g     212425\n",
       "lcNonPeriodic[5]_r     212425\n",
       "lcNonPeriodic[5]_i     212425\n",
       "lcNonPeriodic[5]_z     212425\n",
       "lcNonPeriodic[6]_u     212425\n",
       "lcNonPeriodic[6]_g     212425\n",
       "lcNonPeriodic[6]_r     212425\n",
       "lcNonPeriodic[6]_i     212425\n",
       "lcNonPeriodic[6]_z     212425\n",
       "lcNonPeriodic[7]_u     212419\n",
       "lcNonPeriodic[7]_g     212423\n",
       "lcNonPeriodic[7]_r     212423\n",
       "lcNonPeriodic[7]_i     212423\n",
       "lcNonPeriodic[7]_z     212423\n",
       "lcNonPeriodic[8]_u     212425\n",
       "lcNonPeriodic[8]_g     212425\n",
       "lcNonPeriodic[8]_r     212425\n",
       "lcNonPeriodic[8]_i     212425\n",
       "lcNonPeriodic[8]_z     212425\n",
       "lcNonPeriodic[9]_u     212425\n",
       "lcNonPeriodic[9]_g     212425\n",
       "lcNonPeriodic[9]_r     212425\n",
       "lcNonPeriodic[9]_i     212425\n",
       "lcNonPeriodic[9]_z     212425\n",
       "lcNonPeriodic[10]_u    212425\n",
       "lcNonPeriodic[10]_g    212425\n",
       "lcNonPeriodic[10]_r    212425\n",
       "lcNonPeriodic[10]_i    212425\n",
       "lcNonPeriodic[10]_z    212425\n",
       "lcNonPeriodic[11]_u    212425\n",
       "lcNonPeriodic[11]_g    212425\n",
       "lcNonPeriodic[11]_r    212425\n",
       "lcNonPeriodic[11]_i    212425\n",
       "lcNonPeriodic[11]_z    212425\n",
       "lcNonPeriodic[12]_u    212425\n",
       "lcNonPeriodic[12]_g    212425\n",
       "lcNonPeriodic[12]_r    212425\n",
       "lcNonPeriodic[12]_i    212425\n",
       "lcNonPeriodic[12]_z    212425\n",
       "lcNonPeriodic[13]_u    212425\n",
       "lcNonPeriodic[13]_g    212425\n",
       "lcNonPeriodic[13]_r    212425\n",
       "lcNonPeriodic[13]_i    212425\n",
       "lcNonPeriodic[13]_z    212425\n",
       "lcNonPeriodic[14]_u    212425\n",
       "lcNonPeriodic[14]_g    212425\n",
       "lcNonPeriodic[14]_r    212425\n",
       "lcNonPeriodic[14]_i    212425\n",
       "lcNonPeriodic[14]_z    212425\n",
       "lcNonPeriodic[15]_u    212425\n",
       "lcNonPeriodic[15]_g    212425\n",
       "lcNonPeriodic[15]_r    212425\n",
       "lcNonPeriodic[15]_i    212425\n",
       "lcNonPeriodic[15]_z    212425\n",
       "lcNonPeriodic[16]_u    212425\n",
       "lcNonPeriodic[16]_g    212425\n",
       "lcNonPeriodic[16]_r    212425\n",
       "lcNonPeriodic[16]_i    212425\n",
       "lcNonPeriodic[16]_z    212425\n",
       "lcNonPeriodic[17]_u    212412\n",
       "lcNonPeriodic[17]_g    212412\n",
       "lcNonPeriodic[17]_r    212416\n",
       "lcNonPeriodic[17]_i    212416\n",
       "lcNonPeriodic[17]_z    212418\n",
       "lcNonPeriodic[18]_u    212425\n",
       "lcNonPeriodic[18]_g    212425\n",
       "lcNonPeriodic[18]_r    212425\n",
       "lcNonPeriodic[18]_i    212425\n",
       "lcNonPeriodic[18]_z    212425\n",
       "lcNonPeriodic[19]_u    212425\n",
       "lcNonPeriodic[19]_g    212425\n",
       "lcNonPeriodic[19]_r    212425\n",
       "lcNonPeriodic[19]_i    212425\n",
       "lcNonPeriodic[19]_z    212425\n",
       "lcNonPeriodic[20]_u    212425\n",
       "lcNonPeriodic[20]_g    212425\n",
       "lcNonPeriodic[20]_r    212425\n",
       "lcNonPeriodic[20]_i    212425\n",
       "lcNonPeriodic[20]_z    212425\n",
       "lcNonPeriodic[21]_u    212425\n",
       "lcNonPeriodic[21]_g    212425\n",
       "lcNonPeriodic[21]_r    212425\n",
       "lcNonPeriodic[21]_i    212425\n",
       "lcNonPeriodic[21]_z    212425\n",
       "lcNonPeriodic[22]_u    212425\n",
       "lcNonPeriodic[22]_g    212425\n",
       "lcNonPeriodic[22]_r    212425\n",
       "lcNonPeriodic[22]_i    212425\n",
       "lcNonPeriodic[22]_z    212425\n",
       "lcNonPeriodic[23]_u    212425\n",
       "lcNonPeriodic[23]_g    212425\n",
       "lcNonPeriodic[23]_r    212425\n",
       "lcNonPeriodic[23]_i    212425\n",
       "lcNonPeriodic[23]_z    212425\n",
       "lcNonPeriodic[24]_u    212425\n",
       "lcNonPeriodic[24]_g    212425\n",
       "lcNonPeriodic[24]_r    212425\n",
       "lcNonPeriodic[24]_i    212425\n",
       "lcNonPeriodic[24]_z    212425\n",
       "lcNonPeriodic[25]_u    212425\n",
       "lcNonPeriodic[25]_g    212425\n",
       "lcNonPeriodic[25]_r    212425\n",
       "lcNonPeriodic[25]_i    212425\n",
       "lcNonPeriodic[25]_z    212425\n",
       "lcNonPeriodic[26]_u    212425\n",
       "lcNonPeriodic[26]_g    212425\n",
       "lcNonPeriodic[26]_r    212425\n",
       "lcNonPeriodic[26]_i    212425\n",
       "lcNonPeriodic[26]_z    212425\n",
       "lcNonPeriodic[27]_u    208647\n",
       "lcNonPeriodic[27]_g    208634\n",
       "lcNonPeriodic[27]_r    208626\n",
       "lcNonPeriodic[27]_i    208626\n",
       "lcNonPeriodic[27]_z    208636\n",
       "lcNonPeriodic[28]_u    208647\n",
       "lcNonPeriodic[28]_g    208634\n",
       "lcNonPeriodic[28]_r    208626\n",
       "lcNonPeriodic[28]_i    208626\n",
       "lcNonPeriodic[28]_z    208636\n",
       "ebv                    446487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", 400)\n",
    "object_df_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127a79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut RA, Dec, psParallax, and the CIV distance-related columns\n",
    "# Cut the errors\n",
    "# Keeping both flux and mag, despite those being redundant\n",
    "# Cut all y-band attributes (including stdColor_4)\n",
    "# Also cut photoZ_pest since those aren't necessarily computed for AGNs\n",
    "# Also cut flags since those should probably be made us of in a preprocesing (or post) step.\n",
    "# Keeping all of the light curve attributes, despite their redundancy\n",
    "colvar_list = ['psFlux_u', 'psFlux_g', 'psFlux_r', 'psFlux_i', 'psFlux_z',\\\n",
    "                'bdFlux_u', 'bdFlux_g', 'bdFlux_r', 'bdFlux_i', 'bdFlux_z',\\\n",
    "                'psMag_u', 'psMag_g', 'psMag_r', 'psMag_i', 'psMag_z',\\\n",
    "                'bdMag_u', 'bdMag_g', 'bdMag_r', 'bdMag_i', 'bdMag_z',\\\n",
    "                'extendedness_u', 'extendedness_g', 'extendedness_r', 'extendedness_i', 'extendedness_z',\\\n",
    "                'stdColor_0', 'stdColor_1', 'stdColor_2', 'stdColor_3',\\\n",
    "                'class', 'z',\\\n",
    "                'lcPeriodic[0]_g', 'lcPeriodic[0]_r', 'lcPeriodic[0]_i',\\\n",
    "                'lcPeriodic[1]_g', 'lcPeriodic[1]_r', 'lcPeriodic[1]_i',\\\n",
    "                'lcPeriodic[2]_g', 'lcPeriodic[2]_r', 'lcPeriodic[2]_i',\\\n",
    "                'lcPeriodic[3]_g', 'lcPeriodic[3]_r', 'lcPeriodic[3]_i',\\\n",
    "                'lcPeriodic[4]_u', 'lcPeriodic[4]_g', 'lcPeriodic[4]_r', 'lcPeriodic[4]_i', 'lcPeriodic[4]_z',\\\n",
    "                'lcPeriodic[5]_u', 'lcPeriodic[5]_g', 'lcPeriodic[5]_r', 'lcPeriodic[5]_i', 'lcPeriodic[5]_z',\\\n",
    "                'lcPeriodic[6]_u', 'lcPeriodic[6]_g', 'lcPeriodic[6]_r', 'lcPeriodic[6]_i', 'lcPeriodic[6]_z',\\\n",
    "                'lcPeriodic[7]_u', 'lcPeriodic[7]_g', 'lcPeriodic[7]_r', 'lcPeriodic[7]_i', 'lcPeriodic[7]_z',\\\n",
    "                'lcPeriodic[8]_u', 'lcPeriodic[8]_g', 'lcPeriodic[8]_r', 'lcPeriodic[8]_i', 'lcPeriodic[8]_z',\\\n",
    "                'lcPeriodic[9]_u', 'lcPeriodic[9]_g', 'lcPeriodic[9]_r', 'lcPeriodic[9]_i', 'lcPeriodic[9]_z',\\\n",
    "                'lcPeriodic[10]_u', 'lcPeriodic[10]_g', 'lcPeriodic[10]_r', 'lcPeriodic[10]_i', 'lcPeriodic[10]_z',\\\n",
    "                'lcPeriodic[11]_u', 'lcPeriodic[11]_g', 'lcPeriodic[11]_r', 'lcPeriodic[11]_i', 'lcPeriodic[11]_z',\\\n",
    "                'lcPeriodic[12]_u', 'lcPeriodic[12]_g', 'lcPeriodic[12]_r', 'lcPeriodic[12]_i', 'lcPeriodic[12]_z',\\\n",
    "                'lcPeriodic[13]_u', 'lcPeriodic[13]_g', 'lcPeriodic[13]_r', 'lcPeriodic[13]_i', 'lcPeriodic[13]_z',\\\n",
    "                'lcPeriodic[14]_u', 'lcPeriodic[14]_g', 'lcPeriodic[14]_r', 'lcPeriodic[14]_i', 'lcPeriodic[14]_z',\\\n",
    "                'lcPeriodic[15]_u', 'lcPeriodic[15]_g', 'lcPeriodic[15]_r', 'lcPeriodic[15]_i', 'lcPeriodic[15]_z',\\\n",
    "                'lcPeriodic[16]_u', 'lcPeriodic[16]_g', 'lcPeriodic[16]_r', 'lcPeriodic[16]_i', 'lcPeriodic[16]_z',\\\n",
    "                'lcPeriodic[17]_u', 'lcPeriodic[17]_g', 'lcPeriodic[17]_r', 'lcPeriodic[17]_i', 'lcPeriodic[17]_z',\\\n",
    "                'lcPeriodic[18]_u', 'lcPeriodic[18]_g', 'lcPeriodic[18]_r', 'lcPeriodic[18]_i', 'lcPeriodic[18]_z',\\\n",
    "                'lcPeriodic[19]_u', 'lcPeriodic[19]_g', 'lcPeriodic[19]_r', 'lcPeriodic[19]_i', 'lcPeriodic[19]_z',\\\n",
    "                'lcPeriodic[20]_u', 'lcPeriodic[20]_g', 'lcPeriodic[20]_r', 'lcPeriodic[20]_i', 'lcPeriodic[20]_z',\\\n",
    "                'lcPeriodic[21]_u', 'lcPeriodic[21]_g', 'lcPeriodic[21]_r', 'lcPeriodic[21]_i', 'lcPeriodic[21]_z',\\\n",
    "                'lcPeriodic[22]_u', 'lcPeriodic[22]_g', 'lcPeriodic[22]_r', 'lcPeriodic[22]_i', 'lcPeriodic[22]_z',\\\n",
    "                'lcPeriodic[23]_u', 'lcPeriodic[23]_g', 'lcPeriodic[23]_r', 'lcPeriodic[23]_i', 'lcPeriodic[23]_z',\\\n",
    "                'lcPeriodic[24]_u', 'lcPeriodic[24]_g', 'lcPeriodic[24]_r', 'lcPeriodic[24]_i', 'lcPeriodic[24]_z',\\\n",
    "                'lcPeriodic[25]_u', 'lcPeriodic[25]_g', 'lcPeriodic[25]_r', 'lcPeriodic[25]_i', 'lcPeriodic[25]_z',\\\n",
    "                'lcPeriodic[26]_u', 'lcPeriodic[26]_g', 'lcPeriodic[26]_r', 'lcPeriodic[26]_i', 'lcPeriodic[26]_z',\\\n",
    "                'lcPeriodic[27]_u', 'lcPeriodic[27]_g', 'lcPeriodic[27]_r', 'lcPeriodic[27]_i', 'lcPeriodic[27]_z',\\\n",
    "                'lcPeriodic[28]_u', 'lcPeriodic[28]_g', 'lcPeriodic[28]_r', 'lcPeriodic[28]_i', 'lcPeriodic[28]_z',\\\n",
    "                'lcPeriodic[29]_u', 'lcPeriodic[29]_g', 'lcPeriodic[29]_r', 'lcPeriodic[29]_i', 'lcPeriodic[29]_z',\\\n",
    "                'lcPeriodic[30]_u', 'lcPeriodic[30]_g', 'lcPeriodic[30]_r', 'lcPeriodic[30]_i', 'lcPeriodic[30]_z',\\\n",
    "                'lcPeriodic[31]_u', 'lcPeriodic[31]_g', 'lcPeriodic[31]_r', 'lcPeriodic[31]_i', 'lcPeriodic[31]_z',\\\n",
    "                'lcPeriodic[32]_u', 'lcPeriodic[32]_g', 'lcPeriodic[32]_r', 'lcPeriodic[32]_i', 'lcPeriodic[32]_z',\\\n",
    "                'lcNonPeriodic[0]_u', 'lcNonPeriodic[0]_g', 'lcNonPeriodic[0]_r', 'lcNonPeriodic[0]_i', 'lcNonPeriodic[0]_z',\\\n",
    "                'lcNonPeriodic[1]_u', 'lcNonPeriodic[1]_g', 'lcNonPeriodic[1]_r', 'lcNonPeriodic[1]_i', 'lcNonPeriodic[1]_z',\\\n",
    "                'lcNonPeriodic[2]_u', 'lcNonPeriodic[2]_g', 'lcNonPeriodic[2]_r', 'lcNonPeriodic[2]_i', 'lcNonPeriodic[2]_z',\\\n",
    "                'lcNonPeriodic[3]_u', 'lcNonPeriodic[3]_g', 'lcNonPeriodic[3]_r', 'lcNonPeriodic[3]_i', 'lcNonPeriodic[3]_z',\\\n",
    "                'lcNonPeriodic[4]_u', 'lcNonPeriodic[4]_g', 'lcNonPeriodic[4]_r', 'lcNonPeriodic[4]_i', 'lcNonPeriodic[4]_z',\\\n",
    "                'lcNonPeriodic[5]_u', 'lcNonPeriodic[5]_g', 'lcNonPeriodic[5]_r', 'lcNonPeriodic[5]_i', 'lcNonPeriodic[5]_z',\\\n",
    "                'lcNonPeriodic[6]_u', 'lcNonPeriodic[6]_g', 'lcNonPeriodic[6]_r', 'lcNonPeriodic[6]_i', 'lcNonPeriodic[6]_z',\\\n",
    "                'lcNonPeriodic[7]_u', 'lcNonPeriodic[7]_g', 'lcNonPeriodic[7]_r', 'lcNonPeriodic[7]_i', 'lcNonPeriodic[7]_z',\\\n",
    "                'lcNonPeriodic[8]_u', 'lcNonPeriodic[8]_g', 'lcNonPeriodic[8]_r', 'lcNonPeriodic[8]_i', 'lcNonPeriodic[8]_z',\\\n",
    "                'lcNonPeriodic[9]_u', 'lcNonPeriodic[9]_g', 'lcNonPeriodic[9]_r', 'lcNonPeriodic[9]_i', 'lcNonPeriodic[9]_z',\\\n",
    "                'lcNonPeriodic[10]_u', 'lcNonPeriodic[10]_g', 'lcNonPeriodic[10]_r', 'lcNonPeriodic[10]_i', 'lcNonPeriodic[10]_z',\\\n",
    "                'lcNonPeriodic[11]_u', 'lcNonPeriodic[11]_g', 'lcNonPeriodic[11]_r', 'lcNonPeriodic[11]_i', 'lcNonPeriodic[11]_z',\\\n",
    "                'lcNonPeriodic[12]_u', 'lcNonPeriodic[12]_g', 'lcNonPeriodic[12]_r', 'lcNonPeriodic[12]_i', 'lcNonPeriodic[12]_z',\\\n",
    "                'lcNonPeriodic[13]_u', 'lcNonPeriodic[13]_g', 'lcNonPeriodic[13]_r', 'lcNonPeriodic[13]_i', 'lcNonPeriodic[13]_z',\\\n",
    "                'lcNonPeriodic[14]_u', 'lcNonPeriodic[14]_g', 'lcNonPeriodic[14]_r', 'lcNonPeriodic[14]_i', 'lcNonPeriodic[14]_z',\\\n",
    "                'lcNonPeriodic[15]_u', 'lcNonPeriodic[15]_g', 'lcNonPeriodic[15]_r', 'lcNonPeriodic[15]_i', 'lcNonPeriodic[15]_z',\\\n",
    "                'lcNonPeriodic[16]_u', 'lcNonPeriodic[16]_g', 'lcNonPeriodic[16]_r', 'lcNonPeriodic[16]_i', 'lcNonPeriodic[16]_z',\\\n",
    "                'lcNonPeriodic[17]_u', 'lcNonPeriodic[17]_g', 'lcNonPeriodic[17]_r', 'lcNonPeriodic[17]_i', 'lcNonPeriodic[17]_z',\\\n",
    "                'lcNonPeriodic[18]_u', 'lcNonPeriodic[18]_g', 'lcNonPeriodic[18]_r', 'lcNonPeriodic[18]_i', 'lcNonPeriodic[18]_z',\\\n",
    "                'lcNonPeriodic[19]_u', 'lcNonPeriodic[19]_g', 'lcNonPeriodic[19]_r', 'lcNonPeriodic[19]_i', 'lcNonPeriodic[19]_z',\\\n",
    "                'lcNonPeriodic[20]_u', 'lcNonPeriodic[20]_g', 'lcNonPeriodic[20]_r', 'lcNonPeriodic[20]_i', 'lcNonPeriodic[20]_z',\\\n",
    "                'lcNonPeriodic[21]_u', 'lcNonPeriodic[21]_g', 'lcNonPeriodic[21]_r', 'lcNonPeriodic[21]_i', 'lcNonPeriodic[21]_z',\\\n",
    "                'lcNonPeriodic[22]_u', 'lcNonPeriodic[22]_g', 'lcNonPeriodic[22]_r', 'lcNonPeriodic[22]_i', 'lcNonPeriodic[22]_z',\\\n",
    "                'lcNonPeriodic[23]_u', 'lcNonPeriodic[23]_g', 'lcNonPeriodic[23]_r', 'lcNonPeriodic[23]_i', 'lcNonPeriodic[23]_z',\\\n",
    "                'lcNonPeriodic[24]_u', 'lcNonPeriodic[24]_g', 'lcNonPeriodic[24]_r', 'lcNonPeriodic[24]_i', 'lcNonPeriodic[24]_z',\\\n",
    "                'lcNonPeriodic[25]_u', 'lcNonPeriodic[25]_g', 'lcNonPeriodic[25]_r', 'lcNonPeriodic[25]_i', 'lcNonPeriodic[25]_z',\\\n",
    "                'lcNonPeriodic[26]_u', 'lcNonPeriodic[26]_g', 'lcNonPeriodic[26]_r', 'lcNonPeriodic[26]_i', 'lcNonPeriodic[26]_z',\\\n",
    "                'lcNonPeriodic[27]_u', 'lcNonPeriodic[27]_g', 'lcNonPeriodic[27]_r', 'lcNonPeriodic[27]_i', 'lcNonPeriodic[27]_z',\\\n",
    "                'lcNonPeriodic[28]_u', 'lcNonPeriodic[28]_g', 'lcNonPeriodic[28]_r', 'lcNonPeriodic[28]_i', 'lcNonPeriodic[28]_z',\\\n",
    "                'ebv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ab652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psFlux_u               129168\n",
       "psFlux_g               129168\n",
       "psFlux_r               129168\n",
       "psFlux_i               129168\n",
       "psFlux_z               129168\n",
       "bdFlux_u               129168\n",
       "bdFlux_g               129168\n",
       "bdFlux_r               129168\n",
       "bdFlux_i               129168\n",
       "bdFlux_z               129168\n",
       "psMag_u                129168\n",
       "psMag_g                129168\n",
       "psMag_r                129168\n",
       "psMag_i                129168\n",
       "psMag_z                129168\n",
       "bdMag_u                129168\n",
       "bdMag_g                129168\n",
       "bdMag_r                129168\n",
       "bdMag_i                129168\n",
       "bdMag_z                129168\n",
       "extendedness_u         129168\n",
       "extendedness_g         129168\n",
       "extendedness_r         129168\n",
       "extendedness_i         129168\n",
       "extendedness_z         129168\n",
       "stdColor_0             129168\n",
       "stdColor_1             129168\n",
       "stdColor_2             129168\n",
       "stdColor_3             129168\n",
       "class                  129168\n",
       "z                      129168\n",
       "lcPeriodic[0]_g        129168\n",
       "lcPeriodic[0]_r        129168\n",
       "lcPeriodic[0]_i        129168\n",
       "lcPeriodic[1]_g        129168\n",
       "lcPeriodic[1]_r        129168\n",
       "lcPeriodic[1]_i        129168\n",
       "lcPeriodic[2]_g        129168\n",
       "lcPeriodic[2]_r        129168\n",
       "lcPeriodic[2]_i        129168\n",
       "lcPeriodic[3]_g        129168\n",
       "lcPeriodic[3]_r        129168\n",
       "lcPeriodic[3]_i        129168\n",
       "lcPeriodic[4]_u        129168\n",
       "lcPeriodic[4]_g        129168\n",
       "lcPeriodic[4]_r        129168\n",
       "lcPeriodic[4]_i        129168\n",
       "lcPeriodic[4]_z        129168\n",
       "lcPeriodic[5]_u        129168\n",
       "lcPeriodic[5]_g        129168\n",
       "lcPeriodic[5]_r        129168\n",
       "lcPeriodic[5]_i        129168\n",
       "lcPeriodic[5]_z        129168\n",
       "lcPeriodic[6]_u        129168\n",
       "lcPeriodic[6]_g        129168\n",
       "lcPeriodic[6]_r        129168\n",
       "lcPeriodic[6]_i        129168\n",
       "lcPeriodic[6]_z        129168\n",
       "lcPeriodic[7]_u        129168\n",
       "lcPeriodic[7]_g        129168\n",
       "lcPeriodic[7]_r        129168\n",
       "lcPeriodic[7]_i        129168\n",
       "lcPeriodic[7]_z        129168\n",
       "lcPeriodic[8]_u        129168\n",
       "lcPeriodic[8]_g        129168\n",
       "lcPeriodic[8]_r        129168\n",
       "lcPeriodic[8]_i        129168\n",
       "lcPeriodic[8]_z        129168\n",
       "lcPeriodic[9]_u        129168\n",
       "lcPeriodic[9]_g        129168\n",
       "lcPeriodic[9]_r        129168\n",
       "lcPeriodic[9]_i        129168\n",
       "lcPeriodic[9]_z        129168\n",
       "lcPeriodic[10]_u       129168\n",
       "lcPeriodic[10]_g       129168\n",
       "lcPeriodic[10]_r       129168\n",
       "lcPeriodic[10]_i       129168\n",
       "lcPeriodic[10]_z       129168\n",
       "lcPeriodic[11]_u       129168\n",
       "lcPeriodic[11]_g       129168\n",
       "lcPeriodic[11]_r       129168\n",
       "lcPeriodic[11]_i       129168\n",
       "lcPeriodic[11]_z       129168\n",
       "lcPeriodic[12]_u       129168\n",
       "lcPeriodic[12]_g       129168\n",
       "lcPeriodic[12]_r       129168\n",
       "lcPeriodic[12]_i       129168\n",
       "lcPeriodic[12]_z       129168\n",
       "lcPeriodic[13]_u       129168\n",
       "lcPeriodic[13]_g       129168\n",
       "lcPeriodic[13]_r       129168\n",
       "lcPeriodic[13]_i       129168\n",
       "lcPeriodic[13]_z       129168\n",
       "lcPeriodic[14]_u       129168\n",
       "lcPeriodic[14]_g       129168\n",
       "lcPeriodic[14]_r       129168\n",
       "lcPeriodic[14]_i       129168\n",
       "lcPeriodic[14]_z       129168\n",
       "lcPeriodic[15]_u       129168\n",
       "lcPeriodic[15]_g       129168\n",
       "lcPeriodic[15]_r       129168\n",
       "lcPeriodic[15]_i       129168\n",
       "lcPeriodic[15]_z       129168\n",
       "lcPeriodic[16]_u       129168\n",
       "lcPeriodic[16]_g       129168\n",
       "lcPeriodic[16]_r       129168\n",
       "lcPeriodic[16]_i       129168\n",
       "lcPeriodic[16]_z       129168\n",
       "lcPeriodic[17]_u       129168\n",
       "lcPeriodic[17]_g       129168\n",
       "lcPeriodic[17]_r       129168\n",
       "lcPeriodic[17]_i       129168\n",
       "lcPeriodic[17]_z       129168\n",
       "lcPeriodic[18]_u       129168\n",
       "lcPeriodic[18]_g       129168\n",
       "lcPeriodic[18]_r       129168\n",
       "lcPeriodic[18]_i       129168\n",
       "lcPeriodic[18]_z       129168\n",
       "lcPeriodic[19]_u       129168\n",
       "lcPeriodic[19]_g       129168\n",
       "lcPeriodic[19]_r       129168\n",
       "lcPeriodic[19]_i       129168\n",
       "lcPeriodic[19]_z       129168\n",
       "lcPeriodic[20]_u       129168\n",
       "lcPeriodic[20]_g       129168\n",
       "lcPeriodic[20]_r       129168\n",
       "lcPeriodic[20]_i       129168\n",
       "lcPeriodic[20]_z       129168\n",
       "lcPeriodic[21]_u       129168\n",
       "lcPeriodic[21]_g       129168\n",
       "lcPeriodic[21]_r       129168\n",
       "lcPeriodic[21]_i       129168\n",
       "lcPeriodic[21]_z       129168\n",
       "lcPeriodic[22]_u       129168\n",
       "lcPeriodic[22]_g       129168\n",
       "lcPeriodic[22]_r       129168\n",
       "lcPeriodic[22]_i       129168\n",
       "lcPeriodic[22]_z       129168\n",
       "lcPeriodic[23]_u       129168\n",
       "lcPeriodic[23]_g       129168\n",
       "lcPeriodic[23]_r       129168\n",
       "lcPeriodic[23]_i       129168\n",
       "lcPeriodic[23]_z       129168\n",
       "lcPeriodic[24]_u       129168\n",
       "lcPeriodic[24]_g       129168\n",
       "lcPeriodic[24]_r       129168\n",
       "lcPeriodic[24]_i       129168\n",
       "lcPeriodic[24]_z       129168\n",
       "lcPeriodic[25]_u       129168\n",
       "lcPeriodic[25]_g       129168\n",
       "lcPeriodic[25]_r       129168\n",
       "lcPeriodic[25]_i       129168\n",
       "lcPeriodic[25]_z       129168\n",
       "lcPeriodic[26]_u       129168\n",
       "lcPeriodic[26]_g       129168\n",
       "lcPeriodic[26]_r       129168\n",
       "lcPeriodic[26]_i       129168\n",
       "lcPeriodic[26]_z       129168\n",
       "lcPeriodic[27]_u       129168\n",
       "lcPeriodic[27]_g       129168\n",
       "lcPeriodic[27]_r       129168\n",
       "lcPeriodic[27]_i       129168\n",
       "lcPeriodic[27]_z       129168\n",
       "lcPeriodic[28]_u       129168\n",
       "lcPeriodic[28]_g       129168\n",
       "lcPeriodic[28]_r       129168\n",
       "lcPeriodic[28]_i       129168\n",
       "lcPeriodic[28]_z       129168\n",
       "lcPeriodic[29]_u       129168\n",
       "lcPeriodic[29]_g       129168\n",
       "lcPeriodic[29]_r       129168\n",
       "lcPeriodic[29]_i       129168\n",
       "lcPeriodic[29]_z       129168\n",
       "lcPeriodic[30]_u       129168\n",
       "lcPeriodic[30]_g       129168\n",
       "lcPeriodic[30]_r       129168\n",
       "lcPeriodic[30]_i       129168\n",
       "lcPeriodic[30]_z       129168\n",
       "lcPeriodic[31]_u       129168\n",
       "lcPeriodic[31]_g       129168\n",
       "lcPeriodic[31]_r       129168\n",
       "lcPeriodic[31]_i       129168\n",
       "lcPeriodic[31]_z       129168\n",
       "lcPeriodic[32]_u       129168\n",
       "lcPeriodic[32]_g       129168\n",
       "lcPeriodic[32]_r       129168\n",
       "lcPeriodic[32]_i       129168\n",
       "lcPeriodic[32]_z       129168\n",
       "lcNonPeriodic[0]_u     129168\n",
       "lcNonPeriodic[0]_g     129168\n",
       "lcNonPeriodic[0]_r     129168\n",
       "lcNonPeriodic[0]_i     129168\n",
       "lcNonPeriodic[0]_z     129168\n",
       "lcNonPeriodic[1]_u     129168\n",
       "lcNonPeriodic[1]_g     129168\n",
       "lcNonPeriodic[1]_r     129168\n",
       "lcNonPeriodic[1]_i     129168\n",
       "lcNonPeriodic[1]_z     129168\n",
       "lcNonPeriodic[2]_u     129168\n",
       "lcNonPeriodic[2]_g     129168\n",
       "lcNonPeriodic[2]_r     129168\n",
       "lcNonPeriodic[2]_i     129168\n",
       "lcNonPeriodic[2]_z     129168\n",
       "lcNonPeriodic[3]_u     129168\n",
       "lcNonPeriodic[3]_g     129168\n",
       "lcNonPeriodic[3]_r     129168\n",
       "lcNonPeriodic[3]_i     129168\n",
       "lcNonPeriodic[3]_z     129168\n",
       "lcNonPeriodic[4]_u     129168\n",
       "lcNonPeriodic[4]_g     129168\n",
       "lcNonPeriodic[4]_r     129168\n",
       "lcNonPeriodic[4]_i     129168\n",
       "lcNonPeriodic[4]_z     129168\n",
       "lcNonPeriodic[5]_u     129168\n",
       "lcNonPeriodic[5]_g     129168\n",
       "lcNonPeriodic[5]_r     129168\n",
       "lcNonPeriodic[5]_i     129168\n",
       "lcNonPeriodic[5]_z     129168\n",
       "lcNonPeriodic[6]_u     129168\n",
       "lcNonPeriodic[6]_g     129168\n",
       "lcNonPeriodic[6]_r     129168\n",
       "lcNonPeriodic[6]_i     129168\n",
       "lcNonPeriodic[6]_z     129168\n",
       "lcNonPeriodic[7]_u     129168\n",
       "lcNonPeriodic[7]_g     129168\n",
       "lcNonPeriodic[7]_r     129168\n",
       "lcNonPeriodic[7]_i     129168\n",
       "lcNonPeriodic[7]_z     129168\n",
       "lcNonPeriodic[8]_u     129168\n",
       "lcNonPeriodic[8]_g     129168\n",
       "lcNonPeriodic[8]_r     129168\n",
       "lcNonPeriodic[8]_i     129168\n",
       "lcNonPeriodic[8]_z     129168\n",
       "lcNonPeriodic[9]_u     129168\n",
       "lcNonPeriodic[9]_g     129168\n",
       "lcNonPeriodic[9]_r     129168\n",
       "lcNonPeriodic[9]_i     129168\n",
       "lcNonPeriodic[9]_z     129168\n",
       "lcNonPeriodic[10]_u    129168\n",
       "lcNonPeriodic[10]_g    129168\n",
       "lcNonPeriodic[10]_r    129168\n",
       "lcNonPeriodic[10]_i    129168\n",
       "lcNonPeriodic[10]_z    129168\n",
       "lcNonPeriodic[11]_u    129168\n",
       "lcNonPeriodic[11]_g    129168\n",
       "lcNonPeriodic[11]_r    129168\n",
       "lcNonPeriodic[11]_i    129168\n",
       "lcNonPeriodic[11]_z    129168\n",
       "lcNonPeriodic[12]_u    129168\n",
       "lcNonPeriodic[12]_g    129168\n",
       "lcNonPeriodic[12]_r    129168\n",
       "lcNonPeriodic[12]_i    129168\n",
       "lcNonPeriodic[12]_z    129168\n",
       "lcNonPeriodic[13]_u    129168\n",
       "lcNonPeriodic[13]_g    129168\n",
       "lcNonPeriodic[13]_r    129168\n",
       "lcNonPeriodic[13]_i    129168\n",
       "lcNonPeriodic[13]_z    129168\n",
       "lcNonPeriodic[14]_u    129168\n",
       "lcNonPeriodic[14]_g    129168\n",
       "lcNonPeriodic[14]_r    129168\n",
       "lcNonPeriodic[14]_i    129168\n",
       "lcNonPeriodic[14]_z    129168\n",
       "lcNonPeriodic[15]_u    129168\n",
       "lcNonPeriodic[15]_g    129168\n",
       "lcNonPeriodic[15]_r    129168\n",
       "lcNonPeriodic[15]_i    129168\n",
       "lcNonPeriodic[15]_z    129168\n",
       "lcNonPeriodic[16]_u    129168\n",
       "lcNonPeriodic[16]_g    129168\n",
       "lcNonPeriodic[16]_r    129168\n",
       "lcNonPeriodic[16]_i    129168\n",
       "lcNonPeriodic[16]_z    129168\n",
       "lcNonPeriodic[17]_u    129168\n",
       "lcNonPeriodic[17]_g    129168\n",
       "lcNonPeriodic[17]_r    129168\n",
       "lcNonPeriodic[17]_i    129168\n",
       "lcNonPeriodic[17]_z    129168\n",
       "lcNonPeriodic[18]_u    129168\n",
       "lcNonPeriodic[18]_g    129168\n",
       "lcNonPeriodic[18]_r    129168\n",
       "lcNonPeriodic[18]_i    129168\n",
       "lcNonPeriodic[18]_z    129168\n",
       "lcNonPeriodic[19]_u    129168\n",
       "lcNonPeriodic[19]_g    129168\n",
       "lcNonPeriodic[19]_r    129168\n",
       "lcNonPeriodic[19]_i    129168\n",
       "lcNonPeriodic[19]_z    129168\n",
       "lcNonPeriodic[20]_u    129168\n",
       "lcNonPeriodic[20]_g    129168\n",
       "lcNonPeriodic[20]_r    129168\n",
       "lcNonPeriodic[20]_i    129168\n",
       "lcNonPeriodic[20]_z    129168\n",
       "lcNonPeriodic[21]_u    129168\n",
       "lcNonPeriodic[21]_g    129168\n",
       "lcNonPeriodic[21]_r    129168\n",
       "lcNonPeriodic[21]_i    129168\n",
       "lcNonPeriodic[21]_z    129168\n",
       "lcNonPeriodic[22]_u    129168\n",
       "lcNonPeriodic[22]_g    129168\n",
       "lcNonPeriodic[22]_r    129168\n",
       "lcNonPeriodic[22]_i    129168\n",
       "lcNonPeriodic[22]_z    129168\n",
       "lcNonPeriodic[23]_u    129168\n",
       "lcNonPeriodic[23]_g    129168\n",
       "lcNonPeriodic[23]_r    129168\n",
       "lcNonPeriodic[23]_i    129168\n",
       "lcNonPeriodic[23]_z    129168\n",
       "lcNonPeriodic[24]_u    129168\n",
       "lcNonPeriodic[24]_g    129168\n",
       "lcNonPeriodic[24]_r    129168\n",
       "lcNonPeriodic[24]_i    129168\n",
       "lcNonPeriodic[24]_z    129168\n",
       "lcNonPeriodic[25]_u    129168\n",
       "lcNonPeriodic[25]_g    129168\n",
       "lcNonPeriodic[25]_r    129168\n",
       "lcNonPeriodic[25]_i    129168\n",
       "lcNonPeriodic[25]_z    129168\n",
       "lcNonPeriodic[26]_u    129168\n",
       "lcNonPeriodic[26]_g    129168\n",
       "lcNonPeriodic[26]_r    129168\n",
       "lcNonPeriodic[26]_i    129168\n",
       "lcNonPeriodic[26]_z    129168\n",
       "lcNonPeriodic[27]_u    129168\n",
       "lcNonPeriodic[27]_g    129168\n",
       "lcNonPeriodic[27]_r    129168\n",
       "lcNonPeriodic[27]_i    129168\n",
       "lcNonPeriodic[27]_z    129168\n",
       "lcNonPeriodic[28]_u    129168\n",
       "lcNonPeriodic[28]_g    129168\n",
       "lcNonPeriodic[28]_r    129168\n",
       "lcNonPeriodic[28]_i    129168\n",
       "lcNonPeriodic[28]_z    129168\n",
       "ebv                    129168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_df_colvar = object_df_new[colvar_list].dropna()\n",
    "object_df_colvar.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a2434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psFlux_u</th>\n",
       "      <th>psFlux_g</th>\n",
       "      <th>psFlux_r</th>\n",
       "      <th>psFlux_i</th>\n",
       "      <th>psFlux_z</th>\n",
       "      <th>bdFlux_u</th>\n",
       "      <th>bdFlux_g</th>\n",
       "      <th>bdFlux_r</th>\n",
       "      <th>bdFlux_i</th>\n",
       "      <th>bdFlux_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lcNonPeriodic[27]_g</th>\n",
       "      <th>lcNonPeriodic[27]_r</th>\n",
       "      <th>lcNonPeriodic[27]_i</th>\n",
       "      <th>lcNonPeriodic[27]_z</th>\n",
       "      <th>lcNonPeriodic[28]_u</th>\n",
       "      <th>lcNonPeriodic[28]_g</th>\n",
       "      <th>lcNonPeriodic[28]_r</th>\n",
       "      <th>lcNonPeriodic[28]_i</th>\n",
       "      <th>lcNonPeriodic[28]_z</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objectId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0271388</th>\n",
       "      <td>26160.979422</td>\n",
       "      <td>294519.269238</td>\n",
       "      <td>1.106956e+06</td>\n",
       "      <td>2.057265e+06</td>\n",
       "      <td>2.982015e+06</td>\n",
       "      <td>26436.085624</td>\n",
       "      <td>294967.193358</td>\n",
       "      <td>1.116087e+06</td>\n",
       "      <td>2.086941e+06</td>\n",
       "      <td>3.014907e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032109</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.062576</td>\n",
       "      <td>0.324707</td>\n",
       "      <td>8.555394</td>\n",
       "      <td>2.888606</td>\n",
       "      <td>0.961880</td>\n",
       "      <td>1.213456</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>0.023638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0271389</th>\n",
       "      <td>48849.324901</td>\n",
       "      <td>77854.298779</td>\n",
       "      <td>7.187044e+04</td>\n",
       "      <td>6.333212e+04</td>\n",
       "      <td>5.460789e+04</td>\n",
       "      <td>49320.945937</td>\n",
       "      <td>78824.057129</td>\n",
       "      <td>7.230736e+04</td>\n",
       "      <td>6.410164e+04</td>\n",
       "      <td>5.491608e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242187</td>\n",
       "      <td>0.034497</td>\n",
       "      <td>0.210657</td>\n",
       "      <td>0.145120</td>\n",
       "      <td>4.915713</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>1.949530</td>\n",
       "      <td>0.051217</td>\n",
       "      <td>0.686231</td>\n",
       "      <td>0.027264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0271390</th>\n",
       "      <td>58226.877642</td>\n",
       "      <td>196208.333415</td>\n",
       "      <td>3.151411e+05</td>\n",
       "      <td>3.634721e+05</td>\n",
       "      <td>3.904259e+05</td>\n",
       "      <td>57822.261087</td>\n",
       "      <td>193323.677945</td>\n",
       "      <td>3.125762e+05</td>\n",
       "      <td>3.612207e+05</td>\n",
       "      <td>3.864206e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.057029</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.975324</td>\n",
       "      <td>5.251484</td>\n",
       "      <td>6.415285</td>\n",
       "      <td>0.447885</td>\n",
       "      <td>1.378181</td>\n",
       "      <td>0.039193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0271391</th>\n",
       "      <td>56604.337841</td>\n",
       "      <td>137549.637098</td>\n",
       "      <td>1.816154e+05</td>\n",
       "      <td>1.948576e+05</td>\n",
       "      <td>1.999601e+05</td>\n",
       "      <td>56216.171259</td>\n",
       "      <td>135464.359811</td>\n",
       "      <td>1.799253e+05</td>\n",
       "      <td>1.923424e+05</td>\n",
       "      <td>1.964709e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055463</td>\n",
       "      <td>0.165852</td>\n",
       "      <td>0.318518</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.441824</td>\n",
       "      <td>2.040820</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>5.699177</td>\n",
       "      <td>0.033451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0271393</th>\n",
       "      <td>14996.967510</td>\n",
       "      <td>97006.815709</td>\n",
       "      <td>2.041051e+05</td>\n",
       "      <td>2.577554e+05</td>\n",
       "      <td>2.938509e+05</td>\n",
       "      <td>14858.082736</td>\n",
       "      <td>95621.213064</td>\n",
       "      <td>2.021947e+05</td>\n",
       "      <td>2.551368e+05</td>\n",
       "      <td>2.916749e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034438</td>\n",
       "      <td>0.024726</td>\n",
       "      <td>0.051057</td>\n",
       "      <td>0.069665</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>3.520566</td>\n",
       "      <td>2.222488</td>\n",
       "      <td>1.332720</td>\n",
       "      <td>0.947977</td>\n",
       "      <td>0.029568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468017</th>\n",
       "      <td>17994.203485</td>\n",
       "      <td>27268.917052</td>\n",
       "      <td>3.142641e+04</td>\n",
       "      <td>4.412361e+04</td>\n",
       "      <td>6.025053e+04</td>\n",
       "      <td>20141.763745</td>\n",
       "      <td>31723.140172</td>\n",
       "      <td>3.907511e+04</td>\n",
       "      <td>5.721970e+04</td>\n",
       "      <td>7.828750e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.078444</td>\n",
       "      <td>0.062067</td>\n",
       "      <td>0.084517</td>\n",
       "      <td>87.726218</td>\n",
       "      <td>40.008760</td>\n",
       "      <td>2.298066</td>\n",
       "      <td>4.310347</td>\n",
       "      <td>2.627439</td>\n",
       "      <td>0.085374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468018</th>\n",
       "      <td>58302.017211</td>\n",
       "      <td>61925.019907</td>\n",
       "      <td>6.830879e+04</td>\n",
       "      <td>6.212039e+04</td>\n",
       "      <td>6.179836e+04</td>\n",
       "      <td>57662.689860</td>\n",
       "      <td>62019.204528</td>\n",
       "      <td>6.851232e+04</td>\n",
       "      <td>6.237270e+04</td>\n",
       "      <td>6.194137e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.024527</td>\n",
       "      <td>117.796541</td>\n",
       "      <td>15.694906</td>\n",
       "      <td>112.661792</td>\n",
       "      <td>47.760664</td>\n",
       "      <td>13.566240</td>\n",
       "      <td>0.082823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468019</th>\n",
       "      <td>28501.385092</td>\n",
       "      <td>32930.588107</td>\n",
       "      <td>3.690130e+04</td>\n",
       "      <td>5.006247e+04</td>\n",
       "      <td>5.114888e+04</td>\n",
       "      <td>28380.031107</td>\n",
       "      <td>33401.401023</td>\n",
       "      <td>3.677471e+04</td>\n",
       "      <td>5.005832e+04</td>\n",
       "      <td>5.108732e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232625</td>\n",
       "      <td>0.081062</td>\n",
       "      <td>0.066099</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>11.044441</td>\n",
       "      <td>2.410207</td>\n",
       "      <td>20.050749</td>\n",
       "      <td>22.582279</td>\n",
       "      <td>423.371702</td>\n",
       "      <td>0.093687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468020</th>\n",
       "      <td>17663.977528</td>\n",
       "      <td>25333.897183</td>\n",
       "      <td>3.227447e+04</td>\n",
       "      <td>3.182550e+04</td>\n",
       "      <td>4.002968e+04</td>\n",
       "      <td>17754.149854</td>\n",
       "      <td>25769.644397</td>\n",
       "      <td>3.277461e+04</td>\n",
       "      <td>3.282450e+04</td>\n",
       "      <td>4.067704e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.017833</td>\n",
       "      <td>0.046360</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>246.515970</td>\n",
       "      <td>319.834034</td>\n",
       "      <td>446.851609</td>\n",
       "      <td>82.040181</td>\n",
       "      <td>742.588577</td>\n",
       "      <td>0.132956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468021</th>\n",
       "      <td>25982.198589</td>\n",
       "      <td>31090.684004</td>\n",
       "      <td>3.381537e+04</td>\n",
       "      <td>4.482806e+04</td>\n",
       "      <td>4.863596e+04</td>\n",
       "      <td>26002.322269</td>\n",
       "      <td>31301.339295</td>\n",
       "      <td>3.367639e+04</td>\n",
       "      <td>4.461995e+04</td>\n",
       "      <td>4.856614e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>0.020922</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.046209</td>\n",
       "      <td>5.759539</td>\n",
       "      <td>14.565944</td>\n",
       "      <td>46.401780</td>\n",
       "      <td>88.653421</td>\n",
       "      <td>9.151643</td>\n",
       "      <td>0.073914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129168 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              psFlux_u       psFlux_g      psFlux_r      psFlux_i  \\\n",
       "objectId                                                            \n",
       "0271388   26160.979422  294519.269238  1.106956e+06  2.057265e+06   \n",
       "0271389   48849.324901   77854.298779  7.187044e+04  6.333212e+04   \n",
       "0271390   58226.877642  196208.333415  3.151411e+05  3.634721e+05   \n",
       "0271391   56604.337841  137549.637098  1.816154e+05  1.948576e+05   \n",
       "0271393   14996.967510   97006.815709  2.041051e+05  2.577554e+05   \n",
       "...                ...            ...           ...           ...   \n",
       "1468017   17994.203485   27268.917052  3.142641e+04  4.412361e+04   \n",
       "1468018   58302.017211   61925.019907  6.830879e+04  6.212039e+04   \n",
       "1468019   28501.385092   32930.588107  3.690130e+04  5.006247e+04   \n",
       "1468020   17663.977528   25333.897183  3.227447e+04  3.182550e+04   \n",
       "1468021   25982.198589   31090.684004  3.381537e+04  4.482806e+04   \n",
       "\n",
       "              psFlux_z      bdFlux_u       bdFlux_g      bdFlux_r  \\\n",
       "objectId                                                            \n",
       "0271388   2.982015e+06  26436.085624  294967.193358  1.116087e+06   \n",
       "0271389   5.460789e+04  49320.945937   78824.057129  7.230736e+04   \n",
       "0271390   3.904259e+05  57822.261087  193323.677945  3.125762e+05   \n",
       "0271391   1.999601e+05  56216.171259  135464.359811  1.799253e+05   \n",
       "0271393   2.938509e+05  14858.082736   95621.213064  2.021947e+05   \n",
       "...                ...           ...            ...           ...   \n",
       "1468017   6.025053e+04  20141.763745   31723.140172  3.907511e+04   \n",
       "1468018   6.179836e+04  57662.689860   62019.204528  6.851232e+04   \n",
       "1468019   5.114888e+04  28380.031107   33401.401023  3.677471e+04   \n",
       "1468020   4.002968e+04  17754.149854   25769.644397  3.277461e+04   \n",
       "1468021   4.863596e+04  26002.322269   31301.339295  3.367639e+04   \n",
       "\n",
       "              bdFlux_i      bdFlux_z  ...  lcNonPeriodic[27]_g  \\\n",
       "objectId                              ...                        \n",
       "0271388   2.086941e+06  3.014907e+06  ...             0.032109   \n",
       "0271389   6.410164e+04  5.491608e+04  ...             0.242187   \n",
       "0271390   3.612207e+05  3.864206e+05  ...             0.018121   \n",
       "0271391   1.923424e+05  1.964709e+05  ...             0.055463   \n",
       "0271393   2.551368e+05  2.916749e+05  ...             0.034438   \n",
       "...                ...           ...  ...                  ...   \n",
       "1468017   5.721970e+04  7.828750e+04  ...             0.022847   \n",
       "1468018   6.237270e+04  6.194137e+04  ...             0.051148   \n",
       "1468019   5.005832e+04  5.108732e+04  ...             0.232625   \n",
       "1468020   3.282450e+04  4.067704e+04  ...             0.024506   \n",
       "1468021   4.461995e+04  4.856614e+04  ...             0.053163   \n",
       "\n",
       "          lcNonPeriodic[27]_r  lcNonPeriodic[27]_i  lcNonPeriodic[27]_z  \\\n",
       "objectId                                                                  \n",
       "0271388              0.030674             0.062576             0.324707   \n",
       "0271389              0.034497             0.210657             0.145120   \n",
       "0271390              0.008570             0.057029             0.042912   \n",
       "0271391              0.165852             0.318518             0.027876   \n",
       "0271393              0.024726             0.051057             0.069665   \n",
       "...                       ...                  ...                  ...   \n",
       "1468017              0.078444             0.062067             0.084517   \n",
       "1468018              0.012555             0.017048             0.024527   \n",
       "1468019              0.081062             0.066099             0.012657   \n",
       "1468020              0.017833             0.046360             0.010816   \n",
       "1468021              0.020922             0.010311             0.046209   \n",
       "\n",
       "          lcNonPeriodic[28]_u  lcNonPeriodic[28]_g  lcNonPeriodic[28]_r  \\\n",
       "objectId                                                                  \n",
       "0271388              8.555394             2.888606             0.961880   \n",
       "0271389              4.915713             0.018316             1.949530   \n",
       "0271390              0.975324             5.251484             6.415285   \n",
       "0271391              0.441824             2.040820             0.051330   \n",
       "0271393              0.059122             3.520566             2.222488   \n",
       "...                       ...                  ...                  ...   \n",
       "1468017             87.726218            40.008760             2.298066   \n",
       "1468018            117.796541            15.694906           112.661792   \n",
       "1468019             11.044441             2.410207            20.050749   \n",
       "1468020            246.515970           319.834034           446.851609   \n",
       "1468021              5.759539            14.565944            46.401780   \n",
       "\n",
       "          lcNonPeriodic[28]_i  lcNonPeriodic[28]_z       ebv  \n",
       "objectId                                                      \n",
       "0271388              1.213456             0.034117  0.023638  \n",
       "0271389              0.051217             0.686231  0.027264  \n",
       "0271390              0.447885             1.378181  0.039193  \n",
       "0271391              0.018316             5.699177  0.033451  \n",
       "0271393              1.332720             0.947977  0.029568  \n",
       "...                       ...                  ...       ...  \n",
       "1468017              4.310347             2.627439  0.085374  \n",
       "1468018             47.760664            13.566240  0.082823  \n",
       "1468019             22.582279           423.371702  0.093687  \n",
       "1468020             82.040181           742.588577  0.132956  \n",
       "1468021             88.653421             9.151643  0.073914  \n",
       "\n",
       "[129168 rows x 334 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_df_colvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94deb1",
   "metadata": {},
   "source": [
    "So, now we have object_df_colvar which contains 129k objects with colors and variability.\n",
    "\n",
    "We'll analyze this data set in the context of autoencoders. Specifically, trying to see how well we can recontruct the inputs using the smallest possible bottleneck.\n",
    "\n",
    "Write these out to a file so that we can reuse them later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7040d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df_colvar.to_parquet('object_df_colvar.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07eaa0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    65973\n",
       "2.0    34729\n",
       "1.0    28466\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(object_df_colvar['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618961",
   "metadata": {},
   "source": [
    "## Data Processing <a class=\"anchor\" id=\"four\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24666461",
   "metadata": {},
   "source": [
    "Data processing involves converting unprocessed data into a format that is appropriate for analysis. This encompasses several stages, such as data cleansing, data integration, data transformation, data reduction, and data visualization, with the objective of making the data more usable and insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b2d56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129168, 333)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(129168,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psFlux_u</th>\n",
       "      <th>psFlux_g</th>\n",
       "      <th>psFlux_r</th>\n",
       "      <th>psFlux_i</th>\n",
       "      <th>psFlux_z</th>\n",
       "      <th>bdFlux_u</th>\n",
       "      <th>bdFlux_g</th>\n",
       "      <th>bdFlux_r</th>\n",
       "      <th>bdFlux_i</th>\n",
       "      <th>bdFlux_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lcNonPeriodic[27]_g</th>\n",
       "      <th>lcNonPeriodic[27]_r</th>\n",
       "      <th>lcNonPeriodic[27]_i</th>\n",
       "      <th>lcNonPeriodic[27]_z</th>\n",
       "      <th>lcNonPeriodic[28]_u</th>\n",
       "      <th>lcNonPeriodic[28]_g</th>\n",
       "      <th>lcNonPeriodic[28]_r</th>\n",
       "      <th>lcNonPeriodic[28]_i</th>\n",
       "      <th>lcNonPeriodic[28]_z</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>1.291680e+05</td>\n",
       "      <td>129168.000000</td>\n",
       "      <td>129168.000000</td>\n",
       "      <td>129168.000000</td>\n",
       "      <td>129168.000000</td>\n",
       "      <td>129168.000000</td>\n",
       "      <td>129168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.699303e+04</td>\n",
       "      <td>1.300256e+05</td>\n",
       "      <td>2.631957e+05</td>\n",
       "      <td>3.189598e+05</td>\n",
       "      <td>3.862048e+05</td>\n",
       "      <td>3.783521e+04</td>\n",
       "      <td>1.332971e+05</td>\n",
       "      <td>2.362310e+05</td>\n",
       "      <td>3.083472e+05</td>\n",
       "      <td>3.789396e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075160e-01</td>\n",
       "      <td>1.057642e-01</td>\n",
       "      <td>1.068375e-01</td>\n",
       "      <td>1.137659e-01</td>\n",
       "      <td>1155.222216</td>\n",
       "      <td>217.155013</td>\n",
       "      <td>229.138964</td>\n",
       "      <td>228.182959</td>\n",
       "      <td>673.288631</td>\n",
       "      <td>0.047703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.791017e+04</td>\n",
       "      <td>2.823913e+05</td>\n",
       "      <td>1.034511e+07</td>\n",
       "      <td>5.711507e+05</td>\n",
       "      <td>6.870780e+05</td>\n",
       "      <td>9.939326e+04</td>\n",
       "      <td>2.864658e+05</td>\n",
       "      <td>4.331223e+05</td>\n",
       "      <td>5.141858e+05</td>\n",
       "      <td>6.366625e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.622182e-01</td>\n",
       "      <td>2.481034e-01</td>\n",
       "      <td>2.550262e-01</td>\n",
       "      <td>2.934939e-01</td>\n",
       "      <td>4352.481898</td>\n",
       "      <td>1424.813117</td>\n",
       "      <td>1225.809878</td>\n",
       "      <td>1217.650916</td>\n",
       "      <td>3295.799497</td>\n",
       "      <td>0.028767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.392692e-01</td>\n",
       "      <td>2.381211e+02</td>\n",
       "      <td>1.068223e+03</td>\n",
       "      <td>1.253822e+03</td>\n",
       "      <td>3.721540e+02</td>\n",
       "      <td>1.352985e-01</td>\n",
       "      <td>2.503990e+02</td>\n",
       "      <td>5.916977e+02</td>\n",
       "      <td>8.053055e+02</td>\n",
       "      <td>1.601458e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.173041e+03</td>\n",
       "      <td>6.871549e+03</td>\n",
       "      <td>1.159186e+04</td>\n",
       "      <td>1.557859e+04</td>\n",
       "      <td>1.845911e+04</td>\n",
       "      <td>2.822304e+03</td>\n",
       "      <td>7.895621e+03</td>\n",
       "      <td>1.410113e+04</td>\n",
       "      <td>1.879127e+04</td>\n",
       "      <td>2.256770e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481255e-02</td>\n",
       "      <td>1.236906e-02</td>\n",
       "      <td>1.018621e-02</td>\n",
       "      <td>1.061997e-02</td>\n",
       "      <td>1.961054</td>\n",
       "      <td>0.895356</td>\n",
       "      <td>0.534148</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>1.529153</td>\n",
       "      <td>0.027825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.065597e+03</td>\n",
       "      <td>2.574882e+04</td>\n",
       "      <td>5.308449e+04</td>\n",
       "      <td>7.692428e+04</td>\n",
       "      <td>8.891001e+04</td>\n",
       "      <td>7.663477e+03</td>\n",
       "      <td>2.838897e+04</td>\n",
       "      <td>6.229997e+04</td>\n",
       "      <td>9.207415e+04</td>\n",
       "      <td>1.100885e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.940459e-02</td>\n",
       "      <td>2.694377e-02</td>\n",
       "      <td>2.478391e-02</td>\n",
       "      <td>2.726769e-02</td>\n",
       "      <td>13.525332</td>\n",
       "      <td>5.680325</td>\n",
       "      <td>3.321019</td>\n",
       "      <td>4.004215</td>\n",
       "      <td>7.306155</td>\n",
       "      <td>0.035368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.781734e+04</td>\n",
       "      <td>1.092024e+05</td>\n",
       "      <td>2.281059e+05</td>\n",
       "      <td>3.392031e+05</td>\n",
       "      <td>4.226606e+05</td>\n",
       "      <td>2.857108e+04</td>\n",
       "      <td>1.113382e+05</td>\n",
       "      <td>2.386484e+05</td>\n",
       "      <td>3.558084e+05</td>\n",
       "      <td>4.461221e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.515404e-02</td>\n",
       "      <td>9.895668e-02</td>\n",
       "      <td>9.447166e-02</td>\n",
       "      <td>8.517200e-02</td>\n",
       "      <td>205.325630</td>\n",
       "      <td>87.170420</td>\n",
       "      <td>97.600018</td>\n",
       "      <td>84.233117</td>\n",
       "      <td>59.262192</td>\n",
       "      <td>0.062735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.037682e+06</td>\n",
       "      <td>6.931127e+06</td>\n",
       "      <td>3.714715e+09</td>\n",
       "      <td>9.697823e+06</td>\n",
       "      <td>1.408038e+07</td>\n",
       "      <td>6.047477e+06</td>\n",
       "      <td>6.240139e+06</td>\n",
       "      <td>9.925469e+06</td>\n",
       "      <td>1.208203e+07</td>\n",
       "      <td>1.476919e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436499e+01</td>\n",
       "      <td>5.370183e+00</td>\n",
       "      <td>6.006445e+00</td>\n",
       "      <td>7.383428e+00</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>0.527862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           psFlux_u      psFlux_g      psFlux_r      psFlux_i      psFlux_z  \\\n",
       "count  1.291680e+05  1.291680e+05  1.291680e+05  1.291680e+05  1.291680e+05   \n",
       "mean   3.699303e+04  1.300256e+05  2.631957e+05  3.189598e+05  3.862048e+05   \n",
       "std    9.791017e+04  2.823913e+05  1.034511e+07  5.711507e+05  6.870780e+05   \n",
       "min    8.392692e-01  2.381211e+02  1.068223e+03  1.253822e+03  3.721540e+02   \n",
       "25%    2.173041e+03  6.871549e+03  1.159186e+04  1.557859e+04  1.845911e+04   \n",
       "50%    7.065597e+03  2.574882e+04  5.308449e+04  7.692428e+04  8.891001e+04   \n",
       "75%    2.781734e+04  1.092024e+05  2.281059e+05  3.392031e+05  4.226606e+05   \n",
       "max    6.037682e+06  6.931127e+06  3.714715e+09  9.697823e+06  1.408038e+07   \n",
       "\n",
       "           bdFlux_u      bdFlux_g      bdFlux_r      bdFlux_i      bdFlux_z  \\\n",
       "count  1.291680e+05  1.291680e+05  1.291680e+05  1.291680e+05  1.291680e+05   \n",
       "mean   3.783521e+04  1.332971e+05  2.362310e+05  3.083472e+05  3.789396e+05   \n",
       "std    9.939326e+04  2.864658e+05  4.331223e+05  5.141858e+05  6.366625e+05   \n",
       "min    1.352985e-01  2.503990e+02  5.916977e+02  8.053055e+02  1.601458e+02   \n",
       "25%    2.822304e+03  7.895621e+03  1.410113e+04  1.879127e+04  2.256770e+04   \n",
       "50%    7.663477e+03  2.838897e+04  6.229997e+04  9.207415e+04  1.100885e+05   \n",
       "75%    2.857108e+04  1.113382e+05  2.386484e+05  3.558084e+05  4.461221e+05   \n",
       "max    6.047477e+06  6.240139e+06  9.925469e+06  1.208203e+07  1.476919e+07   \n",
       "\n",
       "       ...  lcNonPeriodic[27]_g  lcNonPeriodic[27]_r  lcNonPeriodic[27]_i  \\\n",
       "count  ...         1.291680e+05         1.291680e+05         1.291680e+05   \n",
       "mean   ...         1.075160e-01         1.057642e-01         1.068375e-01   \n",
       "std    ...         2.622182e-01         2.481034e-01         2.550262e-01   \n",
       "min    ...         5.854756e-08         5.854756e-08         5.854756e-08   \n",
       "25%    ...         1.481255e-02         1.236906e-02         1.018621e-02   \n",
       "50%    ...         2.940459e-02         2.694377e-02         2.478391e-02   \n",
       "75%    ...         8.515404e-02         9.895668e-02         9.447166e-02   \n",
       "max    ...         1.436499e+01         5.370183e+00         6.006445e+00   \n",
       "\n",
       "       lcNonPeriodic[27]_z  lcNonPeriodic[28]_u  lcNonPeriodic[28]_g  \\\n",
       "count         1.291680e+05        129168.000000        129168.000000   \n",
       "mean          1.137659e-01          1155.222216           217.155013   \n",
       "std           2.934939e-01          4352.481898          1424.813117   \n",
       "min           5.854756e-08             0.018316             0.018316   \n",
       "25%           1.061997e-02             1.961054             0.895356   \n",
       "50%           2.726769e-02            13.525332             5.680325   \n",
       "75%           8.517200e-02           205.325630            87.170420   \n",
       "max           7.383428e+00         22026.465795         22026.465795   \n",
       "\n",
       "       lcNonPeriodic[28]_r  lcNonPeriodic[28]_i  lcNonPeriodic[28]_z  \\\n",
       "count        129168.000000        129168.000000        129168.000000   \n",
       "mean            229.138964           228.182959           673.288631   \n",
       "std            1225.809878          1217.650916          3295.799497   \n",
       "min               0.018316             0.018316             0.018316   \n",
       "25%               0.534148             0.772182             1.529153   \n",
       "50%               3.321019             4.004215             7.306155   \n",
       "75%              97.600018            84.233117            59.262192   \n",
       "max           22026.465795         22026.465795         22026.465795   \n",
       "\n",
       "                 ebv  \n",
       "count  129168.000000  \n",
       "mean        0.047703  \n",
       "std         0.028767  \n",
       "min         0.013337  \n",
       "25%         0.027825  \n",
       "50%         0.035368  \n",
       "75%         0.062735  \n",
       "max         0.527862  \n",
       "\n",
       "[8 rows x 333 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardizing and Scaling\n",
    "\n",
    "# Set X to the entire DataFrame\n",
    "X = object_df_colvar\n",
    "# Remove the 'class' column from X as it is the target variable\n",
    "X = X.drop(['class'], axis=1)\n",
    "\n",
    "# Set y to the 'class' column of the DataFrame\n",
    "y = object_df_colvar['class']\n",
    "\n",
    "# Display the shapes and summary statistics \n",
    "display(X.shape, y.shape)\n",
    "display(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c73b4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64584, 333)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(64584, 333)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (50% training, 50% testing)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.5, random_state = 1, shuffle=True)\n",
    "\n",
    "# Impute missing values by using the mean or median value\n",
    "X_train = X_train.fillna(X_train.mean()) # or X_train.median()\n",
    "X_test = X_test.fillna(X_test.mean()) # or X_test.median()\n",
    "\n",
    "# Create a StandardScaler object to standardize the features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fit the scaler using the training data\n",
    "scaler.fit(X_train)\n",
    "# Transform the training data using the fitted scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "# Transform the testing data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the scaled training and testing data\n",
    "display(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0259179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psFlux_u</th>\n",
       "      <th>psFlux_g</th>\n",
       "      <th>psFlux_r</th>\n",
       "      <th>psFlux_i</th>\n",
       "      <th>psFlux_z</th>\n",
       "      <th>bdFlux_u</th>\n",
       "      <th>bdFlux_g</th>\n",
       "      <th>bdFlux_r</th>\n",
       "      <th>bdFlux_i</th>\n",
       "      <th>bdFlux_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lcNonPeriodic[27]_g</th>\n",
       "      <th>lcNonPeriodic[27]_r</th>\n",
       "      <th>lcNonPeriodic[27]_i</th>\n",
       "      <th>lcNonPeriodic[27]_z</th>\n",
       "      <th>lcNonPeriodic[28]_u</th>\n",
       "      <th>lcNonPeriodic[28]_g</th>\n",
       "      <th>lcNonPeriodic[28]_r</th>\n",
       "      <th>lcNonPeriodic[28]_i</th>\n",
       "      <th>lcNonPeriodic[28]_z</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.684624e+04</td>\n",
       "      <td>1.304385e+05</td>\n",
       "      <td>2.357220e+05</td>\n",
       "      <td>3.206205e+05</td>\n",
       "      <td>3.879399e+05</td>\n",
       "      <td>3.774195e+04</td>\n",
       "      <td>1.338499e+05</td>\n",
       "      <td>2.377597e+05</td>\n",
       "      <td>3.101442e+05</td>\n",
       "      <td>3.812804e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076660e-01</td>\n",
       "      <td>1.055362e-01</td>\n",
       "      <td>1.064319e-01</td>\n",
       "      <td>1.136158e-01</td>\n",
       "      <td>1156.328795</td>\n",
       "      <td>212.551488</td>\n",
       "      <td>232.403321</td>\n",
       "      <td>225.791459</td>\n",
       "      <td>674.566006</td>\n",
       "      <td>0.047564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.315547e+04</td>\n",
       "      <td>2.841475e+05</td>\n",
       "      <td>4.556118e+05</td>\n",
       "      <td>5.745580e+05</td>\n",
       "      <td>6.873106e+05</td>\n",
       "      <td>9.448507e+04</td>\n",
       "      <td>2.884775e+05</td>\n",
       "      <td>4.382042e+05</td>\n",
       "      <td>5.203634e+05</td>\n",
       "      <td>6.418169e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.591350e-01</td>\n",
       "      <td>2.470830e-01</td>\n",
       "      <td>2.532232e-01</td>\n",
       "      <td>2.924777e-01</td>\n",
       "      <td>4354.880718</td>\n",
       "      <td>1392.752429</td>\n",
       "      <td>1250.997985</td>\n",
       "      <td>1197.976078</td>\n",
       "      <td>3297.817826</td>\n",
       "      <td>0.028586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.392692e-01</td>\n",
       "      <td>6.421650e+02</td>\n",
       "      <td>1.154431e+03</td>\n",
       "      <td>1.664187e+03</td>\n",
       "      <td>3.721540e+02</td>\n",
       "      <td>3.699554e-01</td>\n",
       "      <td>4.903501e+02</td>\n",
       "      <td>6.114777e+02</td>\n",
       "      <td>8.053055e+02</td>\n",
       "      <td>1.601458e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.013465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.170007e+03</td>\n",
       "      <td>6.880339e+03</td>\n",
       "      <td>1.164597e+04</td>\n",
       "      <td>1.566796e+04</td>\n",
       "      <td>1.857688e+04</td>\n",
       "      <td>2.808569e+03</td>\n",
       "      <td>7.942941e+03</td>\n",
       "      <td>1.427115e+04</td>\n",
       "      <td>1.899227e+04</td>\n",
       "      <td>2.264897e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481359e-02</td>\n",
       "      <td>1.235630e-02</td>\n",
       "      <td>1.018822e-02</td>\n",
       "      <td>1.060690e-02</td>\n",
       "      <td>1.949617</td>\n",
       "      <td>0.881235</td>\n",
       "      <td>0.529593</td>\n",
       "      <td>0.758537</td>\n",
       "      <td>1.508843</td>\n",
       "      <td>0.027818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.036747e+03</td>\n",
       "      <td>2.581057e+04</td>\n",
       "      <td>5.322174e+04</td>\n",
       "      <td>7.704003e+04</td>\n",
       "      <td>8.947503e+04</td>\n",
       "      <td>7.636697e+03</td>\n",
       "      <td>2.839210e+04</td>\n",
       "      <td>6.229214e+04</td>\n",
       "      <td>9.217739e+04</td>\n",
       "      <td>1.103081e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.939356e-02</td>\n",
       "      <td>2.698251e-02</td>\n",
       "      <td>2.472990e-02</td>\n",
       "      <td>2.708515e-02</td>\n",
       "      <td>13.581835</td>\n",
       "      <td>5.643032</td>\n",
       "      <td>3.324245</td>\n",
       "      <td>3.980166</td>\n",
       "      <td>7.190530</td>\n",
       "      <td>0.035275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.779684e+04</td>\n",
       "      <td>1.097199e+05</td>\n",
       "      <td>2.277843e+05</td>\n",
       "      <td>3.390134e+05</td>\n",
       "      <td>4.239446e+05</td>\n",
       "      <td>2.851413e+04</td>\n",
       "      <td>1.119053e+05</td>\n",
       "      <td>2.391752e+05</td>\n",
       "      <td>3.564815e+05</td>\n",
       "      <td>4.480386e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.587611e-02</td>\n",
       "      <td>9.946481e-02</td>\n",
       "      <td>9.471150e-02</td>\n",
       "      <td>8.534781e-02</td>\n",
       "      <td>204.398028</td>\n",
       "      <td>86.710431</td>\n",
       "      <td>98.939164</td>\n",
       "      <td>84.797341</td>\n",
       "      <td>59.479541</td>\n",
       "      <td>0.062549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.130619e+06</td>\n",
       "      <td>6.931127e+06</td>\n",
       "      <td>7.347410e+06</td>\n",
       "      <td>8.475986e+06</td>\n",
       "      <td>1.126342e+07</td>\n",
       "      <td>3.163809e+06</td>\n",
       "      <td>6.240139e+06</td>\n",
       "      <td>8.810218e+06</td>\n",
       "      <td>1.173952e+07</td>\n",
       "      <td>1.476919e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284611e+01</td>\n",
       "      <td>4.237625e+00</td>\n",
       "      <td>4.453405e+00</td>\n",
       "      <td>7.383428e+00</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>0.527862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           psFlux_u      psFlux_g      psFlux_r      psFlux_i      psFlux_z  \\\n",
       "count  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04   \n",
       "mean   3.684624e+04  1.304385e+05  2.357220e+05  3.206205e+05  3.879399e+05   \n",
       "std    9.315547e+04  2.841475e+05  4.556118e+05  5.745580e+05  6.873106e+05   \n",
       "min    8.392692e-01  6.421650e+02  1.154431e+03  1.664187e+03  3.721540e+02   \n",
       "25%    2.170007e+03  6.880339e+03  1.164597e+04  1.566796e+04  1.857688e+04   \n",
       "50%    7.036747e+03  2.581057e+04  5.322174e+04  7.704003e+04  8.947503e+04   \n",
       "75%    2.779684e+04  1.097199e+05  2.277843e+05  3.390134e+05  4.239446e+05   \n",
       "max    3.130619e+06  6.931127e+06  7.347410e+06  8.475986e+06  1.126342e+07   \n",
       "\n",
       "           bdFlux_u      bdFlux_g      bdFlux_r      bdFlux_i      bdFlux_z  \\\n",
       "count  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04   \n",
       "mean   3.774195e+04  1.338499e+05  2.377597e+05  3.101442e+05  3.812804e+05   \n",
       "std    9.448507e+04  2.884775e+05  4.382042e+05  5.203634e+05  6.418169e+05   \n",
       "min    3.699554e-01  4.903501e+02  6.114777e+02  8.053055e+02  1.601458e+02   \n",
       "25%    2.808569e+03  7.942941e+03  1.427115e+04  1.899227e+04  2.264897e+04   \n",
       "50%    7.636697e+03  2.839210e+04  6.229214e+04  9.217739e+04  1.103081e+05   \n",
       "75%    2.851413e+04  1.119053e+05  2.391752e+05  3.564815e+05  4.480386e+05   \n",
       "max    3.163809e+06  6.240139e+06  8.810218e+06  1.173952e+07  1.476919e+07   \n",
       "\n",
       "       ...  lcNonPeriodic[27]_g  lcNonPeriodic[27]_r  lcNonPeriodic[27]_i  \\\n",
       "count  ...         6.458400e+04         6.458400e+04         6.458400e+04   \n",
       "mean   ...         1.076660e-01         1.055362e-01         1.064319e-01   \n",
       "std    ...         2.591350e-01         2.470830e-01         2.532232e-01   \n",
       "min    ...         5.854756e-08         5.854756e-08         5.854756e-08   \n",
       "25%    ...         1.481359e-02         1.235630e-02         1.018822e-02   \n",
       "50%    ...         2.939356e-02         2.698251e-02         2.472990e-02   \n",
       "75%    ...         8.587611e-02         9.946481e-02         9.471150e-02   \n",
       "max    ...         1.284611e+01         4.237625e+00         4.453405e+00   \n",
       "\n",
       "       lcNonPeriodic[27]_z  lcNonPeriodic[28]_u  lcNonPeriodic[28]_g  \\\n",
       "count         6.458400e+04         64584.000000         64584.000000   \n",
       "mean          1.136158e-01          1156.328795           212.551488   \n",
       "std           2.924777e-01          4354.880718          1392.752429   \n",
       "min           5.854756e-08             0.018316             0.018316   \n",
       "25%           1.060690e-02             1.949617             0.881235   \n",
       "50%           2.708515e-02            13.581835             5.643032   \n",
       "75%           8.534781e-02           204.398028            86.710431   \n",
       "max           7.383428e+00         22026.465795         22026.465795   \n",
       "\n",
       "       lcNonPeriodic[28]_r  lcNonPeriodic[28]_i  lcNonPeriodic[28]_z  \\\n",
       "count         64584.000000         64584.000000         64584.000000   \n",
       "mean            232.403321           225.791459           674.566006   \n",
       "std            1250.997985          1197.976078          3297.817826   \n",
       "min               0.018316             0.018316             0.018316   \n",
       "25%               0.529593             0.758537             1.508843   \n",
       "50%               3.324245             3.980166             7.190530   \n",
       "75%              98.939164            84.797341            59.479541   \n",
       "max           22026.465795         22026.465795         22026.465795   \n",
       "\n",
       "                ebv  \n",
       "count  64584.000000  \n",
       "mean       0.047564  \n",
       "std        0.028586  \n",
       "min        0.013465  \n",
       "25%        0.027818  \n",
       "50%        0.035275  \n",
       "75%        0.062549  \n",
       "max        0.527862  \n",
       "\n",
       "[8 rows x 333 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psFlux_u</th>\n",
       "      <th>psFlux_g</th>\n",
       "      <th>psFlux_r</th>\n",
       "      <th>psFlux_i</th>\n",
       "      <th>psFlux_z</th>\n",
       "      <th>bdFlux_u</th>\n",
       "      <th>bdFlux_g</th>\n",
       "      <th>bdFlux_r</th>\n",
       "      <th>bdFlux_i</th>\n",
       "      <th>bdFlux_z</th>\n",
       "      <th>...</th>\n",
       "      <th>lcNonPeriodic[27]_g</th>\n",
       "      <th>lcNonPeriodic[27]_r</th>\n",
       "      <th>lcNonPeriodic[27]_i</th>\n",
       "      <th>lcNonPeriodic[27]_z</th>\n",
       "      <th>lcNonPeriodic[28]_u</th>\n",
       "      <th>lcNonPeriodic[28]_g</th>\n",
       "      <th>lcNonPeriodic[28]_r</th>\n",
       "      <th>lcNonPeriodic[28]_i</th>\n",
       "      <th>lcNonPeriodic[28]_z</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>6.458400e+04</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "      <td>64584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.713982e+04</td>\n",
       "      <td>1.296128e+05</td>\n",
       "      <td>2.906694e+05</td>\n",
       "      <td>3.172992e+05</td>\n",
       "      <td>3.844696e+05</td>\n",
       "      <td>3.792848e+04</td>\n",
       "      <td>1.327443e+05</td>\n",
       "      <td>2.347024e+05</td>\n",
       "      <td>3.065502e+05</td>\n",
       "      <td>3.765988e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.073660e-01</td>\n",
       "      <td>1.059922e-01</td>\n",
       "      <td>1.072431e-01</td>\n",
       "      <td>1.139160e-01</td>\n",
       "      <td>1154.115637</td>\n",
       "      <td>221.758538</td>\n",
       "      <td>225.874606</td>\n",
       "      <td>230.574459</td>\n",
       "      <td>672.011256</td>\n",
       "      <td>0.047843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.024449e+05</td>\n",
       "      <td>2.806256e+05</td>\n",
       "      <td>1.462310e+07</td>\n",
       "      <td>5.677225e+05</td>\n",
       "      <td>6.868463e+05</td>\n",
       "      <td>1.040709e+05</td>\n",
       "      <td>2.844410e+05</td>\n",
       "      <td>4.279779e+05</td>\n",
       "      <td>5.079308e+05</td>\n",
       "      <td>6.314623e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.652676e-01</td>\n",
       "      <td>2.491213e-01</td>\n",
       "      <td>2.568178e-01</td>\n",
       "      <td>2.945088e-01</td>\n",
       "      <td>4350.115189</td>\n",
       "      <td>1456.164330</td>\n",
       "      <td>1200.094043</td>\n",
       "      <td>1237.017518</td>\n",
       "      <td>3293.804969</td>\n",
       "      <td>0.028945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.843956e-01</td>\n",
       "      <td>2.381211e+02</td>\n",
       "      <td>1.068223e+03</td>\n",
       "      <td>1.253822e+03</td>\n",
       "      <td>2.091147e+03</td>\n",
       "      <td>1.352985e-01</td>\n",
       "      <td>2.503990e+02</td>\n",
       "      <td>5.916977e+02</td>\n",
       "      <td>1.131320e+03</td>\n",
       "      <td>1.024772e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>5.854756e-08</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.176188e+03</td>\n",
       "      <td>6.862422e+03</td>\n",
       "      <td>1.151586e+04</td>\n",
       "      <td>1.548882e+04</td>\n",
       "      <td>1.830291e+04</td>\n",
       "      <td>2.834884e+03</td>\n",
       "      <td>7.860284e+03</td>\n",
       "      <td>1.396502e+04</td>\n",
       "      <td>1.864550e+04</td>\n",
       "      <td>2.246082e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480826e-02</td>\n",
       "      <td>1.238137e-02</td>\n",
       "      <td>1.018422e-02</td>\n",
       "      <td>1.063119e-02</td>\n",
       "      <td>1.975322</td>\n",
       "      <td>0.909632</td>\n",
       "      <td>0.539949</td>\n",
       "      <td>0.787177</td>\n",
       "      <td>1.548588</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.092551e+03</td>\n",
       "      <td>2.570722e+04</td>\n",
       "      <td>5.292174e+04</td>\n",
       "      <td>7.680839e+04</td>\n",
       "      <td>8.836768e+04</td>\n",
       "      <td>7.688672e+03</td>\n",
       "      <td>2.837655e+04</td>\n",
       "      <td>6.231039e+04</td>\n",
       "      <td>9.202586e+04</td>\n",
       "      <td>1.098910e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.940891e-02</td>\n",
       "      <td>2.690424e-02</td>\n",
       "      <td>2.486288e-02</td>\n",
       "      <td>2.744198e-02</td>\n",
       "      <td>13.468144</td>\n",
       "      <td>5.711555</td>\n",
       "      <td>3.319086</td>\n",
       "      <td>4.027950</td>\n",
       "      <td>7.422018</td>\n",
       "      <td>0.035462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.783856e+04</td>\n",
       "      <td>1.088653e+05</td>\n",
       "      <td>2.285255e+05</td>\n",
       "      <td>3.393247e+05</td>\n",
       "      <td>4.214133e+05</td>\n",
       "      <td>2.862682e+04</td>\n",
       "      <td>1.108086e+05</td>\n",
       "      <td>2.381399e+05</td>\n",
       "      <td>3.548172e+05</td>\n",
       "      <td>4.442326e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.440174e-02</td>\n",
       "      <td>9.850364e-02</td>\n",
       "      <td>9.426445e-02</td>\n",
       "      <td>8.492988e-02</td>\n",
       "      <td>206.235205</td>\n",
       "      <td>87.512762</td>\n",
       "      <td>96.122076</td>\n",
       "      <td>83.885472</td>\n",
       "      <td>59.183229</td>\n",
       "      <td>0.062928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.037682e+06</td>\n",
       "      <td>5.414997e+06</td>\n",
       "      <td>3.714715e+09</td>\n",
       "      <td>9.697823e+06</td>\n",
       "      <td>1.408038e+07</td>\n",
       "      <td>6.047477e+06</td>\n",
       "      <td>6.154918e+06</td>\n",
       "      <td>9.925469e+06</td>\n",
       "      <td>1.208203e+07</td>\n",
       "      <td>1.446734e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436499e+01</td>\n",
       "      <td>5.370183e+00</td>\n",
       "      <td>6.006445e+00</td>\n",
       "      <td>6.730886e+00</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>22026.465795</td>\n",
       "      <td>0.527724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           psFlux_u      psFlux_g      psFlux_r      psFlux_i      psFlux_z  \\\n",
       "count  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04   \n",
       "mean   3.713982e+04  1.296128e+05  2.906694e+05  3.172992e+05  3.844696e+05   \n",
       "std    1.024449e+05  2.806256e+05  1.462310e+07  5.677225e+05  6.868463e+05   \n",
       "min    8.843956e-01  2.381211e+02  1.068223e+03  1.253822e+03  2.091147e+03   \n",
       "25%    2.176188e+03  6.862422e+03  1.151586e+04  1.548882e+04  1.830291e+04   \n",
       "50%    7.092551e+03  2.570722e+04  5.292174e+04  7.680839e+04  8.836768e+04   \n",
       "75%    2.783856e+04  1.088653e+05  2.285255e+05  3.393247e+05  4.214133e+05   \n",
       "max    6.037682e+06  5.414997e+06  3.714715e+09  9.697823e+06  1.408038e+07   \n",
       "\n",
       "           bdFlux_u      bdFlux_g      bdFlux_r      bdFlux_i      bdFlux_z  \\\n",
       "count  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04  6.458400e+04   \n",
       "mean   3.792848e+04  1.327443e+05  2.347024e+05  3.065502e+05  3.765988e+05   \n",
       "std    1.040709e+05  2.844410e+05  4.279779e+05  5.079308e+05  6.314623e+05   \n",
       "min    1.352985e-01  2.503990e+02  5.916977e+02  1.131320e+03  1.024772e+03   \n",
       "25%    2.834884e+03  7.860284e+03  1.396502e+04  1.864550e+04  2.246082e+04   \n",
       "50%    7.688672e+03  2.837655e+04  6.231039e+04  9.202586e+04  1.098910e+05   \n",
       "75%    2.862682e+04  1.108086e+05  2.381399e+05  3.548172e+05  4.442326e+05   \n",
       "max    6.047477e+06  6.154918e+06  9.925469e+06  1.208203e+07  1.446734e+07   \n",
       "\n",
       "       ...  lcNonPeriodic[27]_g  lcNonPeriodic[27]_r  lcNonPeriodic[27]_i  \\\n",
       "count  ...         6.458400e+04         6.458400e+04         6.458400e+04   \n",
       "mean   ...         1.073660e-01         1.059922e-01         1.072431e-01   \n",
       "std    ...         2.652676e-01         2.491213e-01         2.568178e-01   \n",
       "min    ...         5.854756e-08         5.854756e-08         5.854756e-08   \n",
       "25%    ...         1.480826e-02         1.238137e-02         1.018422e-02   \n",
       "50%    ...         2.940891e-02         2.690424e-02         2.486288e-02   \n",
       "75%    ...         8.440174e-02         9.850364e-02         9.426445e-02   \n",
       "max    ...         1.436499e+01         5.370183e+00         6.006445e+00   \n",
       "\n",
       "       lcNonPeriodic[27]_z  lcNonPeriodic[28]_u  lcNonPeriodic[28]_g  \\\n",
       "count         6.458400e+04         64584.000000         64584.000000   \n",
       "mean          1.139160e-01          1154.115637           221.758538   \n",
       "std           2.945088e-01          4350.115189          1456.164330   \n",
       "min           5.854756e-08             0.018316             0.018316   \n",
       "25%           1.063119e-02             1.975322             0.909632   \n",
       "50%           2.744198e-02            13.468144             5.711555   \n",
       "75%           8.492988e-02           206.235205            87.512762   \n",
       "max           6.730886e+00         22026.465795         22026.465795   \n",
       "\n",
       "       lcNonPeriodic[28]_r  lcNonPeriodic[28]_i  lcNonPeriodic[28]_z  \\\n",
       "count         64584.000000         64584.000000         64584.000000   \n",
       "mean            225.874606           230.574459           672.011256   \n",
       "std            1200.094043          1237.017518          3293.804969   \n",
       "min               0.018316             0.018316             0.018316   \n",
       "25%               0.539949             0.787177             1.548588   \n",
       "50%               3.319086             4.027950             7.422018   \n",
       "75%              96.122076            83.885472            59.183229   \n",
       "max           22026.465795         22026.465795         22026.465795   \n",
       "\n",
       "                ebv  \n",
       "count  64584.000000  \n",
       "mean       0.047843  \n",
       "std        0.028945  \n",
       "min        0.013337  \n",
       "25%        0.027829  \n",
       "50%        0.035462  \n",
       "75%        0.062928  \n",
       "max        0.527724  \n",
       "\n",
       "[8 rows x 333 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the summary statistics of the training data\n",
    "display(X_train.describe())\n",
    "\n",
    "# Display the summary statistics of the testing data\n",
    "display(X_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a87859",
   "metadata": {},
   "source": [
    "## TensorFlow <a class=\"anchor\" id=\"five\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f44b7",
   "metadata": {},
   "source": [
    "Google created TensorFlow and made it available in 2015. This highly scalable framework is extensively utilized for machine learning applications at the production level.\n",
    "\n",
    "TensorFlow operates on a data flow graph, where mathematical operations are represented by nodes and data inputs and outputs are represented by edges. By adopting this approach, TensorFlow can optimize computations and execute them efficiently on both CPUs and GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a14d3",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f01844",
   "metadata": {},
   "source": [
    "The term \"model architecture\" encompasses the holistic arrangement and composition of a machine learning model. This encompasses factors such as the quantity and nature of layers, the number of neurons or units within each layer, the activation functions employed in each layer, the training optimization algorithm, and other design considerations entailed in the model's creation.\n",
    "\n",
    "An autoencoder is a neural network that is utilized for unsupervised learning purposes. \n",
    "\n",
    "TensorFlow offers the Keras API for defining an autoencoder model. This model comprises an encoder and a decoder network, which are trained to reconstruct the input data. The model parameters can be optimized through backpropagation and gradient descent algorithms. Once trained, the model finds applications in tasks such as dimensionality reduction, anomaly detection, and data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c6a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'TF Tester 4'\n",
    "# Define the simple autoencoder function\n",
    "def Autoencoder_Simple(input_size):\n",
    "    # Calculate the hidden layer size (half of the input size)\n",
    "    hidden_size = int(input_size / 2.0)\n",
    "    # Calculate the bottleneck layer size (half of the hidden layer size)\n",
    "    bottleneck_size = int(hidden_size / 2.0)\n",
    "    # Define the input layer with the specified input size\n",
    "    input_tab = Input(shape=(input_size,))\n",
    "    # Define the first hidden layer with 'relu' activation function\n",
    "    hidden_1 = layers.Dense(hidden_size, activation='relu')(input_tab)\n",
    "    # Define the bottleneck layer with 'relu' activation function\n",
    "    bottleneck = layers.Dense(bottleneck_size, activation='relu')(hidden_1)\n",
    "    # Define the second hidden layer with 'relu' activation function\n",
    "    hidden_2 = layers.Dense(hidden_size, activation='relu')(bottleneck)\n",
    "    # Define the output layer with 'linear' activation function\n",
    "    output_tab = layers.Dense(input_size, activation='linear')(hidden_2)\n",
    "    # Create the encoder model, which includes the input layer and bottleneck layer\n",
    "    encoder = Model(input_tab, bottleneck)\n",
    "    # Create the full autoencoder model, which includes the input and output layers\n",
    "    decoder = Model(input_tab, output_tab)\n",
    "\n",
    "    # Return both the full autoencoder model and the encoder model\n",
    "    return decoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8668ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:10:06.777022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-29 20:10:06.777266: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "from tensorflow.keras import layers\n",
    "# Set the input size based on the number of features in the dataset\n",
    "input_size = X.shape[1]\n",
    "# Call the Autoencoder_Simple function, passing the input_size as an argument\n",
    "decoder, encoder = Autoencoder_Simple(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a2e5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "\n",
    "# Plot the model architecture\n",
    "plot_model(decoder, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb11be",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97593a7",
   "metadata": {},
   "source": [
    "Model training involves the procedure of instructing a machine learning model to generate precise predictions for novel data. Within unsupervised learning, model training pertains to comprehending the inherent patterns within the data without relying on explicit labels.\n",
    "\n",
    "The process of training an autoencoder model in TensorFlow revolves around optimizing its parameters to minimize the disparity between the input and output data. This optimization is achieved by reducing the reconstruction error utilizing an optimization algorithm like stochastic gradient descent. \n",
    "\n",
    "Typically, a substantial dataset is employed to train the model, aiming to acquire meaningful data representations beneficial for tasks such as data compression, denoising, and anomaly detection. During training, the weights and biases of the neural network are iteratively adjusted through backpropagation, wherein the gradients of the loss function with respect to the model parameters are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4697d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:11:08.846785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Set the number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# Compile the model with Adam optimizer and mean squared error loss function\n",
    "decoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model using the scaled training data and validation data\n",
    "history = decoder.fit(X_train_scaled, X_train_scaled,\n",
    "                    epochs=n_epochs, batch_size=16, verbose=2,\n",
    "                    validation_data=(X_test_scaled, X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868f1c0",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cabfa",
   "metadata": {},
   "source": [
    "Model evaluation involves assessing the predictive capability of a machine learning model by testing it on a separate dataset, distinct from the training data. This assessment aims to gauge the model's performance and effectiveness.\n",
    "\n",
    "In the case of an autoencoder, evaluating the model focuses on determining its ability to accurately reconstruct unseen input data. This evaluation involves comparing the original input data with the output data generated by the autoencoder and quantifying the dissimilarity between them.\n",
    "\n",
    "A common approach for model evaluation is to plot the loss function's trajectory throughout the training process. The loss function measures the disparity between the model's predictions and the actual data, and the objective during training is to minimize this discrepancy. By visualizing the loss function over time, we gain insights into the model's learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'TF Tester 1'\n",
    "# Plot the training and testing loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5035dc",
   "metadata": {},
   "source": [
    "## PyTorch <a class=\"anchor\" id=\"six\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574cff5f",
   "metadata": {},
   "source": [
    "Facebook introduced PyTorch in 2017 as a flexible framework that offers ease of use and customization. \n",
    "\n",
    "Unlike other frameworks, PyTorch utilizes a dynamic computational graph, enabling developers to construct models in a Pythonic manner. This feature proves particularly advantageous when creating dynamic models that involve varying input shapes or sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a90a7e",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616a138",
   "metadata": {},
   "source": [
    "The term \"model architecture\" encompasses the holistic arrangement and composition of a machine learning model. This encompasses factors such as the quantity and nature of layers, the number of neurons or units within each layer, the activation functions employed in each layer, the training optimization algorithm, and other design considerations entailed in the model's creation.\n",
    "\n",
    "An autoencoder is a neural network that is utilized for unsupervised learning purposes.\n",
    "\n",
    "When working with PyTorch, the process of creating an autoencoder model entails constructing an encoder and decoder network. These components are trained jointly to acquire a condensed representation of the input data. \n",
    "The encoder network is responsible for receiving the input and generating a representation with reduced dimensions. Subsequently, the decoder network utilizes this representation to produce the reconstructed output. \n",
    "The primary objective is to minimize the disparity between the input and output, while simultaneously reducing the dimensionality of the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "# Define the Autoencoder model\n",
    "# Define a class named Autoencoder that inherits from the PyTorch nn.Module class\n",
    "class Autoencoder(nn.Module):\n",
    "    # Initialize the Autoencoder class, taking an input_size argument\n",
    "    def __init__(self, input_size):\n",
    "        # Call the constructor of the parent nn.Module class\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Calculate the size of the hidden layer as half of the input_size\n",
    "        hidden_size = int(input_size / 2)\n",
    "        # Calculate the size of the bottleneck layer as half of the hidden_size\n",
    "        bottleneck_size = int(hidden_size / 2)\n",
    "        # Define the encoder part of the autoencoder as a sequence of layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Add a linear layer with input_size as input and hidden_size as output\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "            # Add a linear layer with hidden_size as input and bottleneck_size as output\n",
    "            nn.Linear(hidden_size, bottleneck_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Define the decoder part of the autoencoder as a sequence of layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Add a linear layer with bottleneck_size as input and hidden_size as output\n",
    "            nn.Linear(bottleneck_size, hidden_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "            # Add a linear layer with hidden_size as input and input_size as output\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "\n",
    "    # Define the forward pass of the autoencoder\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the encoder to get the bottleneck representation\n",
    "        x = self.encoder(x)\n",
    "        # Pass the bottleneck representation through the decoder to get the reconstructed output\n",
    "        x = self.decoder(x)\n",
    "        # Return the reconstructed output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1 give more explanation to keras'\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch TensorDataset for the training and testing data\n",
    "train_dataset = TensorDataset(X_train_torch)  \n",
    "test_dataset = TensorDataset(X_test_torch)\n",
    "# Create a DataLoader for the training and testing data\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Check to ensure that the data does not contain any nan or infinity values\n",
    "print(\"X_train_torch contains nan:\", torch.isnan(X_train_torch).any())\n",
    "print(\"X_train_torch contains inf:\", torch.isinf(X_train_torch).any())\n",
    "print(\"X_test_torch contains nan:\", torch.isnan(X_test_torch).any())\n",
    "print(\"X_test_torch contains inf:\", torch.isinf(X_test_torch).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "# Instantiate the model\n",
    "# Get the number of features in the input data\n",
    "input_size = X.shape[1] \n",
    "# Create an instance of the Autoencoder class with the input size\n",
    "model = Autoencoder(input_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "import torch.optim as optim\n",
    "# Define the loss function as mean squared error (MSE) loss\n",
    "criterion = nn.MSELoss() \n",
    "# Create an Adam optimizer with the specified learning rate and the model's parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26078e25",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb76c7d",
   "metadata": {},
   "source": [
    "Model training involves the procedure of instructing a machine learning model to generate precise predictions for novel data. Within unsupervised learning, model training pertains to comprehending the inherent patterns within the data without relying on explicit labels. \n",
    "\n",
    "PyTorch's Autoencoder Model Training comprises several steps, including the specification of the model's structure, configuration of hyperparameters, and the actual training process. \n",
    "To begin, the encoder and decoder architectures are established using the nn.Module class. Subsequently, important hyperparameters like learning rate, batch size, and number of epochs are defined. \n",
    "The optimizer and loss function are then determined.\n",
    "\n",
    "Following these preparations, the model is trained on the training dataset while also undergoing validation on a separate dataset and testing on yet another dataset. \n",
    "Once the training is complete, the trained model can be utilized for making predictions and generating new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44117e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "# Set the number of epochs for training\n",
    "n_epochs = 50\n",
    "\n",
    "# Loop through each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize the train loss for the current epoch to 0\n",
    "    train_loss = 0.0\n",
    "    # Loop through each batch in the train_loader\n",
    "    for batch in train_loader:\n",
    "        # Get the input data from the current batch\n",
    "        inputs = batch[0]      \n",
    "        # Reset the optimizer gradients to 0\n",
    "        optimizer.zero_grad()   \n",
    "        # Pass the inputs through the model to get the outputs\n",
    "        outputs = model(inputs)     \n",
    "        # Calculate the loss between the outputs and the original inputs\n",
    "        loss = criterion(outputs, inputs)      \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()    \n",
    "        # Update the model parameters using the optimizer\n",
    "        optimizer.step()     \n",
    "        # Accumulate the train loss for the current batch\n",
    "        train_loss += loss.item()\n",
    "    # Initialize the test loss for the current epoch to 0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    # Disable gradient calculations for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Loop through each batch in the test_loader\n",
    "        for batch in test_loader:\n",
    "            # Get the input data from the current batch\n",
    "            inputs = batch[0]\n",
    "            # Pass the inputs through the model to get the outputs\n",
    "            outputs = model(inputs)  \n",
    "            # Calculate the loss between the outputs and the original inputs\n",
    "            loss = criterion(outputs, inputs)    \n",
    "            # Accumulate the test loss for the current batch\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    # Print the train and test loss for the current epoch\n",
    "    print(f\"Epoch: {epoch+1}/{n_epochs}, Train Loss: {train_loss/len(train_loader):.6f}, Test Loss: {test_loss/len(test_loader):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffdbb8f",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98ca7c",
   "metadata": {},
   "source": [
    "Model evaluation involves assessing the predictive capability of a machine learning model by testing it on a separate dataset, distinct from the training data. This assessment aims to gauge the model's performance and effectiveness.\n",
    "\n",
    "In the case of an autoencoder, evaluating the model focuses on determining its ability to accurately reconstruct unseen input data. This evaluation involves comparing the original input data with the output data generated by the autoencoder and quantifying the dissimilarity between them.\n",
    "\n",
    "A common approach for model evaluation is to plot the loss function's trajectory throughout the training process. The loss function measures the disparity between the model's predictions and the actual data, and the objective during training is to minimize this discrepancy. By visualizing the loss function over time, we gain insights into the model's learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48505132",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "\n",
    "# Using the output as a string and extract the losses from it to plot.\n",
    "\n",
    "# Output as a string\n",
    "output = '''\n",
    "Epoch: 1/50, Train Loss: 0.782713, Test Loss: 1.009243\n",
    "Epoch: 2/50, Train Loss: 0.644265, Test Loss: 0.909629\n",
    "Epoch: 3/50, Train Loss: 0.564785, Test Loss: 0.875361\n",
    "Epoch: 4/50, Train Loss: 0.518305, Test Loss: 0.833686\n",
    "Epoch: 5/50, Train Loss: 0.488832, Test Loss: 0.771596\n",
    "Epoch: 6/50, Train Loss: 0.460069, Test Loss: 0.746401\n",
    "Epoch: 7/50, Train Loss: 0.437026, Test Loss: 0.716084\n",
    "Epoch: 8/50, Train Loss: 0.421743, Test Loss: 0.703490\n",
    "Epoch: 9/50, Train Loss: 0.409290, Test Loss: 0.706463\n",
    "Epoch: 10/50, Train Loss: 0.398274, Test Loss: 0.701632\n",
    "Epoch: 11/50, Train Loss: 0.391102, Test Loss: 0.674227\n",
    "Epoch: 12/50, Train Loss: 0.382270, Test Loss: 0.710714\n",
    "Epoch: 13/50, Train Loss: 0.373196, Test Loss: 0.658933\n",
    "Epoch: 14/50, Train Loss: 0.350142, Test Loss: 0.642729\n",
    "Epoch: 15/50, Train Loss: 0.354073, Test Loss: 0.645506\n",
    "Epoch: 16/50, Train Loss: 0.343844, Test Loss: 0.639976\n",
    "Epoch: 17/50, Train Loss: 0.349258, Test Loss: 0.634457\n",
    "Epoch: 18/50, Train Loss: 0.329151, Test Loss: 0.632099\n",
    "Epoch: 19/50, Train Loss: 0.323303, Test Loss: 0.623881\n",
    "Epoch: 20/50, Train Loss: 0.317393, Test Loss: 0.612351\n",
    "Epoch: 21/50, Train Loss: 0.307734, Test Loss: 0.625355\n",
    "Epoch: 22/50, Train Loss: 0.312261, Test Loss: 0.631439\n",
    "Epoch: 23/50, Train Loss: 0.307283, Test Loss: 0.610426\n",
    "Epoch: 24/50, Train Loss: 0.302645, Test Loss: 0.629924\n",
    "Epoch: 25/50, Train Loss: 0.321083, Test Loss: 0.614752\n",
    "Epoch: 26/50, Train Loss: 0.302595, Test Loss: 0.595510\n",
    "Epoch: 27/50, Train Loss: 0.288370, Test Loss: 0.593484\n",
    "Epoch: 28/50, Train Loss: 0.290665, Test Loss: 0.593706\n",
    "Epoch: 29/50, Train Loss: 0.290554, Test Loss: 0.589860\n",
    "Epoch: 30/50, Train Loss: 0.280005, Test Loss: 0.585263\n",
    "Epoch: 31/50, Train Loss: 0.275038, Test Loss: 0.587297\n",
    "Epoch: 32/50, Train Loss: 0.281734, Test Loss: 0.583601\n",
    "Epoch: 33/50, Train Loss: 0.272425, Test Loss: 0.578521\n",
    "Epoch: 34/50, Train Loss: 0.270424, Test Loss: 0.576876\n",
    "Epoch: 35/50, Train Loss: 0.267324, Test Loss: 0.574651\n",
    "Epoch: 36/50, Train Loss: 0.269226, Test Loss: 0.568841\n",
    "Epoch: 37/50, Train Loss: 0.261017, Test Loss: 0.564700\n",
    "Epoch: 38/50, Train Loss: 0.262115, Test Loss: 0.562525\n",
    "Epoch: 39/50, Train Loss: 0.259076, Test Loss: 0.557713\n",
    "Epoch: 40/50, Train Loss: 0.261602, Test Loss: 0.548978\n",
    "Epoch: 41/50, Train Loss: 0.252149, Test Loss: 0.549041\n",
    "Epoch: 42/50, Train Loss: 0.253755, Test Loss: 0.547129\n",
    "Epoch: 43/50, Train Loss: 0.249239, Test Loss: 0.550541\n",
    "Epoch: 44/50, Train Loss: 0.253511, Test Loss: 0.552814\n",
    "Epoch: 45/50, Train Loss: 0.283017, Test Loss: 0.548239\n",
    "Epoch: 46/50, Train Loss: 0.265073, Test Loss: 0.553083\n",
    "Epoch: 47/50, Train Loss: 0.256423, Test Loss: 0.535140\n",
    "Epoch: 48/50, Train Loss: 0.249406, Test Loss: 0.541650\n",
    "Epoch: 49/50, Train Loss: 0.249808, Test Loss: 0.530133\n",
    "Epoch: 50/50, Train Loss: 0.244420, Test Loss: 0.532339\n",
    "'''\n",
    "\n",
    "# Extract the losses from the output\n",
    "loss_data = output.strip().split('\\n')\n",
    "\n",
    "# Initialize lists to store the train and test losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Loop through each line in the loss_data\n",
    "for line in loss_data:\n",
    "    # Split the line by commas and extract the losses\n",
    "    parts = line.split(',')\n",
    "    train_loss_str = parts[1]\n",
    "    test_loss_str = parts[2]\n",
    "    \n",
    "    train_loss = float(train_loss_str.split(':')[1].strip())\n",
    "    test_loss = float(test_loss_str.split(':')[1].strip())\n",
    "\n",
    "    # Append the losses to their respective lists\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51647965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d760f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366687a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "725a6392",
   "metadata": {},
   "source": [
    "## Tensorflow vs PyTorch  <a class=\"anchor\" id=\"seven\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac747f0",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e748695",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40cc17",
   "metadata": {},
   "source": [
    "* Both codes define an autoencoder model architecture that consists of an encoder and a decoder, and the size of the layers decreases progressively towards the bottleneck.\n",
    "* They both start by defining the input size and calculating the sizes of the hidden layer and the bottleneck layer. The sizes are calculated the same way: the hidden layer is half the size of the input layer, and the bottleneck layer is half the size of the hidden layer.\n",
    "* Both models use the ReLU activation function for the hidden layers.\n",
    "* Both models use linear transformation for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708982f",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018ae26",
   "metadata": {},
   "source": [
    "* **Library and Syntax:** The main difference between the two codes is the deep learning library they use. The first code uses TensorFlow with Keras API, which uses a functional API for defining models. The second code uses PyTorch, which uses an object-oriented approach. The way models are defined and the syntax used are different due to these library differences.\n",
    "\n",
    "* **Layer Definition:** In the TensorFlow code, each layer is explicitly defined one at a time and connected to the previous one. In the PyTorch code, layers are defined inside the nn.Sequential(), which automatically connects the layers in the order they are defined.\n",
    "\n",
    "* **Model Structure:** In the TensorFlow code, two models are returned: the autoencoder model and the encoder model. The PyTorch code only defines and returns the autoencoder model. If you wanted the encoder model in PyTorch, you'd need to access the .encoder attribute of an instance of the Autoencoder class.\n",
    "\n",
    "* **Forward Pass:** In the TensorFlow code, the forward pass (how data moves through the network during inference) is implicitly defined by the order in which layers are defined and connected. In PyTorch, the forward pass is explicitly defined in the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1a270",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5def6",
   "metadata": {},
   "source": [
    "The TensorFlow code appears more succinct due to the high-level abstraction provided by Keras. In Keras (and thus in TensorFlow, which has integrated Keras as its official high-level API), many of the lower-level details are abstracted away, making the code shorter and easier to understand. \n",
    "\n",
    "For instance:  \n",
    " The TensorFlow code uses the Keras Model class to define and instantiate the model in just a few lines of code. The model structure, including the layers and their connections, is defined all at once.  \n",
    " The TensorFlow code doesn't include the definition of a training loop or loss function, as these are typically handled by built-in functions such as model.fit() in TensorFlow/Keras. The use of these built-in functions contributes to the succinctness of the TensorFlow code.\n",
    "\n",
    "  On the other hand, PyTorch provides a more granular and explicit interface, which allows for greater flexibility and control, but may also require more code.  \n",
    "  This is especially apparent in the way PyTorch code often includes explicit definitions for the forward pass, loss function, and training loop. \n",
    "  \n",
    "While this might make PyTorch code longer and more verbose, it can also make it more transparent and easier to debug, as it offers more control over the individual operations that the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856222e3",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25486b1c",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e8e90",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db18960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e206b0ee",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744b1f3",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd134577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49f328a",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5ece0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
