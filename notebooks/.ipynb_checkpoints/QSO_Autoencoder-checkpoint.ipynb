{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7eb2c4",
   "metadata": {},
   "source": [
    "# Performing QSO Classification using Variational Autoencoders¶\n",
    "\n",
    "This notebook performs Quasar Classification via a simple Autoencoder. The frameworks used for this deep learning model are Tensorflow and Pytorch.\n",
    "\n",
    "\n",
    "## Authors\n",
    "\n",
    "* Ash Karale\n",
    "    \n",
    "\n",
    "## Contents:\n",
    "\n",
    "* [Introduction](#one)\n",
    "* [Importing Modules](#two)\n",
    "* [Data Acquisition](#three)\n",
    "* [Data Processing](#four)\n",
    "* [Model Definition](#five)\n",
    "* [Model Training](#six)\n",
    "\n",
    "\n",
    "## Versions:\n",
    "\n",
    "Initial Version: November 2022 (Ash Karale)\n",
    "\n",
    "Updated Version: April 2023 (Ash Karale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6223a6a",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction <a class=\"anchor\" id=\"one\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d138f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac234f8",
   "metadata": {},
   "source": [
    "## Importing Modules <a class=\"anchor\" id=\"two\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468c32b",
   "metadata": {},
   "source": [
    "It is considered good practice to import all the modules at the beginning of a Jupyter Notebook or any Python program.\n",
    "By importing all the modules at the start, we ensure that the required dependencies are present and available when we need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648dcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n",
      "[Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# Importing all required modules\n",
    "\n",
    "# System modules allow Python programs to interact with the operating system and perform tasks \n",
    "# such as reading and writing files, managing processes, and accessing environment variables \n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Data manipulation modules allow users to perform various operations on data,\n",
    "# such as cleaning, transforming, aggregating, filtering, and visualizing data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization modules allow users to create visual representations of data\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import palettable\n",
    "import seaborn as sns\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# Scikit-learn provides a range of supervised and unsupervised learning algorithms,\n",
    "# as well as tools for model selection and data preprocessing\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "# Scipy is a Python library for scientific computing and technical computing\n",
    "from scipy import stats\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "# Astropy is a Python library for astronomy and astrophysics\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# TensorFlow is an open-source machine learning library that provides an extensive set of tools and libraries\n",
    "# for building,training, and deploying neural networks, as well as other machine learning algorithms\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# PyTorch is an open-source machine learning library for Python that provides a range of tools\n",
    "# and functions for building and training neural networks and other machine learning models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d6452",
   "metadata": {},
   "source": [
    "## Data Acquisition <a class=\"anchor\" id=\"three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfde60f",
   "metadata": {},
   "source": [
    "Data Acquisition refers to the process of collecting and gathering data from various sources. It is the first step in the data analysis pipeline and involves identifying the sources of data and obtaining the data in a usable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192039dd",
   "metadata": {},
   "source": [
    "This line sets the path to the data. Should another data source be used, replace the line in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97acfd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ash/Research/Data/DELVE/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining a variable named 'data_dir' and assigning it the string value /Users/ash/Research/Data/DELVE/ \n",
    "# This is the path to the directory where the dataset is stored on the local machine\n",
    "data_dir = '/Users/ash/Research/Data/DELVE/'\n",
    "\n",
    "# Using the display() function to display the value of the 'data_dir' variable in the output of the Jupyter Notebook\n",
    "display(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d274f",
   "metadata": {},
   "source": [
    "Reading in the data file.\n",
    "We use Astropy's Table to read in data files because it provides a powerful and flexible way to manipulate and work with tabular data, such as data stored in CSV, FITS, or other formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bfb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "# Reading a data file stored in the FITS format using the Table.read() method \n",
    "# The path to the data file is constructed using the os.path.join() method to join the data_dir variable, \n",
    "# which specifies the directory containing the data file, and the filename 'fullcat15_30.fits'\n",
    "data = Table.read(os.path.join(data_dir, 'fullcat15_30.fits'))\n",
    "\n",
    "# Converting the FITS formatted data to a Pandas DataFrame using the to_pandas() method\n",
    "# of the Table object for easier pandas manipulation\n",
    "fcDF_15_30 = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aeef54",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "\n",
    "Measurements fall into the following main catalogries:\n",
    "- __Astromety__ -> ra, dec, proper motion and parallax\n",
    "- __Photometry__ -> point and extended source photometry, in both AB magnitdues and fluxes (nJy)\n",
    "- __Color__ -> Computed using the fluxes\n",
    "- __Morphology__ -> 1 for extended and 0 for point-like\n",
    "- __Light Curve Features__ -> Extrated on the SDSS light curves if matched\n",
    "- __Redshift__ -> Both spectroscopic and photometric, wherever available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be40be1",
   "metadata": {},
   "source": [
    "Inspecting the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8b051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  list of feature column names for the dataset\n",
    "# These features include photometric magnitudes, extended class, proper motion, and radial velocity\n",
    "fc_list = [\n",
    "    'mag_auto_g', 'mag_auto_i', 'mag_auto_r', 'mag_auto_z', \n",
    "    # Magnitudes in g, i, r, and z bandsfrom AUTO photometry\n",
    "    'ypetromag', 'jpetromag', 'hpetromag', 'kspetromag',\n",
    "    # Magnitudes in Y, J, H, and Ks bands from Petrosian photometry\n",
    "    'w1mpro', 'w2mpro',\n",
    "    # Magnitudes in WISE 1 and WISE 2 bands\n",
    "    'extended_class_g', 'extended_class_r', 'extended_class_i', 'extended_class_z', \n",
    "    # Extended class in g, r, i, and z bands\n",
    "    'pm', 'pmdec', 'pmra', \n",
    "    # Total proper motion, proper motion in declination, and proper motion in right ascension\n",
    "    'radial_velocity',  \n",
    "    # Radial velocity of the objects\n",
    "    'classprob_dsc_combmod_star','classprob_dsc_combmod_galaxy','classprob_dsc_combmod_quasar', \n",
    "    # Classification of the objects (e.g., star, galaxy, QSO)\n",
    "]\n",
    "\n",
    "# Selecting a subset of columns from the DataFrame 'fcDF_15_30' based on the list 'fc_list'\n",
    "fcDF_15_30 = fcDF_15_30[fc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ba7c4",
   "metadata": {},
   "source": [
    "Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cafe091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_auto_g</th>\n",
       "      <th>mag_auto_i</th>\n",
       "      <th>mag_auto_r</th>\n",
       "      <th>mag_auto_z</th>\n",
       "      <th>ypetromag</th>\n",
       "      <th>jpetromag</th>\n",
       "      <th>hpetromag</th>\n",
       "      <th>kspetromag</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>...</th>\n",
       "      <th>extended_class_r</th>\n",
       "      <th>extended_class_i</th>\n",
       "      <th>extended_class_z</th>\n",
       "      <th>pm</th>\n",
       "      <th>pmdec</th>\n",
       "      <th>pmra</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_combmod_galaxy</th>\n",
       "      <th>classprob_dsc_combmod_quasar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.312523e+06</td>\n",
       "      <td>7.681616e+06</td>\n",
       "      <td>2.162878e+06</td>\n",
       "      <td>6.286130e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>48494.000000</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.621252e+01</td>\n",
       "      <td>2.265878e+01</td>\n",
       "      <td>2.480181e+01</td>\n",
       "      <td>2.248277e+01</td>\n",
       "      <td>1.857671e+01</td>\n",
       "      <td>1.867103e+01</td>\n",
       "      <td>1.783285e+01</td>\n",
       "      <td>1.714291e+01</td>\n",
       "      <td>1.680659e+01</td>\n",
       "      <td>1.663629e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607298e+00</td>\n",
       "      <td>1.857492e+00</td>\n",
       "      <td>1.831789e+00</td>\n",
       "      <td>1.386721e+01</td>\n",
       "      <td>-3.923559e+00</td>\n",
       "      <td>8.006602e+00</td>\n",
       "      <td>15.065438</td>\n",
       "      <td>9.447181e-01</td>\n",
       "      <td>3.015133e-02</td>\n",
       "      <td>2.166022e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.001855e+01</td>\n",
       "      <td>1.282219e+01</td>\n",
       "      <td>1.652845e+01</td>\n",
       "      <td>1.344820e+01</td>\n",
       "      <td>1.565382e+00</td>\n",
       "      <td>1.523811e+00</td>\n",
       "      <td>1.433349e+00</td>\n",
       "      <td>1.274097e+00</td>\n",
       "      <td>1.079368e+00</td>\n",
       "      <td>1.070547e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654142e+00</td>\n",
       "      <td>2.206325e+00</td>\n",
       "      <td>2.266141e+00</td>\n",
       "      <td>1.607001e+01</td>\n",
       "      <td>1.240325e+01</td>\n",
       "      <td>1.473784e+01</td>\n",
       "      <td>42.134888</td>\n",
       "      <td>2.224325e-01</td>\n",
       "      <td>1.683584e-01</td>\n",
       "      <td>1.381415e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.278190e+01</td>\n",
       "      <td>1.167814e+01</td>\n",
       "      <td>1.210906e+01</td>\n",
       "      <td>1.139630e+01</td>\n",
       "      <td>1.037403e+01</td>\n",
       "      <td>9.689001e+00</td>\n",
       "      <td>8.260656e+00</td>\n",
       "      <td>8.256360e+00</td>\n",
       "      <td>7.068000e+00</td>\n",
       "      <td>6.085000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>2.600000e-03</td>\n",
       "      <td>-8.026215e+02</td>\n",
       "      <td>-3.656444e+02</td>\n",
       "      <td>-389.880100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137134e+01</td>\n",
       "      <td>1.974994e+01</td>\n",
       "      <td>2.029234e+01</td>\n",
       "      <td>1.943825e+01</td>\n",
       "      <td>1.778231e+01</td>\n",
       "      <td>1.793413e+01</td>\n",
       "      <td>1.716681e+01</td>\n",
       "      <td>1.654000e+01</td>\n",
       "      <td>1.628600e+01</td>\n",
       "      <td>1.608700e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.070828e+00</td>\n",
       "      <td>-7.266419e+00</td>\n",
       "      <td>8.808007e-01</td>\n",
       "      <td>-5.499497</td>\n",
       "      <td>9.995270e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.271964e+01</td>\n",
       "      <td>2.084213e+01</td>\n",
       "      <td>2.150048e+01</td>\n",
       "      <td>2.049579e+01</td>\n",
       "      <td>1.887614e+01</td>\n",
       "      <td>1.897750e+01</td>\n",
       "      <td>1.812667e+01</td>\n",
       "      <td>1.739955e+01</td>\n",
       "      <td>1.693600e+01</td>\n",
       "      <td>1.674200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.908950e+00</td>\n",
       "      <td>-1.996961e+00</td>\n",
       "      <td>5.454478e+00</td>\n",
       "      <td>12.312459</td>\n",
       "      <td>9.999640e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406641e+01</td>\n",
       "      <td>2.170479e+01</td>\n",
       "      <td>2.257661e+01</td>\n",
       "      <td>2.128124e+01</td>\n",
       "      <td>1.971436e+01</td>\n",
       "      <td>1.974666e+01</td>\n",
       "      <td>1.882400e+01</td>\n",
       "      <td>1.802353e+01</td>\n",
       "      <td>1.753000e+01</td>\n",
       "      <td>1.738200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.731142e+01</td>\n",
       "      <td>9.636427e-01</td>\n",
       "      <td>1.218151e+01</td>\n",
       "      <td>31.317938</td>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.868277e+01</td>\n",
       "      <td>3.056738e+01</td>\n",
       "      <td>2.972356e+01</td>\n",
       "      <td>3.215351e+01</td>\n",
       "      <td>2.004100e+01</td>\n",
       "      <td>1.889200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.026368e+02</td>\n",
       "      <td>5.512816e+02</td>\n",
       "      <td>6.766674e+02</td>\n",
       "      <td>761.085100</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mag_auto_g    mag_auto_i    mag_auto_r    mag_auto_z     ypetromag  \\\n",
       "count  8.226904e+06  8.226904e+06  8.226904e+06  8.226904e+06  1.312523e+06   \n",
       "mean   3.621252e+01  2.265878e+01  2.480181e+01  2.248277e+01  1.857671e+01   \n",
       "std    3.001855e+01  1.282219e+01  1.652845e+01  1.344820e+01  1.565382e+00   \n",
       "min    1.278190e+01  1.167814e+01  1.210906e+01  1.139630e+01  1.037403e+01   \n",
       "25%    2.137134e+01  1.974994e+01  2.029234e+01  1.943825e+01  1.778231e+01   \n",
       "50%    2.271964e+01  2.084213e+01  2.150048e+01  2.049579e+01  1.887614e+01   \n",
       "75%    2.406641e+01  2.170479e+01  2.257661e+01  2.128124e+01  1.971436e+01   \n",
       "max    9.900000e+01  9.900000e+01  9.900000e+01  9.900000e+01  2.868277e+01   \n",
       "\n",
       "          jpetromag     hpetromag    kspetromag        w1mpro        w2mpro  \\\n",
       "count  7.681616e+06  2.162878e+06  6.286130e+06  8.226904e+06  8.226904e+06   \n",
       "mean   1.867103e+01  1.783285e+01  1.714291e+01  1.680659e+01  1.663629e+01   \n",
       "std    1.523811e+00  1.433349e+00  1.274097e+00  1.079368e+00  1.070547e+00   \n",
       "min    9.689001e+00  8.260656e+00  8.256360e+00  7.068000e+00  6.085000e+00   \n",
       "25%    1.793413e+01  1.716681e+01  1.654000e+01  1.628600e+01  1.608700e+01   \n",
       "50%    1.897750e+01  1.812667e+01  1.739955e+01  1.693600e+01  1.674200e+01   \n",
       "75%    1.974666e+01  1.882400e+01  1.802353e+01  1.753000e+01  1.738200e+01   \n",
       "max    3.056738e+01  2.972356e+01  3.215351e+01  2.004100e+01  1.889200e+01   \n",
       "\n",
       "       ...  extended_class_r  extended_class_i  extended_class_z  \\\n",
       "count  ...      8.226904e+06      8.226904e+06      8.226904e+06   \n",
       "mean   ...      1.607298e+00      1.857492e+00      1.831789e+00   \n",
       "std    ...      2.654142e+00      2.206325e+00      2.266141e+00   \n",
       "min    ...     -9.000000e+00     -9.000000e+00     -9.000000e+00   \n",
       "25%    ...      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "50%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "75%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "max    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "\n",
       "                 pm         pmdec          pmra  radial_velocity  \\\n",
       "count  1.557373e+06  1.557373e+06  1.557373e+06     48494.000000   \n",
       "mean   1.386721e+01 -3.923559e+00  8.006602e+00        15.065438   \n",
       "std    1.607001e+01  1.240325e+01  1.473784e+01        42.134888   \n",
       "min    2.600000e-03 -8.026215e+02 -3.656444e+02      -389.880100   \n",
       "25%    5.070828e+00 -7.266419e+00  8.808007e-01        -5.499497   \n",
       "50%    9.908950e+00 -1.996961e+00  5.454478e+00        12.312459   \n",
       "75%    1.731142e+01  9.636427e-01  1.218151e+01        31.317938   \n",
       "max    8.026368e+02  5.512816e+02  6.766674e+02       761.085100   \n",
       "\n",
       "       classprob_dsc_combmod_star  classprob_dsc_combmod_galaxy  \\\n",
       "count                1.854957e+06                  1.854957e+06   \n",
       "mean                 9.447181e-01                  3.015133e-02   \n",
       "std                  2.224325e-01                  1.683584e-01   \n",
       "min                  0.000000e+00                  0.000000e+00   \n",
       "25%                  9.995270e-01                  0.000000e+00   \n",
       "50%                  9.999640e-01                  0.000000e+00   \n",
       "75%                  9.999900e-01                  0.000000e+00   \n",
       "max                  1.000000e+00                  1.000000e+00   \n",
       "\n",
       "       classprob_dsc_combmod_quasar  \n",
       "count                  1.854957e+06  \n",
       "mean                   2.166022e-02  \n",
       "std                    1.381415e-01  \n",
       "min                    0.000000e+00  \n",
       "25%                    0.000000e+00  \n",
       "50%                    0.000000e+00  \n",
       "75%                    0.000000e+00  \n",
       "max                    1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display descriptive statistics to describe and explore data\n",
    "\n",
    "# The describe() method provides summary statistics for each column of the DataFrame, \n",
    "# giving insight into the distribution and spread of the data \n",
    "fcDF_15_30.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618961",
   "metadata": {},
   "source": [
    "## Data Processing <a class=\"anchor\" id=\"four\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24666461",
   "metadata": {},
   "source": [
    "Data Processing refers to the process of transforming raw data into a form that is suitable for analysis. It involves a series of steps that may include data cleaning, data integration, data transformation, data reduction, and data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df42e7",
   "metadata": {},
   "source": [
    "Create a subset with the maximal number of objects where the data values are meaningful.\n",
    "Specifically-\n",
    "* Merge the Star, Galaxy, and QSO attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f77ee96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list 'fc15_30' to a Pandas DataFrame using the pd.DataFrame() method\n",
    "fcDF_15_30 = pd.DataFrame(fcDF_15_30)\n",
    "\n",
    "# Replacing the string values of the columns named 'classprob_dsc_combmod_star', 'classprob_dsc_combmod_galaxy',\n",
    "# and 'classprob_dsc_combmod_quasar' with numerical values 0, 1, and 2, respectively.\n",
    "fcDF_15_30 = fcDF_15_30.replace({'classprob_dsc_combmod_star': 0,\n",
    "                           'classprob_dsc_combmod_galaxy': 1,\n",
    "                           'classprob_dsc_combmod_quasar': 2})\n",
    "\n",
    "# Define a function to determine the class based on the highest class probability\n",
    "# The function called 'assign_class' that takes a row as input, and based on the \n",
    "# class probabilities for each object, assigns the object to one of the classes\n",
    "def assign_class(row):\n",
    "    star_prob = row['classprob_dsc_combmod_star']\n",
    "    galaxy_prob = row['classprob_dsc_combmod_galaxy']\n",
    "    quasar_prob = row['classprob_dsc_combmod_quasar']\n",
    "    \n",
    "    if star_prob > galaxy_prob and star_prob > quasar_prob:\n",
    "        return 0\n",
    "    elif galaxy_prob > quasar_prob:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Merging the class probability attributes of galaxies, quasars, and stars into a single 'class' attribute \n",
    "# based on the highest probability value\n",
    "# The apply() method applies the function 'assign_class' to each row of the DataFrame\n",
    "fcDF_15_30['class'] = fcDF_15_30[['classprob_dsc_combmod_galaxy', 'classprob_dsc_combmod_quasar',\n",
    "                            'classprob_dsc_combmod_star']].apply(assign_class, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a87859",
   "metadata": {},
   "source": [
    "## Model Definition <a class=\"anchor\" id=\"five\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e1ba7",
   "metadata": {},
   "source": [
    "Model architecture refers to the overall structure and design of a machine learning model. It includes the number and type of layers, the number of neurons or units in each layer, the activation functions used in each layer, the optimization algorithm used for training, and other design choices that are made when creating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cd6b5",
   "metadata": {},
   "source": [
    "As we proceed with unsupervised classification, it is necessary to have functions to evaluate the performance of the models and the quality of the clustering results. \n",
    "The following functions are commonly used for evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2c7bb",
   "metadata": {},
   "source": [
    "## Model Training <a class=\"anchor\" id=\"six\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384b461",
   "metadata": {},
   "source": [
    "Model training is the process of training a machine learning model to make accurate predictions on new data.\n",
    "In unsupervised learning, model training refers to the process of learning the underlying structure of the data without the use of explicit labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d081e37",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b0c7e",
   "metadata": {},
   "source": [
    "Data Loading is a critical step in the data preprocessing pipeline and involves preparing the data for use in a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a13efc",
   "metadata": {},
   "source": [
    "To help ensure that the data is correctly loaded and preprocessed, two of the most common programming constructs are defined below: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc63423",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2d2e",
   "metadata": {},
   "source": [
    "Training Loop refers to the process of iteratively optimizing the internal parameters of a model to minimize the error on a training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
