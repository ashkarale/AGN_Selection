{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7eb2c4",
   "metadata": {},
   "source": [
    "# Performing QSO Classification using Variational AutoencodersÂ¶\n",
    "\n",
    "This notebook performs Quasar Classification via a simple Autoencoder. The frameworks used for this deep learning model are TensorFlow and Pytorch.\n",
    "\n",
    "\n",
    "## Authors\n",
    "\n",
    "* Ash Karale\n",
    "    \n",
    "\n",
    "## Contents:\n",
    "\n",
    "* [Introduction](#one)\n",
    "* [Importing Modules](#two)\n",
    "* [Data Acquisition](#three)\n",
    "* [Data Processing](#four)\n",
    "* [TensorFlow](#five)\n",
    "* [PyTorch](#six)\n",
    "* [TensorFlow vs PyTorch](#seven)\n",
    "\n",
    "\n",
    "## Versions:\n",
    "\n",
    "Initial Version: November 2022 (Ash Karale)\n",
    "\n",
    "Updated Version: April 2023 (Ash Karale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6223a6a",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction <a class=\"anchor\" id=\"one\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206739fd",
   "metadata": {},
   "source": [
    "### Plan is to explain the dataset first, and what we aim to do with it. Next, an introduction to autoencoders and why we chose it. Lastly, an introduction to TensorFlow and PyTorch- I am thinking just a brief paragraph or two as I will write more about them in their cell blocks below\n",
    "\n",
    "TensorFlow and PyTorch are two of the most popular deep learning frameworks. They allow developers to build and train machine learning models using a variety of techniques, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac234f8",
   "metadata": {},
   "source": [
    "## Importing Modules <a class=\"anchor\" id=\"two\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468c32b",
   "metadata": {},
   "source": [
    "It is widely recommended to include the import statements for all the necessary modules at the beginning of a Jupyter Notebook or any Python program. \n",
    "This practice ensures that the required dependencies are properly imported and accessible at the required points in the code, thus avoiding any potential issues or errors related to missing modules or dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648dcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n",
      "[Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# Importing all required modules\n",
    "\n",
    "# System modules allow Python programs to interact with the operating system and perform tasks \n",
    "# such as reading and writing files, managing processes, and accessing environment variables \n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Data manipulation modules allow users to perform various operations on data,\n",
    "# such as cleaning, transforming, aggregating, filtering, and visualizing data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization modules allow users to create visual representations of data\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import palettable\n",
    "import seaborn as sns\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# Scikit-learn provides a range of supervised and unsupervised learning algorithms,\n",
    "# as well as tools for model selection and data preprocessing\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "# Scipy is a Python library for scientific computing and technical computing\n",
    "from scipy import stats\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "# Astropy is a Python library for astronomy and astrophysics\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# TensorFlow is an open-source machine learning library that provides an extensive set of tools and libraries\n",
    "# for building,training, and deploying neural networks, as well as other machine learning algorithms\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# PyTorch is an open-source machine learning library for Python that provides a range of tools\n",
    "# and functions for building and training neural networks and other machine learning models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d6452",
   "metadata": {},
   "source": [
    "## Data Acquisition <a class=\"anchor\" id=\"three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfde60f",
   "metadata": {},
   "source": [
    "Data acquisition involves the collection and aggregation of data from diverse sources. This crucial initial stage in the data analysis pipeline entails recognizing data sources and acquiring the data in a format suitable for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192039dd",
   "metadata": {},
   "source": [
    "The provided statement establishes the data pathway. If an alternative data source is required, the line in the subsequent cell should be substituted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97acfd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ash/Research/Data/DELVE/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining a variable named 'data_dir' and assigning it the string value /Users/ash/Research/Data/DELVE/ \n",
    "# This is the path to the directory where the dataset is stored on the local machine\n",
    "data_dir = '/Users/ash/Research/Data/DELVE/'\n",
    "\n",
    "# Using the display() function to display the value of the 'data_dir' variable in the output of the Jupyter Notebook\n",
    "display(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d274f",
   "metadata": {},
   "source": [
    "Data file reading is performed using Astropy's Table module due to its versatility and efficiency in handling tabular data. \n",
    "Astropy's Table offers a robust solution for manipulating and analyzing various file formats, including CSV, FITS, and more. This choice is driven by the comprehensive functionality and adaptability provided by Astropy's Table, making it an ideal tool for working with tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bfb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "# Reading a data file stored in the FITS format using the Table.read() method \n",
    "# The path to the data file is constructed using the os.path.join() method to join the data_dir variable, \n",
    "# which specifies the directory containing the data file, and the filename 'fullcat15_30.fits'\n",
    "data = Table.read(os.path.join(data_dir, 'fullcat15_30.fits'))\n",
    "\n",
    "# Converting the FITS formatted data to a Pandas DataFrame using the to_pandas() method\n",
    "# of the Table object for easier pandas manipulation\n",
    "fcDF_15_30 = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aeef54",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "\n",
    "The measurements can be classified into several key categories:\n",
    "- __Astrometry__ includes measurements of celestial coordinates such as right ascension (RA), declination (Dec), proper motion, and parallax.\n",
    "- __Photometry__ encompasses both point and extended source photometry, providing measurements in terms of AB magnitudes and fluxes (expressed in nJy).\n",
    "- __Color__ is determined by computing the ratios of fluxes in different wavelength bands.\n",
    "- __Morphology__ is indicated by a binary value, with 1 representing extended sources and 0 representing point-like sources.\n",
    "- __Light Curve Features__ are extracted from the SDSS light curves when a match is found.\n",
    "- __Redshift__ is provided whenever available, including both spectroscopic and photometric measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be40be1",
   "metadata": {},
   "source": [
    "Inspecting the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8b051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  list of feature column names for the dataset\n",
    "# These features include photometric magnitudes, extended class, proper motion, and radial velocity\n",
    "fc_list = [\n",
    "    'mag_auto_g', 'mag_auto_i', 'mag_auto_r', 'mag_auto_z', \n",
    "    # Magnitudes in g, i, r, and z bandsfrom AUTO photometry\n",
    "    'ypetromag', 'jpetromag', 'hpetromag', 'kspetromag',\n",
    "    # Magnitudes in Y, J, H, and Ks bands from Petrosian photometry\n",
    "    'w1mpro', 'w2mpro',\n",
    "    # Magnitudes in WISE 1 and WISE 2 bands\n",
    "    'extended_class_g', 'extended_class_r', 'extended_class_i', 'extended_class_z', \n",
    "    # Extended class in g, r, i, and z bands\n",
    "    'pm', 'pmdec', 'pmra', \n",
    "    # Total proper motion, proper motion in declination, and proper motion in right ascension\n",
    "    'radial_velocity',  \n",
    "    # Radial velocity of the objects\n",
    "    'classprob_dsc_combmod_star','classprob_dsc_combmod_galaxy','classprob_dsc_combmod_quasar', \n",
    "    # Classification of the objects (e.g., star, galaxy, QSO)\n",
    "]\n",
    "\n",
    "# Selecting a subset of columns from the DataFrame 'fcDF_15_30' based on the list 'fc_list'\n",
    "fcDF_15_30 = fcDF_15_30[fc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ba7c4",
   "metadata": {},
   "source": [
    "Data visualization involves the process of representing data in a visual or graphical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafe091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_auto_g</th>\n",
       "      <th>mag_auto_i</th>\n",
       "      <th>mag_auto_r</th>\n",
       "      <th>mag_auto_z</th>\n",
       "      <th>ypetromag</th>\n",
       "      <th>jpetromag</th>\n",
       "      <th>hpetromag</th>\n",
       "      <th>kspetromag</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>...</th>\n",
       "      <th>extended_class_r</th>\n",
       "      <th>extended_class_i</th>\n",
       "      <th>extended_class_z</th>\n",
       "      <th>pm</th>\n",
       "      <th>pmdec</th>\n",
       "      <th>pmra</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_combmod_galaxy</th>\n",
       "      <th>classprob_dsc_combmod_quasar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.312523e+06</td>\n",
       "      <td>7.681616e+06</td>\n",
       "      <td>2.162878e+06</td>\n",
       "      <td>6.286130e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>48494.000000</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.621252e+01</td>\n",
       "      <td>2.265878e+01</td>\n",
       "      <td>2.480181e+01</td>\n",
       "      <td>2.248277e+01</td>\n",
       "      <td>1.857671e+01</td>\n",
       "      <td>1.867103e+01</td>\n",
       "      <td>1.783285e+01</td>\n",
       "      <td>1.714291e+01</td>\n",
       "      <td>1.680659e+01</td>\n",
       "      <td>1.663629e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607298e+00</td>\n",
       "      <td>1.857492e+00</td>\n",
       "      <td>1.831789e+00</td>\n",
       "      <td>1.386721e+01</td>\n",
       "      <td>-3.923559e+00</td>\n",
       "      <td>8.006602e+00</td>\n",
       "      <td>15.065438</td>\n",
       "      <td>9.447181e-01</td>\n",
       "      <td>3.015133e-02</td>\n",
       "      <td>2.166022e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.001855e+01</td>\n",
       "      <td>1.282219e+01</td>\n",
       "      <td>1.652845e+01</td>\n",
       "      <td>1.344820e+01</td>\n",
       "      <td>1.565382e+00</td>\n",
       "      <td>1.523811e+00</td>\n",
       "      <td>1.433349e+00</td>\n",
       "      <td>1.274097e+00</td>\n",
       "      <td>1.079368e+00</td>\n",
       "      <td>1.070547e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654142e+00</td>\n",
       "      <td>2.206325e+00</td>\n",
       "      <td>2.266141e+00</td>\n",
       "      <td>1.607001e+01</td>\n",
       "      <td>1.240325e+01</td>\n",
       "      <td>1.473784e+01</td>\n",
       "      <td>42.134888</td>\n",
       "      <td>2.224325e-01</td>\n",
       "      <td>1.683584e-01</td>\n",
       "      <td>1.381415e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.278190e+01</td>\n",
       "      <td>1.167814e+01</td>\n",
       "      <td>1.210906e+01</td>\n",
       "      <td>1.139630e+01</td>\n",
       "      <td>1.037403e+01</td>\n",
       "      <td>9.689001e+00</td>\n",
       "      <td>8.260656e+00</td>\n",
       "      <td>8.256360e+00</td>\n",
       "      <td>7.068000e+00</td>\n",
       "      <td>6.085000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>2.600000e-03</td>\n",
       "      <td>-8.026215e+02</td>\n",
       "      <td>-3.656444e+02</td>\n",
       "      <td>-389.880100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137134e+01</td>\n",
       "      <td>1.974994e+01</td>\n",
       "      <td>2.029234e+01</td>\n",
       "      <td>1.943825e+01</td>\n",
       "      <td>1.778231e+01</td>\n",
       "      <td>1.793413e+01</td>\n",
       "      <td>1.716681e+01</td>\n",
       "      <td>1.654000e+01</td>\n",
       "      <td>1.628600e+01</td>\n",
       "      <td>1.608700e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.070828e+00</td>\n",
       "      <td>-7.266419e+00</td>\n",
       "      <td>8.808007e-01</td>\n",
       "      <td>-5.499497</td>\n",
       "      <td>9.995270e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.271964e+01</td>\n",
       "      <td>2.084213e+01</td>\n",
       "      <td>2.150048e+01</td>\n",
       "      <td>2.049579e+01</td>\n",
       "      <td>1.887614e+01</td>\n",
       "      <td>1.897750e+01</td>\n",
       "      <td>1.812667e+01</td>\n",
       "      <td>1.739955e+01</td>\n",
       "      <td>1.693600e+01</td>\n",
       "      <td>1.674200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.908950e+00</td>\n",
       "      <td>-1.996961e+00</td>\n",
       "      <td>5.454478e+00</td>\n",
       "      <td>12.312459</td>\n",
       "      <td>9.999640e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406641e+01</td>\n",
       "      <td>2.170479e+01</td>\n",
       "      <td>2.257661e+01</td>\n",
       "      <td>2.128124e+01</td>\n",
       "      <td>1.971436e+01</td>\n",
       "      <td>1.974666e+01</td>\n",
       "      <td>1.882400e+01</td>\n",
       "      <td>1.802353e+01</td>\n",
       "      <td>1.753000e+01</td>\n",
       "      <td>1.738200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.731142e+01</td>\n",
       "      <td>9.636427e-01</td>\n",
       "      <td>1.218151e+01</td>\n",
       "      <td>31.317938</td>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.868277e+01</td>\n",
       "      <td>3.056738e+01</td>\n",
       "      <td>2.972356e+01</td>\n",
       "      <td>3.215351e+01</td>\n",
       "      <td>2.004100e+01</td>\n",
       "      <td>1.889200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.026368e+02</td>\n",
       "      <td>5.512816e+02</td>\n",
       "      <td>6.766674e+02</td>\n",
       "      <td>761.085100</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mag_auto_g    mag_auto_i    mag_auto_r    mag_auto_z     ypetromag  \\\n",
       "count  8.226904e+06  8.226904e+06  8.226904e+06  8.226904e+06  1.312523e+06   \n",
       "mean   3.621252e+01  2.265878e+01  2.480181e+01  2.248277e+01  1.857671e+01   \n",
       "std    3.001855e+01  1.282219e+01  1.652845e+01  1.344820e+01  1.565382e+00   \n",
       "min    1.278190e+01  1.167814e+01  1.210906e+01  1.139630e+01  1.037403e+01   \n",
       "25%    2.137134e+01  1.974994e+01  2.029234e+01  1.943825e+01  1.778231e+01   \n",
       "50%    2.271964e+01  2.084213e+01  2.150048e+01  2.049579e+01  1.887614e+01   \n",
       "75%    2.406641e+01  2.170479e+01  2.257661e+01  2.128124e+01  1.971436e+01   \n",
       "max    9.900000e+01  9.900000e+01  9.900000e+01  9.900000e+01  2.868277e+01   \n",
       "\n",
       "          jpetromag     hpetromag    kspetromag        w1mpro        w2mpro  \\\n",
       "count  7.681616e+06  2.162878e+06  6.286130e+06  8.226904e+06  8.226904e+06   \n",
       "mean   1.867103e+01  1.783285e+01  1.714291e+01  1.680659e+01  1.663629e+01   \n",
       "std    1.523811e+00  1.433349e+00  1.274097e+00  1.079368e+00  1.070547e+00   \n",
       "min    9.689001e+00  8.260656e+00  8.256360e+00  7.068000e+00  6.085000e+00   \n",
       "25%    1.793413e+01  1.716681e+01  1.654000e+01  1.628600e+01  1.608700e+01   \n",
       "50%    1.897750e+01  1.812667e+01  1.739955e+01  1.693600e+01  1.674200e+01   \n",
       "75%    1.974666e+01  1.882400e+01  1.802353e+01  1.753000e+01  1.738200e+01   \n",
       "max    3.056738e+01  2.972356e+01  3.215351e+01  2.004100e+01  1.889200e+01   \n",
       "\n",
       "       ...  extended_class_r  extended_class_i  extended_class_z  \\\n",
       "count  ...      8.226904e+06      8.226904e+06      8.226904e+06   \n",
       "mean   ...      1.607298e+00      1.857492e+00      1.831789e+00   \n",
       "std    ...      2.654142e+00      2.206325e+00      2.266141e+00   \n",
       "min    ...     -9.000000e+00     -9.000000e+00     -9.000000e+00   \n",
       "25%    ...      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "50%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "75%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "max    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "\n",
       "                 pm         pmdec          pmra  radial_velocity  \\\n",
       "count  1.557373e+06  1.557373e+06  1.557373e+06     48494.000000   \n",
       "mean   1.386721e+01 -3.923559e+00  8.006602e+00        15.065438   \n",
       "std    1.607001e+01  1.240325e+01  1.473784e+01        42.134888   \n",
       "min    2.600000e-03 -8.026215e+02 -3.656444e+02      -389.880100   \n",
       "25%    5.070828e+00 -7.266419e+00  8.808007e-01        -5.499497   \n",
       "50%    9.908950e+00 -1.996961e+00  5.454478e+00        12.312459   \n",
       "75%    1.731142e+01  9.636427e-01  1.218151e+01        31.317938   \n",
       "max    8.026368e+02  5.512816e+02  6.766674e+02       761.085100   \n",
       "\n",
       "       classprob_dsc_combmod_star  classprob_dsc_combmod_galaxy  \\\n",
       "count                1.854957e+06                  1.854957e+06   \n",
       "mean                 9.447181e-01                  3.015133e-02   \n",
       "std                  2.224325e-01                  1.683584e-01   \n",
       "min                  0.000000e+00                  0.000000e+00   \n",
       "25%                  9.995270e-01                  0.000000e+00   \n",
       "50%                  9.999640e-01                  0.000000e+00   \n",
       "75%                  9.999900e-01                  0.000000e+00   \n",
       "max                  1.000000e+00                  1.000000e+00   \n",
       "\n",
       "       classprob_dsc_combmod_quasar  \n",
       "count                  1.854957e+06  \n",
       "mean                   2.166022e-02  \n",
       "std                    1.381415e-01  \n",
       "min                    0.000000e+00  \n",
       "25%                    0.000000e+00  \n",
       "50%                    0.000000e+00  \n",
       "75%                    0.000000e+00  \n",
       "max                    1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display descriptive statistics to describe and explore data\n",
    "\n",
    "# The describe() method provides summary statistics for each column of the DataFrame, \n",
    "# giving insight into the distribution and spread of the data \n",
    "fcDF_15_30.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618961",
   "metadata": {},
   "source": [
    "## Data Processing <a class=\"anchor\" id=\"four\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24666461",
   "metadata": {},
   "source": [
    "Data processing involves converting unprocessed data into a format that is appropriate for analysis. This encompasses several stages, such as data cleansing, data integration, data transformation, data reduction, and data visualization, with the objective of making the data more usable and insightful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df42e7",
   "metadata": {},
   "source": [
    "Form a subset containing the maximum possible number of objects that possess significant data values. \n",
    "* More specifically, combine the attributes related to Stars, Galaxies, and Quasars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77ee96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list 'fc15_30' to a Pandas DataFrame using the pd.DataFrame() method\n",
    "fcDF_15_30 = pd.DataFrame(fcDF_15_30)\n",
    "\n",
    "# Replacing the string values of the columns named 'classprob_dsc_combmod_star', 'classprob_dsc_combmod_galaxy',\n",
    "# and 'classprob_dsc_combmod_quasar' with numerical values 0, 1, and 2, respectively.\n",
    "fcDF_15_30 = fcDF_15_30.replace({'classprob_dsc_combmod_star': 0,\n",
    "                           'classprob_dsc_combmod_galaxy': 1,\n",
    "                           'classprob_dsc_combmod_quasar': 2})\n",
    "\n",
    "# Define a function to determine the class based on the highest class probability\n",
    "# The function called 'assign_class' that takes a row as input, and based on the \n",
    "# class probabilities for each object, assigns the object to one of the classes\n",
    "def assign_class(row):\n",
    "    star_prob = row['classprob_dsc_combmod_star']\n",
    "    galaxy_prob = row['classprob_dsc_combmod_galaxy']\n",
    "    quasar_prob = row['classprob_dsc_combmod_quasar']\n",
    "    \n",
    "    if star_prob > galaxy_prob and star_prob > quasar_prob:\n",
    "        return 0\n",
    "    elif galaxy_prob > quasar_prob:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Merging the class probability attributes of galaxies, quasars, and stars into a single 'class' attribute \n",
    "# based on the highest probability value\n",
    "# The apply() method applies the function 'assign_class' to each row of the DataFrame\n",
    "fcDF_15_30['class'] = fcDF_15_30[['classprob_dsc_combmod_galaxy', 'classprob_dsc_combmod_quasar',\n",
    "                            'classprob_dsc_combmod_star']].apply(assign_class, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b2d56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8226904, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8226904,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_auto_g</th>\n",
       "      <th>mag_auto_i</th>\n",
       "      <th>mag_auto_r</th>\n",
       "      <th>mag_auto_z</th>\n",
       "      <th>ypetromag</th>\n",
       "      <th>jpetromag</th>\n",
       "      <th>hpetromag</th>\n",
       "      <th>kspetromag</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>...</th>\n",
       "      <th>extended_class_r</th>\n",
       "      <th>extended_class_i</th>\n",
       "      <th>extended_class_z</th>\n",
       "      <th>pm</th>\n",
       "      <th>pmdec</th>\n",
       "      <th>pmra</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_combmod_galaxy</th>\n",
       "      <th>classprob_dsc_combmod_quasar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.312523e+06</td>\n",
       "      <td>7.681616e+06</td>\n",
       "      <td>2.162878e+06</td>\n",
       "      <td>6.286130e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>8.226904e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>1.557373e+06</td>\n",
       "      <td>48494.000000</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "      <td>1.854957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.621252e+01</td>\n",
       "      <td>2.265878e+01</td>\n",
       "      <td>2.480181e+01</td>\n",
       "      <td>2.248277e+01</td>\n",
       "      <td>1.857671e+01</td>\n",
       "      <td>1.867103e+01</td>\n",
       "      <td>1.783285e+01</td>\n",
       "      <td>1.714291e+01</td>\n",
       "      <td>1.680659e+01</td>\n",
       "      <td>1.663629e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607298e+00</td>\n",
       "      <td>1.857492e+00</td>\n",
       "      <td>1.831789e+00</td>\n",
       "      <td>1.386721e+01</td>\n",
       "      <td>-3.923559e+00</td>\n",
       "      <td>8.006602e+00</td>\n",
       "      <td>15.065438</td>\n",
       "      <td>9.447181e-01</td>\n",
       "      <td>3.015133e-02</td>\n",
       "      <td>2.166022e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.001855e+01</td>\n",
       "      <td>1.282219e+01</td>\n",
       "      <td>1.652845e+01</td>\n",
       "      <td>1.344820e+01</td>\n",
       "      <td>1.565382e+00</td>\n",
       "      <td>1.523811e+00</td>\n",
       "      <td>1.433349e+00</td>\n",
       "      <td>1.274097e+00</td>\n",
       "      <td>1.079368e+00</td>\n",
       "      <td>1.070547e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654142e+00</td>\n",
       "      <td>2.206325e+00</td>\n",
       "      <td>2.266141e+00</td>\n",
       "      <td>1.607001e+01</td>\n",
       "      <td>1.240325e+01</td>\n",
       "      <td>1.473784e+01</td>\n",
       "      <td>42.134888</td>\n",
       "      <td>2.224325e-01</td>\n",
       "      <td>1.683584e-01</td>\n",
       "      <td>1.381415e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.278190e+01</td>\n",
       "      <td>1.167814e+01</td>\n",
       "      <td>1.210906e+01</td>\n",
       "      <td>1.139630e+01</td>\n",
       "      <td>1.037403e+01</td>\n",
       "      <td>9.689001e+00</td>\n",
       "      <td>8.260656e+00</td>\n",
       "      <td>8.256360e+00</td>\n",
       "      <td>7.068000e+00</td>\n",
       "      <td>6.085000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>2.600000e-03</td>\n",
       "      <td>-8.026215e+02</td>\n",
       "      <td>-3.656444e+02</td>\n",
       "      <td>-389.880100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137134e+01</td>\n",
       "      <td>1.974994e+01</td>\n",
       "      <td>2.029234e+01</td>\n",
       "      <td>1.943825e+01</td>\n",
       "      <td>1.778231e+01</td>\n",
       "      <td>1.793413e+01</td>\n",
       "      <td>1.716681e+01</td>\n",
       "      <td>1.654000e+01</td>\n",
       "      <td>1.628600e+01</td>\n",
       "      <td>1.608700e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.070828e+00</td>\n",
       "      <td>-7.266419e+00</td>\n",
       "      <td>8.808007e-01</td>\n",
       "      <td>-5.499497</td>\n",
       "      <td>9.995270e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.271964e+01</td>\n",
       "      <td>2.084213e+01</td>\n",
       "      <td>2.150048e+01</td>\n",
       "      <td>2.049579e+01</td>\n",
       "      <td>1.887614e+01</td>\n",
       "      <td>1.897750e+01</td>\n",
       "      <td>1.812667e+01</td>\n",
       "      <td>1.739955e+01</td>\n",
       "      <td>1.693600e+01</td>\n",
       "      <td>1.674200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.908950e+00</td>\n",
       "      <td>-1.996961e+00</td>\n",
       "      <td>5.454478e+00</td>\n",
       "      <td>12.312459</td>\n",
       "      <td>9.999640e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406641e+01</td>\n",
       "      <td>2.170479e+01</td>\n",
       "      <td>2.257661e+01</td>\n",
       "      <td>2.128124e+01</td>\n",
       "      <td>1.971436e+01</td>\n",
       "      <td>1.974666e+01</td>\n",
       "      <td>1.882400e+01</td>\n",
       "      <td>1.802353e+01</td>\n",
       "      <td>1.753000e+01</td>\n",
       "      <td>1.738200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.731142e+01</td>\n",
       "      <td>9.636427e-01</td>\n",
       "      <td>1.218151e+01</td>\n",
       "      <td>31.317938</td>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.868277e+01</td>\n",
       "      <td>3.056738e+01</td>\n",
       "      <td>2.972356e+01</td>\n",
       "      <td>3.215351e+01</td>\n",
       "      <td>2.004100e+01</td>\n",
       "      <td>1.889200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.026368e+02</td>\n",
       "      <td>5.512816e+02</td>\n",
       "      <td>6.766674e+02</td>\n",
       "      <td>761.085100</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mag_auto_g    mag_auto_i    mag_auto_r    mag_auto_z     ypetromag  \\\n",
       "count  8.226904e+06  8.226904e+06  8.226904e+06  8.226904e+06  1.312523e+06   \n",
       "mean   3.621252e+01  2.265878e+01  2.480181e+01  2.248277e+01  1.857671e+01   \n",
       "std    3.001855e+01  1.282219e+01  1.652845e+01  1.344820e+01  1.565382e+00   \n",
       "min    1.278190e+01  1.167814e+01  1.210906e+01  1.139630e+01  1.037403e+01   \n",
       "25%    2.137134e+01  1.974994e+01  2.029234e+01  1.943825e+01  1.778231e+01   \n",
       "50%    2.271964e+01  2.084213e+01  2.150048e+01  2.049579e+01  1.887614e+01   \n",
       "75%    2.406641e+01  2.170479e+01  2.257661e+01  2.128124e+01  1.971436e+01   \n",
       "max    9.900000e+01  9.900000e+01  9.900000e+01  9.900000e+01  2.868277e+01   \n",
       "\n",
       "          jpetromag     hpetromag    kspetromag        w1mpro        w2mpro  \\\n",
       "count  7.681616e+06  2.162878e+06  6.286130e+06  8.226904e+06  8.226904e+06   \n",
       "mean   1.867103e+01  1.783285e+01  1.714291e+01  1.680659e+01  1.663629e+01   \n",
       "std    1.523811e+00  1.433349e+00  1.274097e+00  1.079368e+00  1.070547e+00   \n",
       "min    9.689001e+00  8.260656e+00  8.256360e+00  7.068000e+00  6.085000e+00   \n",
       "25%    1.793413e+01  1.716681e+01  1.654000e+01  1.628600e+01  1.608700e+01   \n",
       "50%    1.897750e+01  1.812667e+01  1.739955e+01  1.693600e+01  1.674200e+01   \n",
       "75%    1.974666e+01  1.882400e+01  1.802353e+01  1.753000e+01  1.738200e+01   \n",
       "max    3.056738e+01  2.972356e+01  3.215351e+01  2.004100e+01  1.889200e+01   \n",
       "\n",
       "       ...  extended_class_r  extended_class_i  extended_class_z  \\\n",
       "count  ...      8.226904e+06      8.226904e+06      8.226904e+06   \n",
       "mean   ...      1.607298e+00      1.857492e+00      1.831789e+00   \n",
       "std    ...      2.654142e+00      2.206325e+00      2.266141e+00   \n",
       "min    ...     -9.000000e+00     -9.000000e+00     -9.000000e+00   \n",
       "25%    ...      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "50%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "75%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "max    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "\n",
       "                 pm         pmdec          pmra  radial_velocity  \\\n",
       "count  1.557373e+06  1.557373e+06  1.557373e+06     48494.000000   \n",
       "mean   1.386721e+01 -3.923559e+00  8.006602e+00        15.065438   \n",
       "std    1.607001e+01  1.240325e+01  1.473784e+01        42.134888   \n",
       "min    2.600000e-03 -8.026215e+02 -3.656444e+02      -389.880100   \n",
       "25%    5.070828e+00 -7.266419e+00  8.808007e-01        -5.499497   \n",
       "50%    9.908950e+00 -1.996961e+00  5.454478e+00        12.312459   \n",
       "75%    1.731142e+01  9.636427e-01  1.218151e+01        31.317938   \n",
       "max    8.026368e+02  5.512816e+02  6.766674e+02       761.085100   \n",
       "\n",
       "       classprob_dsc_combmod_star  classprob_dsc_combmod_galaxy  \\\n",
       "count                1.854957e+06                  1.854957e+06   \n",
       "mean                 9.447181e-01                  3.015133e-02   \n",
       "std                  2.224325e-01                  1.683584e-01   \n",
       "min                  0.000000e+00                  0.000000e+00   \n",
       "25%                  9.995270e-01                  0.000000e+00   \n",
       "50%                  9.999640e-01                  0.000000e+00   \n",
       "75%                  9.999900e-01                  0.000000e+00   \n",
       "max                  1.000000e+00                  1.000000e+00   \n",
       "\n",
       "       classprob_dsc_combmod_quasar  \n",
       "count                  1.854957e+06  \n",
       "mean                   2.166022e-02  \n",
       "std                    1.381415e-01  \n",
       "min                    0.000000e+00  \n",
       "25%                    0.000000e+00  \n",
       "50%                    0.000000e+00  \n",
       "75%                    0.000000e+00  \n",
       "max                    1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardizing and Scaling\n",
    "\n",
    "# Set X to the entire DataFrame\n",
    "X = fcDF_15_30\n",
    "# Remove the 'class' column from X as it is the target variable\n",
    "X = X.drop(['class'], axis=1)\n",
    "\n",
    "# Set y to the 'class' column of the DataFrame\n",
    "y = fcDF_15_30['class']\n",
    "\n",
    "# Display the shapes and summary statistics \n",
    "display(X.shape, y.shape)\n",
    "display(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c73b4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4113452, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4113452, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (50% training, 50% testing)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.5, random_state = 1, shuffle=True)\n",
    "\n",
    "# Impute missing values by using the mean or median value\n",
    "X_train = X_train.fillna(X_train.mean()) # or X_train.median()\n",
    "X_test = X_test.fillna(X_test.mean()) # or X_test.median()\n",
    "\n",
    "# Create a StandardScaler object to standardize the features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fit the scaler using the training data\n",
    "scaler.fit(X_train)\n",
    "# Transform the training data using the fitted scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "# Transform the testing data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the scaled training and testing data\n",
    "display(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0259179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_auto_g</th>\n",
       "      <th>mag_auto_i</th>\n",
       "      <th>mag_auto_r</th>\n",
       "      <th>mag_auto_z</th>\n",
       "      <th>ypetromag</th>\n",
       "      <th>jpetromag</th>\n",
       "      <th>hpetromag</th>\n",
       "      <th>kspetromag</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>...</th>\n",
       "      <th>extended_class_r</th>\n",
       "      <th>extended_class_i</th>\n",
       "      <th>extended_class_z</th>\n",
       "      <th>pm</th>\n",
       "      <th>pmdec</th>\n",
       "      <th>pmra</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_combmod_galaxy</th>\n",
       "      <th>classprob_dsc_combmod_quasar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.622024e+01</td>\n",
       "      <td>2.265907e+01</td>\n",
       "      <td>2.480370e+01</td>\n",
       "      <td>2.248994e+01</td>\n",
       "      <td>1.857653e+01</td>\n",
       "      <td>1.867119e+01</td>\n",
       "      <td>1.783308e+01</td>\n",
       "      <td>1.714314e+01</td>\n",
       "      <td>1.680671e+01</td>\n",
       "      <td>1.663623e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606736e+00</td>\n",
       "      <td>1.857049e+00</td>\n",
       "      <td>1.830402e+00</td>\n",
       "      <td>1.386853e+01</td>\n",
       "      <td>-3.923129e+00</td>\n",
       "      <td>7.989458e+00</td>\n",
       "      <td>1.496564e+01</td>\n",
       "      <td>9.447756e-01</td>\n",
       "      <td>2.995606e-02</td>\n",
       "      <td>2.181235e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.002534e+01</td>\n",
       "      <td>1.282308e+01</td>\n",
       "      <td>1.653305e+01</td>\n",
       "      <td>1.346784e+01</td>\n",
       "      <td>6.256626e-01</td>\n",
       "      <td>1.472865e+00</td>\n",
       "      <td>7.345629e-01</td>\n",
       "      <td>1.113901e+00</td>\n",
       "      <td>1.079560e+00</td>\n",
       "      <td>1.070733e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654679e+00</td>\n",
       "      <td>2.206470e+00</td>\n",
       "      <td>2.268565e+00</td>\n",
       "      <td>7.004411e+00</td>\n",
       "      <td>5.450415e+00</td>\n",
       "      <td>6.387013e+00</td>\n",
       "      <td>3.187139e+00</td>\n",
       "      <td>1.055817e-01</td>\n",
       "      <td>7.970007e-02</td>\n",
       "      <td>6.582942e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.278190e+01</td>\n",
       "      <td>1.167814e+01</td>\n",
       "      <td>1.210906e+01</td>\n",
       "      <td>1.139630e+01</td>\n",
       "      <td>1.051031e+01</td>\n",
       "      <td>9.689001e+00</td>\n",
       "      <td>9.826766e+00</td>\n",
       "      <td>9.507744e+00</td>\n",
       "      <td>7.965000e+00</td>\n",
       "      <td>7.808000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>2.600000e-03</td>\n",
       "      <td>-8.026215e+02</td>\n",
       "      <td>-3.656444e+02</td>\n",
       "      <td>-2.607022e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137033e+01</td>\n",
       "      <td>1.975028e+01</td>\n",
       "      <td>2.029223e+01</td>\n",
       "      <td>1.943848e+01</td>\n",
       "      <td>1.857653e+01</td>\n",
       "      <td>1.803132e+01</td>\n",
       "      <td>1.783308e+01</td>\n",
       "      <td>1.686470e+01</td>\n",
       "      <td>1.628600e+01</td>\n",
       "      <td>1.608700e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.386853e+01</td>\n",
       "      <td>-3.923129e+00</td>\n",
       "      <td>7.989458e+00</td>\n",
       "      <td>1.496564e+01</td>\n",
       "      <td>9.447756e-01</td>\n",
       "      <td>2.995606e-02</td>\n",
       "      <td>2.181235e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.271930e+01</td>\n",
       "      <td>2.084202e+01</td>\n",
       "      <td>2.149993e+01</td>\n",
       "      <td>2.049579e+01</td>\n",
       "      <td>1.857653e+01</td>\n",
       "      <td>1.885876e+01</td>\n",
       "      <td>1.783308e+01</td>\n",
       "      <td>1.714314e+01</td>\n",
       "      <td>1.693600e+01</td>\n",
       "      <td>1.674200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.386853e+01</td>\n",
       "      <td>-3.923129e+00</td>\n",
       "      <td>7.989458e+00</td>\n",
       "      <td>1.496564e+01</td>\n",
       "      <td>9.447756e-01</td>\n",
       "      <td>2.995606e-02</td>\n",
       "      <td>2.181235e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406738e+01</td>\n",
       "      <td>2.170480e+01</td>\n",
       "      <td>2.257708e+01</td>\n",
       "      <td>2.128109e+01</td>\n",
       "      <td>1.857653e+01</td>\n",
       "      <td>1.969211e+01</td>\n",
       "      <td>1.783308e+01</td>\n",
       "      <td>1.783367e+01</td>\n",
       "      <td>1.753100e+01</td>\n",
       "      <td>1.738300e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.386853e+01</td>\n",
       "      <td>-3.923129e+00</td>\n",
       "      <td>7.989458e+00</td>\n",
       "      <td>1.496564e+01</td>\n",
       "      <td>9.447756e-01</td>\n",
       "      <td>2.995606e-02</td>\n",
       "      <td>2.181235e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.868277e+01</td>\n",
       "      <td>3.056738e+01</td>\n",
       "      <td>2.623996e+01</td>\n",
       "      <td>3.215351e+01</td>\n",
       "      <td>2.003600e+01</td>\n",
       "      <td>1.889200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.026368e+02</td>\n",
       "      <td>5.512816e+02</td>\n",
       "      <td>6.766674e+02</td>\n",
       "      <td>4.176311e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mag_auto_g    mag_auto_i    mag_auto_r    mag_auto_z     ypetromag  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06   \n",
       "mean   3.622024e+01  2.265907e+01  2.480370e+01  2.248994e+01  1.857653e+01   \n",
       "std    3.002534e+01  1.282308e+01  1.653305e+01  1.346784e+01  6.256626e-01   \n",
       "min    1.278190e+01  1.167814e+01  1.210906e+01  1.139630e+01  1.051031e+01   \n",
       "25%    2.137033e+01  1.975028e+01  2.029223e+01  1.943848e+01  1.857653e+01   \n",
       "50%    2.271930e+01  2.084202e+01  2.149993e+01  2.049579e+01  1.857653e+01   \n",
       "75%    2.406738e+01  2.170480e+01  2.257708e+01  2.128109e+01  1.857653e+01   \n",
       "max    9.900000e+01  9.900000e+01  9.900000e+01  9.900000e+01  2.868277e+01   \n",
       "\n",
       "          jpetromag     hpetromag    kspetromag        w1mpro        w2mpro  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06   \n",
       "mean   1.867119e+01  1.783308e+01  1.714314e+01  1.680671e+01  1.663623e+01   \n",
       "std    1.472865e+00  7.345629e-01  1.113901e+00  1.079560e+00  1.070733e+00   \n",
       "min    9.689001e+00  9.826766e+00  9.507744e+00  7.965000e+00  7.808000e+00   \n",
       "25%    1.803132e+01  1.783308e+01  1.686470e+01  1.628600e+01  1.608700e+01   \n",
       "50%    1.885876e+01  1.783308e+01  1.714314e+01  1.693600e+01  1.674200e+01   \n",
       "75%    1.969211e+01  1.783308e+01  1.783367e+01  1.753100e+01  1.738300e+01   \n",
       "max    3.056738e+01  2.623996e+01  3.215351e+01  2.003600e+01  1.889200e+01   \n",
       "\n",
       "       ...  extended_class_r  extended_class_i  extended_class_z  \\\n",
       "count  ...      4.113452e+06      4.113452e+06      4.113452e+06   \n",
       "mean   ...      1.606736e+00      1.857049e+00      1.830402e+00   \n",
       "std    ...      2.654679e+00      2.206470e+00      2.268565e+00   \n",
       "min    ...     -9.000000e+00     -9.000000e+00     -9.000000e+00   \n",
       "25%    ...      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "50%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "75%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "max    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "\n",
       "                 pm         pmdec          pmra  radial_velocity  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06     4.113452e+06   \n",
       "mean   1.386853e+01 -3.923129e+00  7.989458e+00     1.496564e+01   \n",
       "std    7.004411e+00  5.450415e+00  6.387013e+00     3.187139e+00   \n",
       "min    2.600000e-03 -8.026215e+02 -3.656444e+02    -2.607022e+02   \n",
       "25%    1.386853e+01 -3.923129e+00  7.989458e+00     1.496564e+01   \n",
       "50%    1.386853e+01 -3.923129e+00  7.989458e+00     1.496564e+01   \n",
       "75%    1.386853e+01 -3.923129e+00  7.989458e+00     1.496564e+01   \n",
       "max    8.026368e+02  5.512816e+02  6.766674e+02     4.176311e+02   \n",
       "\n",
       "       classprob_dsc_combmod_star  classprob_dsc_combmod_galaxy  \\\n",
       "count                4.113452e+06                  4.113452e+06   \n",
       "mean                 9.447756e-01                  2.995606e-02   \n",
       "std                  1.055817e-01                  7.970007e-02   \n",
       "min                  0.000000e+00                  0.000000e+00   \n",
       "25%                  9.447756e-01                  2.995606e-02   \n",
       "50%                  9.447756e-01                  2.995606e-02   \n",
       "75%                  9.447756e-01                  2.995606e-02   \n",
       "max                  1.000000e+00                  1.000000e+00   \n",
       "\n",
       "       classprob_dsc_combmod_quasar  \n",
       "count                  4.113452e+06  \n",
       "mean                   2.181235e-02  \n",
       "std                    6.582942e-02  \n",
       "min                    0.000000e+00  \n",
       "25%                    2.181235e-02  \n",
       "50%                    2.181235e-02  \n",
       "75%                    2.181235e-02  \n",
       "max                    1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_auto_g</th>\n",
       "      <th>mag_auto_i</th>\n",
       "      <th>mag_auto_r</th>\n",
       "      <th>mag_auto_z</th>\n",
       "      <th>ypetromag</th>\n",
       "      <th>jpetromag</th>\n",
       "      <th>hpetromag</th>\n",
       "      <th>kspetromag</th>\n",
       "      <th>w1mpro</th>\n",
       "      <th>w2mpro</th>\n",
       "      <th>...</th>\n",
       "      <th>extended_class_r</th>\n",
       "      <th>extended_class_i</th>\n",
       "      <th>extended_class_z</th>\n",
       "      <th>pm</th>\n",
       "      <th>pmdec</th>\n",
       "      <th>pmra</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_combmod_galaxy</th>\n",
       "      <th>classprob_dsc_combmod_quasar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "      <td>4.113452e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.620479e+01</td>\n",
       "      <td>2.265848e+01</td>\n",
       "      <td>2.479992e+01</td>\n",
       "      <td>2.247560e+01</td>\n",
       "      <td>1.857690e+01</td>\n",
       "      <td>1.867087e+01</td>\n",
       "      <td>1.783262e+01</td>\n",
       "      <td>1.714267e+01</td>\n",
       "      <td>1.680647e+01</td>\n",
       "      <td>1.663633e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607860e+00</td>\n",
       "      <td>1.857935e+00</td>\n",
       "      <td>1.833176e+00</td>\n",
       "      <td>1.386589e+01</td>\n",
       "      <td>-3.923989e+00</td>\n",
       "      <td>8.023788e+00</td>\n",
       "      <td>1.516541e+01</td>\n",
       "      <td>9.446607e-01</td>\n",
       "      <td>3.034684e-02</td>\n",
       "      <td>2.150791e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.001175e+01</td>\n",
       "      <td>1.282129e+01</td>\n",
       "      <td>1.652386e+01</td>\n",
       "      <td>1.342852e+01</td>\n",
       "      <td>6.248419e-01</td>\n",
       "      <td>1.472027e+00</td>\n",
       "      <td>7.353093e-01</td>\n",
       "      <td>1.113538e+00</td>\n",
       "      <td>1.079176e+00</td>\n",
       "      <td>1.070361e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.653605e+00</td>\n",
       "      <td>2.206180e+00</td>\n",
       "      <td>2.263713e+00</td>\n",
       "      <td>6.979330e+00</td>\n",
       "      <td>5.342078e+00</td>\n",
       "      <td>6.437422e+00</td>\n",
       "      <td>3.281982e+00</td>\n",
       "      <td>1.056586e-01</td>\n",
       "      <td>8.018615e-02</td>\n",
       "      <td>6.536032e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.316891e+01</td>\n",
       "      <td>1.246892e+01</td>\n",
       "      <td>1.211705e+01</td>\n",
       "      <td>1.221446e+01</td>\n",
       "      <td>1.037403e+01</td>\n",
       "      <td>1.013221e+01</td>\n",
       "      <td>8.260656e+00</td>\n",
       "      <td>8.256360e+00</td>\n",
       "      <td>7.068000e+00</td>\n",
       "      <td>6.085000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>-9.000000e+00</td>\n",
       "      <td>5.783000e-03</td>\n",
       "      <td>-7.481313e+02</td>\n",
       "      <td>-3.379641e+02</td>\n",
       "      <td>-3.898801e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137233e+01</td>\n",
       "      <td>1.974964e+01</td>\n",
       "      <td>2.029244e+01</td>\n",
       "      <td>1.943801e+01</td>\n",
       "      <td>1.857690e+01</td>\n",
       "      <td>1.803143e+01</td>\n",
       "      <td>1.783262e+01</td>\n",
       "      <td>1.686352e+01</td>\n",
       "      <td>1.628600e+01</td>\n",
       "      <td>1.608700e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.386589e+01</td>\n",
       "      <td>-3.923989e+00</td>\n",
       "      <td>8.023788e+00</td>\n",
       "      <td>1.516541e+01</td>\n",
       "      <td>9.446607e-01</td>\n",
       "      <td>3.034684e-02</td>\n",
       "      <td>2.150791e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.272001e+01</td>\n",
       "      <td>2.084224e+01</td>\n",
       "      <td>2.150103e+01</td>\n",
       "      <td>2.049578e+01</td>\n",
       "      <td>1.857690e+01</td>\n",
       "      <td>1.885797e+01</td>\n",
       "      <td>1.783262e+01</td>\n",
       "      <td>1.714267e+01</td>\n",
       "      <td>1.693600e+01</td>\n",
       "      <td>1.674200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.386589e+01</td>\n",
       "      <td>-3.923989e+00</td>\n",
       "      <td>8.023788e+00</td>\n",
       "      <td>1.516541e+01</td>\n",
       "      <td>9.446607e-01</td>\n",
       "      <td>3.034684e-02</td>\n",
       "      <td>2.150791e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406546e+01</td>\n",
       "      <td>2.170478e+01</td>\n",
       "      <td>2.257610e+01</td>\n",
       "      <td>2.128138e+01</td>\n",
       "      <td>1.857690e+01</td>\n",
       "      <td>1.969202e+01</td>\n",
       "      <td>1.783262e+01</td>\n",
       "      <td>1.783368e+01</td>\n",
       "      <td>1.753000e+01</td>\n",
       "      <td>1.738200e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.386589e+01</td>\n",
       "      <td>-3.923989e+00</td>\n",
       "      <td>8.023788e+00</td>\n",
       "      <td>1.516541e+01</td>\n",
       "      <td>9.446607e-01</td>\n",
       "      <td>3.034684e-02</td>\n",
       "      <td>2.150791e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.677974e+01</td>\n",
       "      <td>2.986823e+01</td>\n",
       "      <td>2.972356e+01</td>\n",
       "      <td>2.691011e+01</td>\n",
       "      <td>2.004100e+01</td>\n",
       "      <td>1.886600e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.995270e+02</td>\n",
       "      <td>5.512816e+02</td>\n",
       "      <td>6.727384e+02</td>\n",
       "      <td>7.610851e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mag_auto_g    mag_auto_i    mag_auto_r    mag_auto_z     ypetromag  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06   \n",
       "mean   3.620479e+01  2.265848e+01  2.479992e+01  2.247560e+01  1.857690e+01   \n",
       "std    3.001175e+01  1.282129e+01  1.652386e+01  1.342852e+01  6.248419e-01   \n",
       "min    1.316891e+01  1.246892e+01  1.211705e+01  1.221446e+01  1.037403e+01   \n",
       "25%    2.137233e+01  1.974964e+01  2.029244e+01  1.943801e+01  1.857690e+01   \n",
       "50%    2.272001e+01  2.084224e+01  2.150103e+01  2.049578e+01  1.857690e+01   \n",
       "75%    2.406546e+01  2.170478e+01  2.257610e+01  2.128138e+01  1.857690e+01   \n",
       "max    9.900000e+01  9.900000e+01  9.900000e+01  9.900000e+01  2.677974e+01   \n",
       "\n",
       "          jpetromag     hpetromag    kspetromag        w1mpro        w2mpro  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06  4.113452e+06   \n",
       "mean   1.867087e+01  1.783262e+01  1.714267e+01  1.680647e+01  1.663633e+01   \n",
       "std    1.472027e+00  7.353093e-01  1.113538e+00  1.079176e+00  1.070361e+00   \n",
       "min    1.013221e+01  8.260656e+00  8.256360e+00  7.068000e+00  6.085000e+00   \n",
       "25%    1.803143e+01  1.783262e+01  1.686352e+01  1.628600e+01  1.608700e+01   \n",
       "50%    1.885797e+01  1.783262e+01  1.714267e+01  1.693600e+01  1.674200e+01   \n",
       "75%    1.969202e+01  1.783262e+01  1.783368e+01  1.753000e+01  1.738200e+01   \n",
       "max    2.986823e+01  2.972356e+01  2.691011e+01  2.004100e+01  1.886600e+01   \n",
       "\n",
       "       ...  extended_class_r  extended_class_i  extended_class_z  \\\n",
       "count  ...      4.113452e+06      4.113452e+06      4.113452e+06   \n",
       "mean   ...      1.607860e+00      1.857935e+00      1.833176e+00   \n",
       "std    ...      2.653605e+00      2.206180e+00      2.263713e+00   \n",
       "min    ...     -9.000000e+00     -9.000000e+00     -9.000000e+00   \n",
       "25%    ...      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "50%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "75%    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "max    ...      3.000000e+00      3.000000e+00      3.000000e+00   \n",
       "\n",
       "                 pm         pmdec          pmra  radial_velocity  \\\n",
       "count  4.113452e+06  4.113452e+06  4.113452e+06     4.113452e+06   \n",
       "mean   1.386589e+01 -3.923989e+00  8.023788e+00     1.516541e+01   \n",
       "std    6.979330e+00  5.342078e+00  6.437422e+00     3.281982e+00   \n",
       "min    5.783000e-03 -7.481313e+02 -3.379641e+02    -3.898801e+02   \n",
       "25%    1.386589e+01 -3.923989e+00  8.023788e+00     1.516541e+01   \n",
       "50%    1.386589e+01 -3.923989e+00  8.023788e+00     1.516541e+01   \n",
       "75%    1.386589e+01 -3.923989e+00  8.023788e+00     1.516541e+01   \n",
       "max    7.995270e+02  5.512816e+02  6.727384e+02     7.610851e+02   \n",
       "\n",
       "       classprob_dsc_combmod_star  classprob_dsc_combmod_galaxy  \\\n",
       "count                4.113452e+06                  4.113452e+06   \n",
       "mean                 9.446607e-01                  3.034684e-02   \n",
       "std                  1.056586e-01                  8.018615e-02   \n",
       "min                  0.000000e+00                  0.000000e+00   \n",
       "25%                  9.446607e-01                  3.034684e-02   \n",
       "50%                  9.446607e-01                  3.034684e-02   \n",
       "75%                  9.446607e-01                  3.034684e-02   \n",
       "max                  1.000000e+00                  1.000000e+00   \n",
       "\n",
       "       classprob_dsc_combmod_quasar  \n",
       "count                  4.113452e+06  \n",
       "mean                   2.150791e-02  \n",
       "std                    6.536032e-02  \n",
       "min                    0.000000e+00  \n",
       "25%                    2.150791e-02  \n",
       "50%                    2.150791e-02  \n",
       "75%                    2.150791e-02  \n",
       "max                    1.000000e+00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the summary statistics of the training data\n",
    "display(X_train.describe())\n",
    "\n",
    "# Display the summary statistics of the testing data\n",
    "display(X_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a87859",
   "metadata": {},
   "source": [
    "## TensorFlow <a class=\"anchor\" id=\"five\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f44b7",
   "metadata": {},
   "source": [
    "Google created TensorFlow and made it available in 2015. This highly scalable framework is extensively utilized for machine learning applications at the production level.\n",
    "\n",
    "TensorFlow operates on a data flow graph, where mathematical operations are represented by nodes and data inputs and outputs are represented by edges. By adopting this approach, TensorFlow can optimize computations and execute them efficiently on both CPUs and GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a14d3",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f01844",
   "metadata": {},
   "source": [
    "The term \"model architecture\" encompasses the holistic arrangement and composition of a machine learning model. This encompasses factors such as the quantity and nature of layers, the number of neurons or units within each layer, the activation functions employed in each layer, the training optimization algorithm, and other design considerations entailed in the model's creation.\n",
    "\n",
    "An autoencoder is a neural network that is utilized for unsupervised learning purposes. \n",
    "\n",
    "TensorFlow offers the Keras API for defining an autoencoder model. This model comprises an encoder and a decoder network, which are trained to reconstruct the input data. The model parameters can be optimized through backpropagation and gradient descent algorithms. Once trained, the model finds applications in tasks such as dimensionality reduction, anomaly detection, and data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c6a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'TF Tester 4'\n",
    "# Define the simple autoencoder function\n",
    "def Autoencoder_Simple(input_size):\n",
    "    # Calculate the hidden layer size (half of the input size)\n",
    "    hidden_size = int(input_size / 2.0)\n",
    "    # Calculate the bottleneck layer size (half of the hidden layer size)\n",
    "    bottleneck_size = int(hidden_size / 2.0)\n",
    "    # Define the input layer with the specified input size\n",
    "    input_tab = Input(shape=(input_size,))\n",
    "    # Define the first hidden layer with 'relu' activation function\n",
    "    hidden_1 = layers.Dense(hidden_size, activation='relu')(input_tab)\n",
    "    # Define the bottleneck layer with 'relu' activation function\n",
    "    bottleneck = layers.Dense(bottleneck_size, activation='relu')(hidden_1)\n",
    "    # Define the second hidden layer with 'relu' activation function\n",
    "    hidden_2 = layers.Dense(hidden_size, activation='relu')(bottleneck)\n",
    "    # Define the output layer with 'linear' activation function\n",
    "    output_tab = layers.Dense(input_size, activation='linear')(hidden_2)\n",
    "    # Create the encoder model, which includes the input layer and bottleneck layer\n",
    "    encoder = Model(input_tab, bottleneck)\n",
    "    # Create the full autoencoder model, which includes the input and output layers\n",
    "    model = Model(input_tab, output_tab)\n",
    "\n",
    "    # Return both the full autoencoder model and the encoder model\n",
    "    return model 'decoder', encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8668ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 18:43:48.939706: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-13 18:43:48.940149: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "from tensorflow.keras import layers\n",
    "# Set the input size based on the number of features in the dataset\n",
    "input_size = X.shape[1]\n",
    "# Call the Autoencoder_Simple function, passing the input_size as an argument\n",
    "model, encoder = Autoencoder_Simple(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2e5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "\n",
    "# Plot the model architecture\n",
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb11be",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97593a7",
   "metadata": {},
   "source": [
    "Model training involves the procedure of instructing a machine learning model to generate precise predictions for novel data. Within unsupervised learning, model training pertains to comprehending the inherent patterns within the data without relying on explicit labels.\n",
    "\n",
    "The process of training an autoencoder model in TensorFlow revolves around optimizing its parameters to minimize the disparity between the input and output data. This optimization is achieved by reducing the reconstruction error utilizing an optimization algorithm like stochastic gradient descent. \n",
    "\n",
    "Typically, a substantial dataset is employed to train the model, aiming to acquire meaningful data representations beneficial for tasks such as data compression, denoising, and anomaly detection. During training, the weights and biases of the neural network are iteratively adjusted through backpropagation, wherein the gradients of the loss function with respect to the model parameters are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4697d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 18:44:03.650187: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-13 18:44:03.903588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-13 19:02:39.378503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257091/257091 - 1771s - loss: 0.2014 - val_loss: 0.1973 - 1771s/epoch - 7ms/step\n",
      "Epoch 2/50\n",
      "257091/257091 - 1734s - loss: 0.1946 - val_loss: 0.1970 - 1734s/epoch - 7ms/step\n",
      "Epoch 3/50\n",
      "257091/257091 - 1846s - loss: 0.1941 - val_loss: 0.1959 - 1846s/epoch - 7ms/step\n",
      "Epoch 4/50\n",
      "257091/257091 - 1742s - loss: 0.1935 - val_loss: 0.1955 - 1742s/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "257091/257091 - 1762s - loss: 0.1934 - val_loss: 0.1951 - 1762s/epoch - 7ms/step\n",
      "Epoch 6/50\n",
      "257091/257091 - 1776s - loss: 0.1934 - val_loss: 0.1950 - 1776s/epoch - 7ms/step\n",
      "Epoch 7/50\n",
      "257091/257091 - 5554s - loss: 0.1934 - val_loss: 0.1950 - 5554s/epoch - 22ms/step\n",
      "Epoch 8/50\n",
      "257091/257091 - 43917s - loss: 0.1933 - val_loss: 0.1946 - 43917s/epoch - 171ms/step\n",
      "Epoch 9/50\n",
      "257091/257091 - 1794s - loss: 0.1933 - val_loss: 0.1948 - 1794s/epoch - 7ms/step\n",
      "Epoch 10/50\n",
      "257091/257091 - 1905s - loss: 0.1933 - val_loss: 0.1956 - 1905s/epoch - 7ms/step\n",
      "Epoch 11/50\n",
      "257091/257091 - 1771s - loss: 0.1933 - val_loss: 0.1953 - 1771s/epoch - 7ms/step\n",
      "Epoch 12/50\n",
      "257091/257091 - 1788s - loss: 0.1933 - val_loss: 0.1944 - 1788s/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "257091/257091 - 1790s - loss: 0.1933 - val_loss: 0.1952 - 1790s/epoch - 7ms/step\n",
      "Epoch 14/50\n",
      "257091/257091 - 1782s - loss: 0.1932 - val_loss: 0.1946 - 1782s/epoch - 7ms/step\n",
      "Epoch 15/50\n"
     ]
    }
   ],
   "source": [
    "'TF Tester 4'\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Set the number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# Compile the model with Adam optimizer and mean squared error loss function\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model using the scaled training data and validation data\n",
    "history = model.fit(X_train_scaled, X_train_scaled,\n",
    "                    epochs=n_epochs, batch_size=16, verbose=2,\n",
    "                    validation_data=(X_test_scaled, X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868f1c0",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cabfa",
   "metadata": {},
   "source": [
    "Model evaluation involves assessing the predictive capability of a machine learning model by testing it on a separate dataset, distinct from the training data. This assessment aims to gauge the model's performance and effectiveness.\n",
    "\n",
    "In the case of an autoencoder, evaluating the model focuses on determining its ability to accurately reconstruct unseen input data. This evaluation involves comparing the original input data with the output data generated by the autoencoder and quantifying the dissimilarity between them.\n",
    "\n",
    "A common approach for model evaluation is to plot the loss function's trajectory throughout the training process. The loss function measures the disparity between the model's predictions and the actual data, and the objective during training is to minimize this discrepancy. By visualizing the loss function over time, we gain insights into the model's learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'TF Tester 1'\n",
    "# Plot the training and testing loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5035dc",
   "metadata": {},
   "source": [
    "## PyTorch <a class=\"anchor\" id=\"six\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574cff5f",
   "metadata": {},
   "source": [
    "Facebook introduced PyTorch in 2017 as a flexible framework that offers ease of use and customization. \n",
    "\n",
    "Unlike other frameworks, PyTorch utilizes a dynamic computational graph, enabling developers to construct models in a Pythonic manner. This feature proves particularly advantageous when creating dynamic models that involve varying input shapes or sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a90a7e",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616a138",
   "metadata": {},
   "source": [
    "The term \"model architecture\" encompasses the holistic arrangement and composition of a machine learning model. This encompasses factors such as the quantity and nature of layers, the number of neurons or units within each layer, the activation functions employed in each layer, the training optimization algorithm, and other design considerations entailed in the model's creation.\n",
    "\n",
    "An autoencoder is a neural network that is utilized for unsupervised learning purposes.\n",
    "\n",
    "When working with PyTorch, the process of creating an autoencoder model entails constructing an encoder and decoder network. These components are trained jointly to acquire a condensed representation of the input data. \n",
    "The encoder network is responsible for receiving the input and generating a representation with reduced dimensions. Subsequently, the decoder network utilizes this representation to produce the reconstructed output. \n",
    "The primary objective is to minimize the disparity between the input and output, while simultaneously reducing the dimensionality of the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cfbc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "# Define the Autoencoder model\n",
    "# Define a class named Autoencoder that inherits from the PyTorch nn.Module class\n",
    "class Autoencoder(nn.Module):\n",
    "    # Initialize the Autoencoder class, taking an input_size argument\n",
    "    def __init__(self, input_size):\n",
    "        # Call the constructor of the parent nn.Module class\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Calculate the size of the hidden layer as half of the input_size\n",
    "        hidden_size = int(input_size / 2)\n",
    "        # Calculate the size of the bottleneck layer as half of the hidden_size\n",
    "        bottleneck_size = int(hidden_size / 2)\n",
    "        # Define the encoder part of the autoencoder as a sequence of layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Add a linear layer with input_size as input and hidden_size as output\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "            # Add a linear layer with hidden_size as input and bottleneck_size as output\n",
    "            nn.Linear(hidden_size, bottleneck_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Define the decoder part of the autoencoder as a sequence of layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Add a linear layer with bottleneck_size as input and hidden_size as output\n",
    "            nn.Linear(bottleneck_size, hidden_size),\n",
    "            # Add a ReLU activation layer\n",
    "            nn.ReLU(),\n",
    "            # Add a linear layer with hidden_size as input and input_size as output\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "\n",
    "    # Define the forward pass of the autoencoder\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the encoder to get the bottleneck representation\n",
    "        x = self.encoder(x)\n",
    "        # Pass the bottleneck representation through the decoder to get the reconstructed output\n",
    "        x = self.decoder(x)\n",
    "        # Return the reconstructed output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e03b6e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_torch contains nan: tensor(False)\n",
      "X_train_torch contains inf: tensor(False)\n",
      "X_test_torch contains nan: tensor(False)\n",
      "X_test_torch contains inf: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "'PT Tester 1 give more explanation to keras'\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch TensorDataset for the training and testing data\n",
    "train_dataset = TensorDataset(X_train_torch)  \n",
    "test_dataset = TensorDataset(X_test_torch)\n",
    "# Create a DataLoader for the training and testing data\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Check to ensure that the data does not contain any nan or infinity values\n",
    "print(\"X_train_torch contains nan:\", torch.isnan(X_train_torch).any())\n",
    "print(\"X_train_torch contains inf:\", torch.isinf(X_train_torch).any())\n",
    "print(\"X_test_torch contains nan:\", torch.isnan(X_test_torch).any())\n",
    "print(\"X_test_torch contains inf:\", torch.isinf(X_test_torch).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40bd1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "# Instantiate the model\n",
    "# Get the number of features in the input data\n",
    "input_size = X.shape[1] \n",
    "# Create an instance of the Autoencoder class with the input size\n",
    "model = Autoencoder(input_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "import torch.optim as optim\n",
    "# Define the loss function as mean squared error (MSE) loss\n",
    "criterion = nn.MSELoss() \n",
    "# Create an Adam optimizer with the specified learning rate and the model's parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26078e25",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb76c7d",
   "metadata": {},
   "source": [
    "Model training involves the procedure of instructing a machine learning model to generate precise predictions for novel data. Within unsupervised learning, model training pertains to comprehending the inherent patterns within the data without relying on explicit labels. \n",
    "\n",
    "PyTorch's Autoencoder Model Training comprises several steps, including the specification of the model's structure, configuration of hyperparameters, and the actual training process. \n",
    "To begin, the encoder and decoder architectures are established using the nn.Module class. Subsequently, important hyperparameters like learning rate, batch size, and number of epochs are defined. \n",
    "The optimizer and loss function are then determined.\n",
    "\n",
    "Following these preparations, the model is trained on the training dataset while also undergoing validation on a separate dataset and testing on yet another dataset. \n",
    "Once the training is complete, the trained model can be utilized for making predictions and generating new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e44117e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.204974, Test Loss: 0.180165\n",
      "Epoch: 2/50, Train Loss: 0.176585, Test Loss: 0.175485\n",
      "Epoch: 3/50, Train Loss: 0.171567, Test Loss: 0.168642\n",
      "Epoch: 4/50, Train Loss: 0.197860, Test Loss: 0.194732\n",
      "Epoch: 5/50, Train Loss: 0.191366, Test Loss: 0.185105\n",
      "Epoch: 6/50, Train Loss: 0.183782, Test Loss: 0.182551\n",
      "Epoch: 7/50, Train Loss: 0.184195, Test Loss: 0.182726\n",
      "Epoch: 8/50, Train Loss: 0.184192, Test Loss: 0.182597\n",
      "Epoch: 9/50, Train Loss: 0.184411, Test Loss: 0.185470\n",
      "Epoch: 10/50, Train Loss: 0.182817, Test Loss: 0.180296\n",
      "Epoch: 11/50, Train Loss: 0.183069, Test Loss: 0.182173\n",
      "Epoch: 12/50, Train Loss: 0.184476, Test Loss: 0.183482\n",
      "Epoch: 13/50, Train Loss: 0.184548, Test Loss: 0.183062\n",
      "Epoch: 14/50, Train Loss: 0.184422, Test Loss: 0.181984\n",
      "Epoch: 15/50, Train Loss: 0.184155, Test Loss: 0.186118\n",
      "Epoch: 16/50, Train Loss: 0.184086, Test Loss: 0.185751\n",
      "Epoch: 17/50, Train Loss: 0.184288, Test Loss: 0.183167\n",
      "Epoch: 18/50, Train Loss: 0.184408, Test Loss: 0.190368\n",
      "Epoch: 19/50, Train Loss: 0.184166, Test Loss: 0.182013\n",
      "Epoch: 20/50, Train Loss: 0.184299, Test Loss: 0.182965\n",
      "Epoch: 21/50, Train Loss: 0.184320, Test Loss: 0.188758\n",
      "Epoch: 22/50, Train Loss: 0.184405, Test Loss: 0.182461\n",
      "Epoch: 23/50, Train Loss: 0.184702, Test Loss: 0.183229\n",
      "Epoch: 24/50, Train Loss: 0.184036, Test Loss: 0.184159\n",
      "Epoch: 25/50, Train Loss: 0.184053, Test Loss: 0.183055\n",
      "Epoch: 26/50, Train Loss: 0.184493, Test Loss: 0.182483\n",
      "Epoch: 27/50, Train Loss: 0.184141, Test Loss: 0.186442\n",
      "Epoch: 28/50, Train Loss: 0.184628, Test Loss: 0.183238\n",
      "Epoch: 29/50, Train Loss: 0.184792, Test Loss: 0.182296\n",
      "Epoch: 30/50, Train Loss: 0.184565, Test Loss: 0.182591\n",
      "Epoch: 31/50, Train Loss: 0.184569, Test Loss: 0.184549\n",
      "Epoch: 32/50, Train Loss: 0.184111, Test Loss: 0.182878\n",
      "Epoch: 33/50, Train Loss: 0.184840, Test Loss: 0.183035\n",
      "Epoch: 34/50, Train Loss: 0.184522, Test Loss: 0.182288\n",
      "Epoch: 35/50, Train Loss: 0.184345, Test Loss: 0.182474\n",
      "Epoch: 36/50, Train Loss: 0.184023, Test Loss: 0.182138\n",
      "Epoch: 37/50, Train Loss: 0.184334, Test Loss: 0.182417\n",
      "Epoch: 38/50, Train Loss: 0.184844, Test Loss: 0.181717\n",
      "Epoch: 39/50, Train Loss: 0.184653, Test Loss: 0.182992\n",
      "Epoch: 40/50, Train Loss: 0.184247, Test Loss: 0.184875\n",
      "Epoch: 41/50, Train Loss: 0.184033, Test Loss: 0.182938\n",
      "Epoch: 42/50, Train Loss: 0.183228, Test Loss: 0.182625\n",
      "Epoch: 43/50, Train Loss: 0.183353, Test Loss: 0.184283\n",
      "Epoch: 44/50, Train Loss: 0.183265, Test Loss: 0.182878\n",
      "Epoch: 45/50, Train Loss: 0.183363, Test Loss: 0.182230\n",
      "Epoch: 46/50, Train Loss: 0.183643, Test Loss: 0.183758\n",
      "Epoch: 47/50, Train Loss: 0.183767, Test Loss: 0.182404\n",
      "Epoch: 48/50, Train Loss: 0.183774, Test Loss: 0.183001\n",
      "Epoch: 49/50, Train Loss: 0.183544, Test Loss: 0.181167\n",
      "Epoch: 50/50, Train Loss: 0.183839, Test Loss: 0.183598\n"
     ]
    }
   ],
   "source": [
    "'PT Tester 1'\n",
    "# Set the number of epochs for training\n",
    "n_epochs = 50\n",
    "\n",
    "# Loop through each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize the train loss for the current epoch to 0\n",
    "    train_loss = 0.0\n",
    "    # Loop through each batch in the train_loader\n",
    "    for batch in train_loader:\n",
    "        # Get the input data from the current batch\n",
    "        inputs = batch[0]      \n",
    "        # Reset the optimizer gradients to 0\n",
    "        optimizer.zero_grad()   \n",
    "        # Pass the inputs through the model to get the outputs\n",
    "        outputs = model(inputs)     \n",
    "        # Calculate the loss between the outputs and the original inputs\n",
    "        loss = criterion(outputs, inputs)      \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()    \n",
    "        # Update the model parameters using the optimizer\n",
    "        optimizer.step()     \n",
    "        # Accumulate the train loss for the current batch\n",
    "        train_loss += loss.item()\n",
    "    # Initialize the test loss for the current epoch to 0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    # Disable gradient calculations for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Loop through each batch in the test_loader\n",
    "        for batch in test_loader:\n",
    "            # Get the input data from the current batch\n",
    "            inputs = batch[0]\n",
    "            # Pass the inputs through the model to get the outputs\n",
    "            outputs = model(inputs)  \n",
    "            # Calculate the loss between the outputs and the original inputs\n",
    "            loss = criterion(outputs, inputs)    \n",
    "            # Accumulate the test loss for the current batch\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    # Print the train and test loss for the current epoch\n",
    "    print(f\"Epoch: {epoch+1}/{n_epochs}, Train Loss: {train_loss/len(train_loader):.6f}, Test Loss: {test_loss/len(test_loader):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffdbb8f",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98ca7c",
   "metadata": {},
   "source": [
    "Model evaluation involves assessing the predictive capability of a machine learning model by testing it on a separate dataset, distinct from the training data. This assessment aims to gauge the model's performance and effectiveness.\n",
    "\n",
    "In the case of an autoencoder, evaluating the model focuses on determining its ability to accurately reconstruct unseen input data. This evaluation involves comparing the original input data with the output data generated by the autoencoder and quantifying the dissimilarity between them.\n",
    "\n",
    "A common approach for model evaluation is to plot the loss function's trajectory throughout the training process. The loss function measures the disparity between the model's predictions and the actual data, and the objective during training is to minimize this discrepancy. By visualizing the loss function over time, we gain insights into the model's learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48505132",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PT Tester 1'\n",
    "\n",
    "# Using the output as a string and extract the losses from it to plot.\n",
    "\n",
    "# Output as a string\n",
    "output = '''\n",
    "Epoch: 1/50, Train Loss: 0.204974, Test Loss: 0.180165\n",
    "Epoch: 2/50, Train Loss: 0.176585, Test Loss: 0.175485\n",
    "Epoch: 3/50, Train Loss: 0.171567, Test Loss: 0.168642\n",
    "Epoch: 4/50, Train Loss: 0.197860, Test Loss: 0.194732\n",
    "Epoch: 5/50, Train Loss: 0.191366, Test Loss: 0.185105\n",
    "Epoch: 6/50, Train Loss: 0.183782, Test Loss: 0.182551\n",
    "Epoch: 7/50, Train Loss: 0.184195, Test Loss: 0.182726\n",
    "Epoch: 8/50, Train Loss: 0.184192, Test Loss: 0.182597\n",
    "Epoch: 9/50, Train Loss: 0.184411, Test Loss: 0.185470\n",
    "Epoch: 10/50, Train Loss: 0.182817, Test Loss: 0.180296\n",
    "Epoch: 11/50, Train Loss: 0.183069, Test Loss: 0.182173\n",
    "Epoch: 12/50, Train Loss: 0.184476, Test Loss: 0.183482\n",
    "Epoch: 13/50, Train Loss: 0.184548, Test Loss: 0.183062\n",
    "Epoch: 14/50, Train Loss: 0.184422, Test Loss: 0.181984\n",
    "Epoch: 15/50, Train Loss: 0.184155, Test Loss: 0.186118\n",
    "Epoch: 16/50, Train Loss: 0.184086, Test Loss: 0.185751\n",
    "Epoch: 17/50, Train Loss: 0.184288, Test Loss: 0.183167\n",
    "Epoch: 18/50, Train Loss: 0.184408, Test Loss: 0.190368\n",
    "Epoch: 19/50, Train Loss: 0.184166, Test Loss: 0.182013\n",
    "Epoch: 20/50, Train Loss: 0.184299, Test Loss: 0.182965\n",
    "Epoch: 21/50, Train Loss: 0.184320, Test Loss: 0.188758\n",
    "Epoch: 22/50, Train Loss: 0.184405, Test Loss: 0.182461\n",
    "Epoch: 23/50, Train Loss: 0.184702, Test Loss: 0.183229\n",
    "Epoch: 24/50, Train Loss: 0.184036, Test Loss: 0.184159\n",
    "Epoch: 25/50, Train Loss: 0.184053, Test Loss: 0.183055\n",
    "Epoch: 26/50, Train Loss: 0.184493, Test Loss: 0.182483\n",
    "Epoch: 27/50, Train Loss: 0.184141, Test Loss: 0.186442\n",
    "Epoch: 28/50, Train Loss: 0.184628, Test Loss: 0.183238\n",
    "Epoch: 29/50, Train Loss: 0.184792, Test Loss: 0.182296\n",
    "Epoch: 30/50, Train Loss: 0.184565, Test Loss: 0.182591\n",
    "Epoch: 31/50, Train Loss: 0.184569, Test Loss: 0.184549\n",
    "Epoch: 32/50, Train Loss: 0.184111, Test Loss: 0.182878\n",
    "Epoch: 33/50, Train Loss: 0.184840, Test Loss: 0.183035\n",
    "Epoch: 34/50, Train Loss: 0.184522, Test Loss: 0.182288\n",
    "Epoch: 35/50, Train Loss: 0.184345, Test Loss: 0.182474\n",
    "Epoch: 36/50, Train Loss: 0.184023, Test Loss: 0.182138\n",
    "Epoch: 37/50, Train Loss: 0.184334, Test Loss: 0.182417\n",
    "Epoch: 38/50, Train Loss: 0.184844, Test Loss: 0.181717\n",
    "Epoch: 39/50, Train Loss: 0.184653, Test Loss: 0.182992\n",
    "Epoch: 40/50, Train Loss: 0.184247, Test Loss: 0.184875\n",
    "Epoch: 41/50, Train Loss: 0.184033, Test Loss: 0.182938\n",
    "Epoch: 42/50, Train Loss: 0.183228, Test Loss: 0.182625\n",
    "Epoch: 43/50, Train Loss: 0.183353, Test Loss: 0.184283\n",
    "Epoch: 44/50, Train Loss: 0.183265, Test Loss: 0.182878\n",
    "Epoch: 45/50, Train Loss: 0.183363, Test Loss: 0.182230\n",
    "Epoch: 46/50, Train Loss: 0.183643, Test Loss: 0.183758\n",
    "Epoch: 47/50, Train Loss: 0.183767, Test Loss: 0.182404\n",
    "Epoch: 48/50, Train Loss: 0.183774, Test Loss: 0.183001\n",
    "Epoch: 49/50, Train Loss: 0.183544, Test Loss: 0.181167\n",
    "Epoch: 50/50, Train Loss: 0.183839, Test Loss: 0.183598\n",
    "'''\n",
    "\n",
    "# Extract the losses from the output\n",
    "loss_data = output.strip().split('\\n')\n",
    "\n",
    "# Initialize lists to store the train and test losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Loop through each line in the loss_data\n",
    "for line in loss_data:\n",
    "    # Split the line by commas and extract the losses\n",
    "    parts = line.split(',')\n",
    "    train_loss_str = parts[1]\n",
    "    test_loss_str = parts[2]\n",
    "    \n",
    "    train_loss = float(train_loss_str.split(':')[1].strip())\n",
    "    test_loss = float(test_loss_str.split(':')[1].strip())\n",
    "\n",
    "    # Append the losses to their respective lists\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a7ec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9904a",
   "metadata": {},
   "source": [
    "#### Discussion of the Train vs Test Loss Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b7ad7",
   "metadata": {},
   "source": [
    "The training loss is slightly decreasing over time which is good.\n",
    "\n",
    "The test loss is also decreasing, but not consistently. Ideally, it should decrease consistently, similar to the training loss. It doesn't seem to overfit as it isn't increasing.\n",
    "\n",
    "The training and test losses are quite close to each other which is good as it suggests that the model is not overfitting or underfitting too much.\n",
    "\n",
    "Although, the output suggests that the model has not trained properly due to the loss not being low enough.\n",
    "Maybe the training data is insufficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a6392",
   "metadata": {},
   "source": [
    "## Tensorflow vs PyTorch  <a class=\"anchor\" id=\"seven\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac747f0",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e748695",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40cc17",
   "metadata": {},
   "source": [
    "* Both codes define an autoencoder model architecture that consists of an encoder and a decoder, and the size of the layers decreases progressively towards the bottleneck.\n",
    "* They both start by defining the input size and calculating the sizes of the hidden layer and the bottleneck layer. The sizes are calculated the same way: the hidden layer is half the size of the input layer, and the bottleneck layer is half the size of the hidden layer.\n",
    "* Both models use the ReLU activation function for the hidden layers.\n",
    "* Both models use linear transformation for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708982f",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018ae26",
   "metadata": {},
   "source": [
    "* **Library and Syntax:** The main difference between the two codes is the deep learning library they use. The first code uses TensorFlow with Keras API, which uses a functional API for defining models. The second code uses PyTorch, which uses an object-oriented approach. The way models are defined and the syntax used are different due to these library differences.\n",
    "\n",
    "* **Layer Definition:** In the TensorFlow code, each layer is explicitly defined one at a time and connected to the previous one. In the PyTorch code, layers are defined inside the nn.Sequential(), which automatically connects the layers in the order they are defined.\n",
    "\n",
    "* **Model Structure:** In the TensorFlow code, two models are returned: the autoencoder model and the encoder model. The PyTorch code only defines and returns the autoencoder model. If you wanted the encoder model in PyTorch, you'd need to access the .encoder attribute of an instance of the Autoencoder class.\n",
    "\n",
    "* **Forward Pass:** In the TensorFlow code, the forward pass (how data moves through the network during inference) is implicitly defined by the order in which layers are defined and connected. In PyTorch, the forward pass is explicitly defined in the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e341f",
   "metadata": {},
   "source": [
    "**TensorFlow:**\n",
    "def Autoencoder_Simple(input_size):  \n",
    "#This line defines the function Autoencoder_Simple which takes an argument input_size.\n",
    "\n",
    "**PyTorch:**\n",
    "class Autoencoder(nn.Module):  \n",
    "#This line defines a new class Autoencoder which inherits from nn.Module. In PyTorch, all neural networks should inherit from this class.\n",
    "\n",
    "**TensorFlow:**\n",
    "hidden_size = int(input_size / 2.0)   \n",
    "#This line calculates the size of the hidden layer. It is identical in both pieces of code.  \n",
    "\n",
    "**PyTorch:**\n",
    "def __init__(self, input_size):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    hidden_size = int(input_size / 2)\n",
    "  \n",
    "#These lines define the initialization method for the Autoencoder class, which takes an argument input_size. The super() function is used to call the initialization method of the parent nn.Module class. The hidden_size is calculated in the same way as in the TensorFlow code.  \n",
    "\n",
    "**TensorFlow:**\n",
    "bottleneck_size = int(hidden_size / 2.0)    \n",
    "#This line calculates the size of the bottleneck layer. It is identical in both pieces of code.\n",
    "\n",
    "**PyTorch:**\n",
    "bottleneck_size = int(hidden_size / 2)    \n",
    "#This line calculates the size of the bottleneck layer in the same way as in the TensorFlow code.\n",
    "\n",
    "**TensorFlow:**\n",
    "input_tab = Input(shape=(input_size,))    \n",
    "#This line defines the input layer for the TensorFlow model. The size of the input layer is defined by input_size.\n",
    "\n",
    "**PyTorch:**\n",
    "self.encoder = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, bottleneck_size),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "  \n",
    "#This block of code in PyTorch defines the encoder part of the autoencoder. It is a sequence of a linear layer, a ReLU activation, another linear layer, and another ReLU activation. The sizes of the layers and the types of activations correspond to those in the TensorFlow code.\n",
    "\n",
    "**TensorFlow:**\n",
    "hidden_1 = layers.Dense(hidden_size, activation='relu')(input_tab)\n",
    "bottleneck = layers.Dense(bottleneck_size, activation='relu')(hidden_1)\n",
    "  \n",
    "#These lines define the first two layers of the autoencoder: a dense layer with size hidden_size and a ReLU activation, and another dense layer with size bottleneck_size and a ReLU activation. These correspond to the first two layers in the PyTorch encoder.\n",
    "\n",
    "**PyTorch:**\n",
    "self.decoder = nn.Sequential(\n",
    "    nn.Linear(bottleneck_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, input_size),\n",
    ")\n",
    "  \n",
    "#This block of code defines the decoder part of the autoencoder in PyTorch. It is a sequence of a linear layer, a ReLU activation, and another linear layer. The sizes of the layers and the types of activations correspond to those in the TensorFlow code.\n",
    "\n",
    "**TensorFlow:**\n",
    "hidden_2 = layers.Dense(hidden_size, activation='relu')(bottleneck)\n",
    "output_tab = layers.Dense(input_size, activation='linear')(hidden_2)\n",
    "  \n",
    "#These lines define the last two layers of the TensorFlow autoencoder: a dense layer with size hidden_size and a ReLU activation, and another dense layer with size input_size and a linear activation. These correspond to the layers in the PyTorch decoder.\n",
    "\n",
    "**PyTorch:**\n",
    "def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    x = self.decoder(x)\n",
    "    return x\n",
    "  \n",
    "#These lines define the forward pass for the autoencoder in PyTorch. It simply involves passing the input x through the encoder, then passing the output of the encoder through the decoder, and returning the output of the decoder.\n",
    "\n",
    "**TensorFlow:**\n",
    "encoder = Model(input_tab, bottleneck)\n",
    "model = Model(input_tab, output_tab)\n",
    "return model, encoder\n",
    "  \n",
    "#These lines create two models in TensorFlow: the full autoencoder model (named model) and the encoder model (named encoder). Both models use input_tab as their input layer. The autoencoder model uses output_tab as its output layer, while the encoder model uses bottleneck as its output layer. The function then returns both models.\n",
    "\n",
    "**PyTorch:**\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "  \n",
    "#Here, we're converting the training and testing data to PyTorch tensors, which are multi-dimensional matrices similar to numpy arrays but can be used on GPUs and with automatic differentiation, which is essential for training neural networks.\n",
    "\n",
    "**TensorFlow:**\n",
    "from tensorflow.keras import layers  \n",
    "#This line imports the layers module from TensorFlow's Keras API. This module includes various layers that can be used to build a neural network model, such as Dense (fully connected) layers, Convolutional layers, and so on.\n",
    "\n",
    "**PyTorch:**\n",
    "train_dataset = TensorDataset(X_train_torch)  \n",
    "test_dataset = TensorDataset(X_test_torch)\n",
    "  \n",
    "#In these lines, we're wrapping the PyTorch tensors into a TensorDataset. A TensorDataset wraps tensors and allows access to slices of these tensors across the first dimension which will be useful when we batch our data during training.\n",
    "\n",
    "**TensorFlow:**\n",
    "input_size = X.shape[1]  \n",
    "#This line gets the number of features in the dataset, which corresponds to the second dimension of the data matrix X. It's used as the input size for the model.\n",
    "\n",
    "**PyTorch:**\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "  \n",
    "#Here, we're creating DataLoaders for the training and testing data. A DataLoader can load multiple samples in parallel and provides features like batching, shuffling, and loading the data in parallel using multiprocessing.\n",
    "\n",
    "**TensorFlow:**\n",
    "model, encoder = Autoencoder_Simple(input_size)\n",
    "plot_model(model, show_shapes=True, to_file='model.png')\n",
    "  \n",
    "#This line is calling a function named Autoencoder_Simple() that creates and returns two models: the full autoencoder and just the encoder part of it. We also use the plot_model() function from Keras to visualize the model's architecture, including the shape of the tensors at each layer. \n",
    "\n",
    "**PyTorch:**\n",
    "input_size = X.shape[1] \n",
    "model = Autoencoder(input_size)\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "  \n",
    "#These lines get the number of features (input size) from the data and instantiate the Autoencoder model with that input size. We're also defining the loss function as Mean Squared Error (MSE) loss and the optimizer as Adam. These are used during the training loop to update the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1a270",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5def6",
   "metadata": {},
   "source": [
    "The TensorFlow code appears more succinct due to the high-level abstraction provided by Keras. In Keras (and thus in TensorFlow, which has integrated Keras as its official high-level API), many of the lower-level details are abstracted away, making the code shorter and easier to understand. \n",
    "\n",
    "For instance:  \n",
    " The TensorFlow code uses the Keras Model class to define and instantiate the model in just a few lines of code. The model structure, including the layers and their connections, is defined all at once.  \n",
    " The TensorFlow code doesn't include the definition of a training loop or loss function, as these are typically handled by built-in functions such as model.fit() in TensorFlow/Keras. The use of these built-in functions contributes to the succinctness of the TensorFlow code.\n",
    "\n",
    "  On the other hand, PyTorch provides a more granular and explicit interface, which allows for greater flexibility and control, but may also require more code.  \n",
    "  This is especially apparent in the way PyTorch code often includes explicit definitions for the forward pass, loss function, and training loop. \n",
    "  \n",
    "While this might make PyTorch code longer and more verbose, it can also make it more transparent and easier to debug, as it offers more control over the individual operations that the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856222e3",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25486b1c",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7c64a",
   "metadata": {},
   "source": [
    "data challenge photometry datsset trying to identify blackholes make a color color plot of all objects and output of the autoencoder - tell a story for the poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e8e90",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db18960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e206b0ee",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744b1f3",
   "metadata": {},
   "source": [
    "#### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd134577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49f328a",
   "metadata": {},
   "source": [
    "#### Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5ece0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
